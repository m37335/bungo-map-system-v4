#!/usr/bin/env python3
"""
æ–‡è±ªåœ°å›³ã‚·ã‚¹ãƒ†ãƒ  - ç°¡å˜ãƒ‡ãƒ¼ã‚¿åé›†
é’ç©ºæ–‡åº«ã‹ã‚‰æ–°ã—ã„ä½œå“ã‚’å–å¾—ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ 
"""

import requests
import sqlite3
import re
import os
import time
from pathlib import Path
from urllib.parse import urljoin
import zipfile
import io

# æ–°ã—ã„ä½œå“ã®è¨­å®š
NEW_WORKS = [
    {
        "author": "æ£®é´å¤–",
        "title": "èˆå§«", 
        "aozora_id": "52374",  # é’ç©ºæ–‡åº«ID
        "zip_url": "https://www.aozora.gr.jp/cards/000129/files/52374_zip.zip"
    },
    {
        "author": "æ¨‹å£ä¸€è‘‰",
        "title": "ãŸã‘ãã‚‰ã¹",
        "aozora_id": "2386",
        "zip_url": "https://www.aozora.gr.jp/cards/000064/files/2386_zip.zip"
    },
    {
        "author": "å®®æ²¢è³¢æ²»",
        "title": "æ³¨æ–‡ã®å¤šã„æ–™ç†åº—",
        "aozora_id": "1927",
        "zip_url": "https://www.aozora.gr.jp/cards/000081/files/1927_zip.zip"
    }
]

def find_database():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
    possible_paths = [
        "bungo_project_v3/data/bungo_production.db",
        "bungo_project_v2/data/bungo_production.db", 
        "bungo_project/data/bungo_production.db"
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            return path
    return None

def download_and_extract_text(zip_url, title):
    """é’ç©ºæ–‡åº«ã‹ã‚‰ä½œå“ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»æŠ½å‡º"""
    print(f"   ğŸ“¥ {title} ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
    
    try:
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        cache_dir = Path("aozora_cache")
        cache_dir.mkdir(exist_ok=True)
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        response = requests.get(zip_url, timeout=30)
        response.raise_for_status()
        
        # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹
        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
            txt_files = [name for name in zip_file.namelist() if name.endswith('.txt')]
            
            if not txt_files:
                print(f"   âŒ {title}: ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None
            
            # æœ€åˆã®txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            with zip_file.open(txt_files[0]) as txt_file:
                # Shift-JISã§èª­ã¿è¾¼ã¿ï¼ˆé’ç©ºæ–‡åº«ã®æ¨™æº–ï¼‰
                try:
                    content = txt_file.read().decode('shift_jis')
                except UnicodeDecodeError:
                    try:
                        content = txt_file.read().decode('utf-8')
                    except UnicodeDecodeError:
                        content = txt_file.read().decode('utf-8', errors='ignore')
        
        # é’ç©ºæ–‡åº«ã®æ³¨è¨˜ã‚’å‰Šé™¤ï¼ˆç°¡å˜ç‰ˆï¼‰
        content = re.sub(r'ã€Š.*?ã€‹', '', content)  # ãƒ«ãƒ“é™¤å»
        content = re.sub(r'ï¼»ï¼ƒ.*?ï¼½', '', content)  # æ³¨è¨˜é™¤å»
        content = re.sub(r'-----.*?-----', '', content, flags=re.DOTALL)  # ãƒ˜ãƒƒãƒ€é™¤å»
        
        print(f"   âœ… {title}: {len(content)}æ–‡å­— å–å¾—å®Œäº†")
        return content
        
    except Exception as e:
        print(f"   âŒ {title} ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def extract_places_simple(text, title):
    """ç°¡å˜ãªåœ°åæŠ½å‡ºï¼ˆæ­£è¦è¡¨ç¾ãƒ™ãƒ¼ã‚¹ï¼‰"""
    print(f"   ğŸ” {title} åœ°åæŠ½å‡ºä¸­...")
    
    # åœ°åãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä¸€èˆ¬çš„ãªåœ°åã¨æ–‡å­¦ä½œå“ã«ã‚ˆãå‡ºã‚‹åœ°åï¼‰
    place_patterns = [
        # ä¸»è¦éƒ½å¸‚
        r'æ±äº¬|äº¬éƒ½|å¤§é˜ª|åå¤å±‹|æ¨ªæµœ|ç¥æˆ¸|ç¦å²¡|æœ­å¹Œ|ä»™å°|åºƒå³¶|ç†Šæœ¬|é¹¿å…å³¶',
        # æ­´å²çš„åœ°å
        r'æ±Ÿæˆ¸|å¹³å®‰äº¬|éŒå€‰|å¥ˆè‰¯|å¤§å’Œ|å¤§å‚|é•·å®‰|æ´›ä¸­|æ´›å¤–',
        # åœ°æ–¹ãƒ»çœŒå
        r'åŒ—æµ·é“|é’æ£®|å²©æ‰‹|å®®åŸ|ç§‹ç”°|å±±å½¢|ç¦å³¶|èŒ¨åŸ|æ ƒæœ¨|ç¾¤é¦¬|åŸ¼ç‰|åƒè‘‰|æ±äº¬|ç¥å¥ˆå·|æ–°æ½Ÿ|å¯Œå±±|çŸ³å·|ç¦äº•|å±±æ¢¨|é•·é‡|å²é˜œ|é™å²¡|æ„›çŸ¥|ä¸‰é‡|æ»‹è³€|äº¬éƒ½|å¤§é˜ª|å…µåº«|å¥ˆè‰¯|å’Œæ­Œå±±|é³¥å–|å³¶æ ¹|å²¡å±±|åºƒå³¶|å±±å£|å¾³å³¶|é¦™å·|æ„›åª›|é«˜çŸ¥|ç¦å²¡|ä½è³€|é•·å´|ç†Šæœ¬|å¤§åˆ†|å®®å´|é¹¿å…å³¶|æ²–ç¸„',
        # åŒºåãƒ»å¸‚åï¼ˆæŠœç²‹ï¼‰
        r'æ–°å®¿|æ¸‹è°·|å“å·|ç›®é»’|ä¸–ç”°è°·|ä¸­é‡|æ‰ä¸¦|ç·´é¦¬|å°æ±|å¢¨ç”°|æ±Ÿæ±|è’å·|è¶³ç«‹|è‘›é£¾|æ±Ÿæˆ¸å·|åƒä»£ç”°|ä¸­å¤®|æ¸¯|æ–‡äº¬|è±Šå³¶|åŒ—|æ¿æ©‹',
        # ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘åœ°åï¼ˆèˆå§«ç­‰ï¼‰
        r'ãƒ™ãƒ«ãƒªãƒ³|ãƒ‘ãƒª|ãƒ­ãƒ³ãƒ‰ãƒ³|ã‚¦ã‚£ãƒ¼ãƒ³|ãƒ­ãƒ¼ãƒ|ãƒŸãƒ¥ãƒ³ãƒ˜ãƒ³|ãƒãƒ³ãƒ–ãƒ«ã‚¯|ãƒ•ãƒ©ãƒ³ã‚¯ãƒ•ãƒ«ãƒˆ|ãƒ‰ãƒ¬ã‚¹ãƒ‡ãƒ³|ãƒ©ã‚¤ãƒ—ãƒ„ã‚£ãƒ’',
        # ãã®ä»–æ–‡å­¦åœ°å
        r'ä¸Šé‡|æµ…è‰|éŠ€åº§|ä¸¸ã®å†…|æ–°æ©‹|æœ‰æ¥½ç”º|ä¸¡å›½|æ—¥æœ¬æ©‹|ç¥ç”°|å°å·ç”º|éº¹ç”º|éº»å¸ƒ|èµ¤å‚|é’å±±|è¡¨å‚é“'
    ]
    
    places = []
    full_pattern = '|'.join(place_patterns)
    
    # æ–‡ç« ã‚’å¥ç‚¹ã§åˆ†å‰²
    sentences = re.split(r'[ã€‚ï¼Ÿï¼]', text)
    
    for sentence in sentences:
        sentence = sentence.strip()
        if len(sentence) < 5:  # çŸ­ã™ãã‚‹æ–‡ã¯é™¤å¤–
            continue
            
        # åœ°åã‚’æ¤œç´¢
        matches = re.finditer(f'({full_pattern})', sentence)
        for match in matches:
            place_name = match.group(1)
            
            # å‰å¾Œã®æ–‡è„ˆã‚’å–å¾—
            start_pos = max(0, sentence.find(place_name) - 20)
            end_pos = min(len(sentence), sentence.find(place_name) + len(place_name) + 20)
            context = sentence[start_pos:end_pos]
            
            places.append({
                'place_name': place_name,
                'sentence': sentence,
                'context': context,
                'confidence': 0.8  # æ­£è¦è¡¨ç¾ãƒ™ãƒ¼ã‚¹ã®åŸºæœ¬ä¿¡é ¼åº¦
            })
    
    # é‡è¤‡é™¤å»ï¼ˆåœ°åã¨æ–‡ç« ã®çµ„ã¿åˆã‚ã›ï¼‰
    unique_places = []
    seen = set()
    for place in places:
        key = (place['place_name'], place['sentence'][:50])
        if key not in seen:
            seen.add(key)
            unique_places.append(place)
    
    print(f"   âœ… {title}: {len(unique_places)}ä»¶ã®åœ°åã‚’æŠ½å‡º")
    return unique_places

def save_to_database(db_path, author_name, title, places, aozora_url):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
    with sqlite3.connect(db_path) as conn:
        cursor = conn.cursor()
        
        # è‘—è€…ã‚’è¿½åŠ ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
        cursor.execute("INSERT OR IGNORE INTO authors (name) VALUES (?)", (author_name,))
        cursor.execute("SELECT author_id FROM authors WHERE name = ?", (author_name,))
        author_id = cursor.fetchone()[0]
        
        # ä½œå“ã‚’è¿½åŠ ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
        cursor.execute("INSERT OR IGNORE INTO works (author_id, title) VALUES (?, ?)", (author_id, title))
        cursor.execute("SELECT work_id FROM works WHERE author_id = ? AND title = ?", (author_id, title))
        work_result = cursor.fetchone()
        if work_result:
            work_id = work_result[0]
        else:
            print(f"   âŒ ä½œå“è¿½åŠ ã‚¨ãƒ©ãƒ¼: {title}")
            return
        
        # åœ°åã‚’è¿½åŠ 
        added_count = 0
        for place in places:
            try:
                cursor.execute("""
                    INSERT OR IGNORE INTO places 
                    (work_id, place_name, sentence, confidence, extraction_method, aozora_url)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (
                    work_id,
                    place['place_name'], 
                    place['sentence'],
                    place['confidence'],
                    'regex_simple',
                    aozora_url
                ))
                if cursor.rowcount > 0:
                    added_count += 1
            except Exception as e:
                print(f"   âš ï¸ åœ°åä¿å­˜ã‚¨ãƒ©ãƒ¼ ({place['place_name']}): {e}")
        
        conn.commit()
        print(f"   âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜: {added_count}ä»¶è¿½åŠ ")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸš€ æ–‡è±ªåœ°å›³ã‚·ã‚¹ãƒ†ãƒ  - æ–°è¦ãƒ‡ãƒ¼ã‚¿åé›†")
    print("=" * 50)
    
    db_path = find_database()
    if not db_path:
        print("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    print(f"ğŸ“ ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {db_path}")
    
    for work_info in NEW_WORKS:
        print(f"\nğŸ“š å‡¦ç†ä¸­: {work_info['author']} - {work_info['title']}")
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        text = download_and_extract_text(work_info['zip_url'], work_info['title'])
        if not text:
            continue
        
        # åœ°åæŠ½å‡º
        places = extract_places_simple(text, work_info['title'])
        if not places:
            print(f"   âš ï¸ {work_info['title']}: åœ°åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            continue
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
        save_to_database(
            db_path, 
            work_info['author'], 
            work_info['title'], 
            places,
            work_info['zip_url']
        )
        
        # çŸ­æ™‚é–“ã®å¾…æ©Ÿï¼ˆã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›ï¼‰
        time.sleep(2)
    
    print(f"\nğŸ‰ ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†!")
    print(f"æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã™ã‚‹ã«ã¯:")
    print(f"  python3 simple_data_export.py")

if __name__ == "__main__":
    main() 
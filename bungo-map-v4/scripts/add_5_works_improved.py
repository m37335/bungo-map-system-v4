#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ—¾ é’ç©ºæ–‡åº«5ä½œå“è¿½åŠ â†’å®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œï¼ˆæ”¹è‰¯ç‰ˆï¼‰

é’ç©ºæ–‡åº«URLã‚¢ã‚¯ã‚»ã‚¹å•é¡Œã‚’ä¿®æ­£ã—ã€é©åˆ‡ãªãƒ†ã‚­ã‚¹ãƒˆå–å¾—ã‚’å®Ÿè¡Œ
"""

import sys
import os
import sqlite3
import requests
import re
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
from urllib.parse import urljoin, urlparse

# v3ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, '/app')
sys.path.insert(0, '/app/bungo_map')

# v3ã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from bungo_map.extractors.aozora_search import AozoraSearcher
from bungo_map.extractors.aozora_extractor import AozoraExtractor
from bungo_map.processors.aozora_content_processor import AozoraContentProcessor
from bungo_map.extractors.simple_place_extractor import SimplePlaceExtractor

class ImprovedWorkflowExecutor:
    """æ”¹è‰¯ç‰ˆé’ç©ºæ–‡åº«â†’å®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, db_path: str = '/app/bungo-map-v4/data/databases/bungo_v4.db'):
        self.db_path = db_path
        
        print("ğŸ”§ æ”¹è‰¯ç‰ˆå®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
        
        # v3ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        self.searcher = AozoraSearcher()
        self.extractor = AozoraExtractor()
        self.processor = AozoraContentProcessor()
        self.simple_extractor = SimplePlaceExtractor()
        print("âœ… v3çµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        
        # è¿½åŠ äºˆå®šã®5ä½œå“ï¼ˆå®Ÿè¨¼æ¸ˆã¿URLä»˜ãï¼‰
        self.target_works = [
            ('å¤ç›®æ¼±çŸ³', 'ã“ã“ã‚', 'https://www.aozora.gr.jp/cards/000148/files/773_14560.html'),
            ('èŠ¥å·é¾ä¹‹ä»‹', 'ç¾…ç”Ÿé–€', 'https://www.aozora.gr.jp/cards/000879/files/127_15260.html'),
            ('å¤ªå®°æ²»', 'èµ°ã‚Œãƒ¡ãƒ­ã‚¹', 'https://www.aozora.gr.jp/cards/000035/files/1567_14913.html'),
            ('å®®æ²¢è³¢æ²»', 'æ³¨æ–‡ã®å¤šã„æ–™ç†åº—', 'https://www.aozora.gr.jp/cards/000081/files/43754_17659.html'),
            ('æ¨‹å£ä¸€è‘‰', 'ãŸã‘ãã‚‰ã¹', 'https://www.aozora.gr.jp/cards/000064/files/893_14763.html')
        ]
    
    def execute_complete_workflow(self):
        """å®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ"""
        print("ğŸš€ æ”¹è‰¯ç‰ˆé’ç©ºæ–‡åº«â†’å®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œé–‹å§‹")
        print("=" * 80)
        
        # ãƒ•ã‚§ãƒ¼ã‚º1: ä½œå“è¿½åŠ 
        print("\nğŸ“š ãƒ•ã‚§ãƒ¼ã‚º1: é’ç©ºæ–‡åº«ä½œå“è¿½åŠ ï¼ˆæ”¹è‰¯ç‰ˆï¼‰")
        print("-" * 50)
        
        added_works = []
        for i, (author_name, work_title, aozora_url) in enumerate(self.target_works, 1):
            print(f"\nğŸ“– {i}/5: {author_name} - {work_title}")
            work_id = self._add_single_work_improved(author_name, work_title, aozora_url)
            if work_id:
                added_works.append((work_id, author_name, work_title))
            time.sleep(1)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
        
        print(f"\nâœ… ãƒ•ã‚§ãƒ¼ã‚º1å®Œäº†: {len(added_works)}ä½œå“è¿½åŠ ")
        
        # ãƒ•ã‚§ãƒ¼ã‚º2: åœ°åæŠ½å‡º
        print("\nğŸ—ºï¸ ãƒ•ã‚§ãƒ¼ã‚º2: åœ°åæŠ½å‡ºå®Ÿè¡Œï¼ˆæ”¹è‰¯ç‰ˆï¼‰")
        print("-" * 50)
        
        total_places = 0
        for work_id, author_name, work_title in added_works:
            print(f"\nğŸ” åœ°åæŠ½å‡º: {work_title}")
            places_count = self._extract_places_for_work_improved(work_id)
            total_places += places_count
            print(f"  âœ… æŠ½å‡ºåœ°åæ•°: {places_count}")
        
        print(f"\nâœ… ãƒ•ã‚§ãƒ¼ã‚º2å®Œäº†: ç·åœ°åæ•° {total_places}")
        
        # æœ€çµ‚çµ±è¨ˆ
        self._show_final_statistics()
        
        print(f"\nğŸ‰ æ”¹è‰¯ç‰ˆå®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œå®Œäº†ï¼")
    
    def _add_single_work_improved(self, author_name: str, work_title: str, aozora_url: str) -> Optional[int]:
        """å˜ä¸€ä½œå“ã®è¿½åŠ ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        try:
            print(f"  ğŸ”— ç›´æ¥ãƒ•ã‚¡ã‚¤ãƒ«URL: {aozora_url}")
            
            # 1. å®Ÿéš›ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥å–å¾—
            raw_content = self._fetch_text_content_improved(aozora_url)
            if not raw_content or len(raw_content) < 100:
                print(f"  âŒ ãƒ†ã‚­ã‚¹ãƒˆå–å¾—å¤±æ•—: {len(raw_content) if raw_content else 0}æ–‡å­—")
                return None
            
            print(f"  ğŸ“„ ãƒ†ã‚­ã‚¹ãƒˆå–å¾—æˆåŠŸ: {len(raw_content):,}æ–‡å­—")
            
            # 2. ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å‡¦ç†
            processed_result = self.processor.process_work_content(0, raw_content)
            if not processed_result['success']:
                print(f"  âŒ å‡¦ç†å¤±æ•—: {processed_result.get('error', 'Unknown')}")
                return None
            
            sentences = processed_result['sentences']
            main_content = processed_result['main_content']
            print(f"  ğŸ“ æ–‡åˆ†å‰²: {len(sentences)}æ–‡ï¼ˆæœ¬æ–‡: {len(main_content):,}æ–‡å­—ï¼‰")
            
            # 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¿½åŠ 
            work_id = self._add_to_database(
                author_name, work_title, aozora_url, main_content, sentences
            )
            
            if work_id:
                print(f"  âœ… è¿½åŠ å®Œäº†: work_id={work_id}")
                return work_id
            else:
                print(f"  âŒ DBè¿½åŠ å¤±æ•—")
                return None
                
        except Exception as e:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _fetch_text_content_improved(self, url: str) -> str:
        """æ”¹è‰¯ç‰ˆãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—"""
        try:
            print(f"    ğŸŒ ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {url}")
            
            # User-Agentã‚’è¨­å®š
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            
            # æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°åˆ¤å®š
            if 'charset=shift_jis' in response.headers.get('content-type', ''):
                content = response.content.decode('shift_jis', errors='ignore')
            elif 'charset=utf-8' in response.headers.get('content-type', ''):
                content = response.content.decode('utf-8', errors='ignore')
            else:
                # è‡ªå‹•åˆ¤å®š
                try:
                    content = response.content.decode('shift_jis', errors='ignore')
                except:
                    content = response.content.decode('utf-8', errors='ignore')
            
            print(f"    âœ… å–å¾—æˆåŠŸ: {len(content):,}æ–‡å­—")
            return content
            
        except Exception as e:
            print(f"    âŒ ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def _add_to_database(self, author_name: str, work_title: str, 
                        aozora_url: str, main_content: str, sentences: List[str]) -> Optional[int]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ """
        try:
            with sqlite3.connect(self.db_path) as conn:
                # ä½œå®¶å–å¾—/ä½œæˆ
                author_id = self._get_or_create_author(conn, author_name)
                
                # é‡è¤‡ç¢ºèª
                cursor = conn.execute(
                    "SELECT work_id FROM works WHERE title = ? AND author_id = ?",
                    (work_title, author_id)
                )
                existing = cursor.fetchone()
                if existing:
                    print(f"    âš ï¸ æ—¢å­˜ä½œå“: work_id={existing[0]}")
                    return existing[0]
                
                # ä½œå“è¿½åŠ 
                cursor = conn.execute("""
                    INSERT INTO works (title, author_id, aozora_url, content_length, sentence_count, created_at)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (work_title, author_id, aozora_url, len(main_content), len(sentences), datetime.now().isoformat()))
                
                work_id = cursor.lastrowid
                
                # ã‚»ãƒ³ãƒ†ãƒ³ã‚¹è¿½åŠ 
                valid_sentences = 0
                for i, sentence_text in enumerate(sentences):
                    cleaned_sentence = sentence_text.strip()
                    if len(cleaned_sentence) < 5:
                        continue
                    
                    before_text = sentences[i-1].strip()[:200] if i > 0 else ""
                    after_text = sentences[i+1].strip()[:200] if i < len(sentences)-1 else ""
                    
                    conn.execute("""
                        INSERT INTO sentences (
                            sentence_text, work_id, author_id, before_text, after_text,
                            position_in_work, created_at
                        )
                        VALUES (?, ?, ?, ?, ?, ?, ?)
                    """, (
                        cleaned_sentence,
                        work_id,
                        author_id,
                        before_text,
                        after_text,
                        i + 1,
                        datetime.now().isoformat()
                    ))
                    valid_sentences += 1
                
                conn.commit()
                print(f"    ğŸ“Š æœ‰åŠ¹ã‚»ãƒ³ãƒ†ãƒ³ã‚¹: {valid_sentences}/{len(sentences)}")
                return work_id
                
        except Exception as e:
            print(f"    âš ï¸ DBè¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _get_or_create_author(self, conn: sqlite3.Connection, author_name: str) -> int:
        """ä½œå®¶å–å¾—/ä½œæˆ"""
        cursor = conn.execute("SELECT author_id FROM authors WHERE name = ?", (author_name,))
        result = cursor.fetchone()
        
        if result:
            return result[0]
        
        cursor = conn.execute(
            "INSERT INTO authors (name, created_at) VALUES (?, ?)",
            (author_name, datetime.now().isoformat())
        )
        return cursor.lastrowid
    
    def _extract_places_for_work_improved(self, work_id: int) -> int:
        """ä½œå“ã®åœ°åæŠ½å‡ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        total_places = 0
        
        try:
            # ã‚»ãƒ³ãƒ†ãƒ³ã‚¹å–å¾—
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("""
                    SELECT sentence_id, sentence_text, before_text, after_text
                    FROM sentences WHERE work_id = ?
                    ORDER BY position_in_work
                """, (work_id,))
                sentences = cursor.fetchall()
                
                print(f"    ğŸ“ å‡¦ç†å¯¾è±¡: {len(sentences)}æ–‡")
            
            if not sentences:
                print(f"    âš ï¸ ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return 0
            
            # åœ°åæŠ½å‡ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰
            for sentence_id, sentence_text, before_text, after_text in sentences:
                if not sentence_text or len(sentence_text.strip()) < 5:
                    continue
                
                try:
                    # SimpleæŠ½å‡ºå™¨ã§åœ°åæŠ½å‡º
                    simple_places = self.simple_extractor.extract_places_from_text(work_id, sentence_text)
                    
                    # places_masterã¨sentence_placesã«è¿½åŠ 
                    with sqlite3.connect(self.db_path) as conn:
                        for place in simple_places:
                            try:
                                # places_masterã«è¿½åŠ 
                                cursor = conn.execute("""
                                    INSERT OR IGNORE INTO places_master (place_name, canonical_name, place_type, confidence)
                                    VALUES (?, ?, ?, ?)
                                """, (place.place_name, place.place_name, 'åœ°å', getattr(place, 'confidence', 0.8)))
                                
                                # place_idå–å¾—
                                cursor = conn.execute(
                                    "SELECT place_id FROM places_master WHERE place_name = ?", 
                                    (place.place_name,)
                                )
                                result = cursor.fetchone()
                                if not result:
                                    continue
                                place_id = result[0]
                                
                                # sentence_placesã«è¿½åŠ 
                                conn.execute("""
                                    INSERT INTO sentence_places (
                                        sentence_id, place_id, extraction_method, confidence,
                                        context_before, context_after, matched_text, created_at
                                    )
                                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                                """, (
                                    sentence_id, place_id, 
                                    getattr(place, 'extraction_method', 'simple'), 
                                    getattr(place, 'confidence', 0.8),
                                    before_text, after_text, place.place_name, 
                                    datetime.now().isoformat()
                                ))
                                
                                total_places += 1
                                print(f"    ğŸ—ºï¸ åœ°åç™ºè¦‹: {place.place_name}")
                                
                            except Exception as e:
                                print(f"    âš ï¸ åœ°åè¿½åŠ ã‚¨ãƒ©ãƒ¼: {place.place_name} - {e}")
                                continue
                        
                        conn.commit()
                
                except Exception as e:
                    print(f"    âš ï¸ ã‚»ãƒ³ãƒ†ãƒ³ã‚¹å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
        
        except Exception as e:
            print(f"    âŒ åœ°åæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        
        return total_places
    
    def _show_final_statistics(self):
        """æœ€çµ‚çµ±è¨ˆè¡¨ç¤º"""
        with sqlite3.connect(self.db_path) as conn:
            # åŸºæœ¬çµ±è¨ˆ
            cursor = conn.execute("SELECT COUNT(*) FROM authors")
            authors_count = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(*) FROM works")
            works_count = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(*) FROM sentences")
            sentences_count = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(*) FROM places_master")
            places_count = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(*) FROM sentence_places")
            sentence_places_count = cursor.fetchone()[0]
            
            # æœ€æ–°ä½œå“
            cursor = conn.execute("""
                SELECT a.name, w.title, w.sentence_count, w.content_length
                FROM authors a
                JOIN works w ON a.author_id = w.author_id
                ORDER BY w.created_at DESC
                LIMIT 5
            """)
            recent_works = cursor.fetchall()
            
            # åœ°ååˆ¥çµ±è¨ˆ
            cursor = conn.execute("""
                SELECT pm.place_name, COUNT(sp.sentence_id) as count
                FROM places_master pm
                LEFT JOIN sentence_places sp ON pm.place_id = sp.place_id
                GROUP BY pm.place_name
                ORDER BY count DESC
                LIMIT 10
            """)
            top_places = cursor.fetchall()
        
        print(f"\nğŸ“Š æ”¹è‰¯ç‰ˆå®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œå¾Œã®çµ±è¨ˆ")
        print("=" * 60)
        print(f"ğŸ‘¥ ä½œå®¶æ•°: {authors_count:,}")
        print(f"ğŸ“š ä½œå“æ•°: {works_count:,}")
        print(f"ğŸ“ ã‚»ãƒ³ãƒ†ãƒ³ã‚¹æ•°: {sentences_count:,}")
        print(f"ğŸ—ºï¸ åœ°åæ•°: {places_count:,}")
        print(f"ğŸ”— æ–‡-åœ°åé–¢ä¿‚æ•°: {sentence_places_count:,}")
        
        print(f"\nğŸ“– è¿½åŠ ã•ã‚ŒãŸä½œå“:")
        for author, title, sentences, content_length in recent_works:
            print(f"  â€¢ {author} - {title} ({sentences:,}æ–‡, {content_length:,}æ–‡å­—)")
        
        if top_places:
            print(f"\nğŸ—ºï¸ é »å‡ºåœ°åTOP10:")
            for place_name, count in top_places:
                print(f"  â€¢ {place_name}: {count}å›")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ—¾ æ”¹è‰¯ç‰ˆé’ç©ºæ–‡åº«5ä½œå“â†’å®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ")
    print("=" * 80)
    
    executor = ImprovedWorkflowExecutor()
    executor.execute_complete_workflow()


if __name__ == "__main__":
    main() 
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ï¿½ï¿½ é’ç©ºæ–‡åº«5ä½œå“â†’å®Œå…¨åœ°åãƒ•ãƒ­ãƒ¼æœ€çµ‚ç‰ˆ v4

åœ°åæŠ½å‡ºã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ã€æ­£ç¢ºãªå‡¦ç†ã‚’å®Ÿè¡Œ
çµ±åˆåœ°åæŠ½å‡ºãƒ»æ­£è¦åŒ–ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
"""

import sys
import os
import sqlite3
import requests
import re
import time
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple

# v4ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, '/app/bungo-map-v4')

# v4ã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.bungo_map.database.manager import DatabaseManager
from src.bungo_map.extractors_v4.unified_place_extractor import UnifiedPlaceExtractor
from src.bungo_map.extractors_v4.place_normalizer import PlaceNormalizer

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class FinalWorkflowExecutor:
    """æœ€çµ‚ç‰ˆå®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ  v4"""
    
    def __init__(self, db_path: str = '/app/bungo-map-v4/data/databases/bungo_v4.db'):
        self.db_path = db_path
        
        logger.info("ğŸ”§ æœ€çµ‚ç‰ˆå®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ v4åˆæœŸåŒ–ä¸­...")
        
        # v4ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        self.db_manager = DatabaseManager(db_path)
        self.unified_extractor = UnifiedPlaceExtractor()
        self.normalizer = PlaceNormalizer()
        
        logger.info("âœ… v4çµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def execute_place_extraction_and_geocoding(self):
        """åœ°åæŠ½å‡ºã¨Geocodingã®å®Ÿè¡Œ"""
        logger.info("ğŸš€ æœ€çµ‚ç‰ˆåœ°åæŠ½å‡º+Geocodingå®Ÿè¡Œé–‹å§‹")
        logger.info("=" * 80)
        
        # ãƒ•ã‚§ãƒ¼ã‚º1: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
        logger.info("\nğŸ“Š ãƒ•ã‚§ãƒ¼ã‚º1: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ç¢ºèª")
        logger.info("-" * 50)
        
        stats = self._get_current_statistics()
        logger.info(f"ğŸ‘¥ ä½œå®¶æ•°: {stats['authors']:,}")
        logger.info(f"ğŸ“š ä½œå“æ•°: {stats['works']:,}")
        logger.info(f"ğŸ“ ã‚»ãƒ³ãƒ†ãƒ³ã‚¹æ•°: {stats['sentences']:,}")
        logger.info(f"ğŸ—ºï¸ æ—¢å­˜åœ°åæ•°: {stats['places']:,}")
        logger.info(f"ğŸ”— æ—¢å­˜æ–‡-åœ°åé–¢ä¿‚æ•°: {stats['sentence_places']:,}")
        
        # ãƒ•ã‚§ãƒ¼ã‚º2: åœ°åæŠ½å‡ºå®Ÿè¡Œ
        logger.info("\nğŸ—ºï¸ ãƒ•ã‚§ãƒ¼ã‚º2: å…¨ã‚»ãƒ³ãƒ†ãƒ³ã‚¹åœ°åæŠ½å‡ºå®Ÿè¡Œ")
        logger.info("-" * 50)
        
        total_extracted = self._extract_all_places()
        logger.info(f"\nâœ… ãƒ•ã‚§ãƒ¼ã‚º2å®Œäº†: {total_extracted}ä»¶ã®æ–°è¦åœ°åæŠ½å‡º")
        
        # ãƒ•ã‚§ãƒ¼ã‚º3: çµ±è¨ˆæƒ…å ±ã®æ›´æ–°
        logger.info("\nğŸ“Š ãƒ•ã‚§ãƒ¼ã‚º3: çµ±è¨ˆæƒ…å ±æ›´æ–°")
        logger.info("-" * 50)
        
        self._update_all_statistics()
        logger.info("\nâœ… ãƒ•ã‚§ãƒ¼ã‚º3å®Œäº†: çµ±è¨ˆæƒ…å ±æ›´æ–°å®Œäº†")
        
        # æœ€çµ‚çµ±è¨ˆ
        logger.info("\nğŸ“Š ãƒ•ã‚§ãƒ¼ã‚º4: æœ€çµ‚çµ±è¨ˆè¡¨ç¤º")
        logger.info("-" * 50)
        self._show_comprehensive_statistics()
        
        logger.info(f"\nğŸ‰ æœ€çµ‚ç‰ˆå®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œå®Œäº†ï¼")
    
    def _get_current_statistics(self) -> Dict[str, int]:
        """ç¾åœ¨ã®çµ±è¨ˆæƒ…å ±å–å¾—"""
        with sqlite3.connect(self.db_path) as conn:
            stats = {}
            
            cursor = conn.execute("SELECT COUNT(*) FROM authors")
            stats['authors'] = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(*) FROM works")
            stats['works'] = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(*) FROM sentences")
            stats['sentences'] = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(*) FROM places_master")
            stats['places'] = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(*) FROM sentence_places")
            stats['sentence_places'] = cursor.fetchone()[0]
            
            return stats
    
    def _extract_all_places(self) -> int:
        """å…¨ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã®åœ°åæŠ½å‡º"""
        total_extracted = 0
        
        try:
            # å…¨ã‚»ãƒ³ãƒ†ãƒ³ã‚¹å–å¾—
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("""
                    SELECT s.sentence_id, s.sentence_text, s.before_text, s.after_text, s.work_id, s.author_id
                    FROM sentences s
                    WHERE length(s.sentence_text) > 5
                    ORDER BY s.work_id, s.position_in_work
                """)
                all_sentences = cursor.fetchall()
                
                logger.info(f"ğŸ“ å‡¦ç†å¯¾è±¡ã‚»ãƒ³ãƒ†ãƒ³ã‚¹: {len(all_sentences):,}ä»¶")
            
            # åœ°åæŠ½å‡ºå‡¦ç†
            for i, (sentence_id, sentence_text, before_text, after_text, work_id, author_id) in enumerate(all_sentences):
                if i > 0 and i % 1000 == 0:
                    logger.info(f"  ğŸ“ é€²æ—: {i:,}/{len(all_sentences):,} ({i/len(all_sentences)*100:.1f}%)")
                
                try:
                    # ä½œå“ã®å‡¦ç†
                    result = self.db_manager.process_work(
                        work_id=work_id,
                        text=sentence_text,
                        context_before=before_text,
                        context_after=after_text
                    )
                    
                    if result['success']:
                        total_extracted += len(result['saved_places'])
                        
                        if result['saved_places']:
                            place_names = [p['place_name'] for p in result['saved_places']]
                            logger.info(f"    ğŸ—ºï¸ æŠ½å‡º: {', '.join(place_names)}")
                
                except Exception as e:
                    logger.error(f"    âš ï¸ ã‚»ãƒ³ãƒ†ãƒ³ã‚¹å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
        
        except Exception as e:
            logger.error(f"âŒ åœ°åæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        
        return total_extracted
    
    def _update_all_statistics(self):
        """å…¨çµ±è¨ˆæƒ…å ±ã®æ›´æ–°"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                # ä½œå“ã®çµ±è¨ˆæ›´æ–°
                cursor = conn.execute("SELECT work_id FROM works")
                work_ids = [row[0] for row in cursor.fetchall()]
                
                for work_id in work_ids:
                    try:
                        stats = self.db_manager.get_work_statistics(work_id)
                        if stats:
                            logger.info(f"  ğŸ“š ä½œå“çµ±è¨ˆæ›´æ–°: {stats['work_title']}")
                            logger.info(f"    åœ°åæ•°: {stats['unique_places']}, è¨€åŠå›æ•°: {stats['total_mentions']}")
                    except Exception as e:
                        logger.error(f"    âš ï¸ ä½œå“çµ±è¨ˆæ›´æ–°ã‚¨ãƒ©ãƒ¼ (ID: {work_id}): {e}")
                
                # ä½œè€…ã®çµ±è¨ˆæ›´æ–°
                cursor = conn.execute("SELECT author_id FROM authors")
                author_ids = [row[0] for row in cursor.fetchall()]
                
                for author_id in author_ids:
                    try:
                        stats = self.db_manager.get_author_statistics(author_id)
                        if stats:
                            logger.info(f"  ğŸ‘¤ ä½œè€…çµ±è¨ˆæ›´æ–°: {stats['author_name']}")
                            logger.info(f"    ä½œå“æ•°: {stats['work_count']}, åœ°åæ•°: {stats['unique_places']}")
                    except Exception as e:
                        logger.error(f"    âš ï¸ ä½œè€…çµ±è¨ˆæ›´æ–°ã‚¨ãƒ©ãƒ¼ (ID: {author_id}): {e}")
        
        except Exception as e:
            logger.error(f"âŒ çµ±è¨ˆæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _show_comprehensive_statistics(self):
        """åŒ…æ‹¬çš„çµ±è¨ˆè¡¨ç¤º"""
        with sqlite3.connect(self.db_path) as conn:
            # åŸºæœ¬çµ±è¨ˆ
            final_stats = self._get_current_statistics()
            
            # ä½œå“åˆ¥çµ±è¨ˆ
            cursor = conn.execute("""
                SELECT 
                    a.author_name, w.work_title, w.sentence_count,
                    COUNT(DISTINCT pm.place_id) as unique_places,
                    COUNT(sp.id) as total_mentions
                FROM authors a
                JOIN works w ON a.author_id = w.author_id
                LEFT JOIN sentences s ON w.work_id = s.work_id
                LEFT JOIN sentence_places sp ON s.sentence_id = sp.sentence_id
                LEFT JOIN places_master pm ON sp.place_id = pm.place_id
                GROUP BY a.author_id, w.work_id
                ORDER BY w.created_at DESC
            """)
            work_stats = cursor.fetchall()
            
            # é »å‡ºåœ°åTOP10
            cursor = conn.execute("""
                SELECT 
                    pm.place_name, 
                    pm.canonical_name,
                    pm.place_type,
                    pm.prefecture,
                    pm.mention_count
                FROM places_master pm
                WHERE pm.mention_count > 0
                ORDER BY pm.mention_count DESC
                LIMIT 10
            """)
            top_places = cursor.fetchall()
        
        logger.info("ğŸ“Š æœ€çµ‚çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ")
        logger.info("=" * 60)
        logger.info(f"ğŸ‘¥ ä½œå®¶æ•°: {final_stats['authors']:,}")
        logger.info(f"ğŸ“š ä½œå“æ•°: {final_stats['works']:,}")
        logger.info(f"ğŸ“ ã‚»ãƒ³ãƒ†ãƒ³ã‚¹æ•°: {final_stats['sentences']:,}")
        logger.info(f"ğŸ—ºï¸ ç·åœ°åæ•°: {final_stats['places']:,}")
        logger.info(f"ğŸ”— æ–‡-åœ°åé–¢ä¿‚æ•°: {final_stats['sentence_places']:,}")
        
        logger.info(f"\nğŸ“– ä½œå“åˆ¥åœ°åçµ±è¨ˆ:")
        for author, title, sentences, unique_places, total_mentions in work_stats:
            if unique_places > 0:
                logger.info(f"  â€¢ {author} - {title}: {unique_places}åœ°å, {total_mentions}å›è¨€åŠ")
        
        if top_places:
            logger.info(f"\nğŸ—ºï¸ é »å‡ºåœ°åTOP10:")
            for place_name, canonical_name, place_type, prefecture, count in top_places:
                logger.info(f"  â€¢ {place_name} â†’ {canonical_name}")
                logger.info(f"    ã‚¿ã‚¤ãƒ—: {place_type}")
                if prefecture:
                    logger.info(f"    éƒ½é“åºœçœŒ: {prefecture}")
                logger.info(f"    è¨€åŠå›æ•°: {count}å›")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logger.info("ğŸ—¾ æœ€çµ‚ç‰ˆé’ç©ºæ–‡åº«åœ°åæŠ½å‡º+Geocodingå®Ÿè¡Œ")
    logger.info("=" * 80)
    
    executor = FinalWorkflowExecutor()
    executor.execute_place_extraction_and_geocoding()


if __name__ == "__main__":
    main() 
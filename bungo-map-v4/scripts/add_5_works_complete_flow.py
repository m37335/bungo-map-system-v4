#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ—¾ é’ç©ºæ–‡åº«5ä½œå“è¿½åŠ â†’å®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ

1. é’ç©ºæ–‡åº«ã‹ã‚‰5ä½œå“ã‚’å–å¾—ãƒ»è¿½åŠ 
2. v3ã‚·ã‚¹ãƒ†ãƒ ã§ã‚»ãƒ³ãƒ†ãƒ³ã‚¹åˆ†å‰²
3. v3åœ°åæŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ ã§åœ°åæŠ½å‡º
4. v3 AI Geocodingã§åº§æ¨™å–å¾—

å®Œå…¨ãªæ–‡å­¦åœ°å›³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ãƒ•ãƒ­ãƒ¼
"""

import sys
import os
import sqlite3
import requests
import re
import time
from datetime import datetime
from typing import Dict, List, Any, Optional

# v3ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, '/app')
sys.path.insert(0, '/app/bungo_map')

try:
    # v3ã®å„ªç§€ãªã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    from bungo_map.extractors.aozora_search import AozoraSearcher
    from bungo_map.extractors.aozora_extractor import AozoraExtractor
    from bungo_map.processors.aozora_content_processor import AozoraContentProcessor
    from bungo_map.extractors.simple_place_extractor import SimplePlaceExtractor
    from bungo_map.extractors.enhanced_place_extractor import EnhancedPlaceExtractor
    from bungo_map.ai.context_aware_geocoding import ContextAwareGeocodingService
    V3_AVAILABLE = True
    print("âœ… v3çµ±åˆã‚·ã‚¹ãƒ†ãƒ èª­ã¿è¾¼ã¿æˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ v3ã‚·ã‚¹ãƒ†ãƒ èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
    V3_AVAILABLE = False

class CompleteWorkflowExecutor:
    """é’ç©ºæ–‡åº«â†’å®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, db_path: str = '/app/bungo-map-v4/data/databases/bungo_v4.db'):
        self.db_path = db_path
        
        print("ğŸ”§ å®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
        
        if V3_AVAILABLE:
            # v3ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
            self.searcher = AozoraSearcher()
            self.extractor = AozoraExtractor()
            self.processor = AozoraContentProcessor()
            self.simple_extractor = SimplePlaceExtractor()
            self.enhanced_extractor = EnhancedPlaceExtractor()
            self.ai_geocoding = ContextAwareGeocodingService()
            print("âœ… v3çµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        else:
            print("âŒ v3ã‚·ã‚¹ãƒ†ãƒ åˆ©ç”¨ä¸å¯")
            sys.exit(1)
        
        # è¿½åŠ äºˆå®šã®5ä½œå“
        self.target_works = [
            ('å¤ç›®æ¼±çŸ³', 'ã“ã“ã‚'),
            ('èŠ¥å·é¾ä¹‹ä»‹', 'ç¾…ç”Ÿé–€'),
            ('å¤ªå®°æ²»', 'èµ°ã‚Œãƒ¡ãƒ­ã‚¹'),
            ('å®®æ²¢è³¢æ²»', 'æ³¨æ–‡ã®å¤šã„æ–™ç†åº—'),
            ('æ¨‹å£ä¸€è‘‰', 'ãŸã‘ãã‚‰ã¹')
        ]
    
    def execute_complete_workflow(self):
        """å®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ"""
        print("ğŸš€ é’ç©ºæ–‡åº«â†’å®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œé–‹å§‹")
        print("=" * 80)
        
        # ãƒ•ã‚§ãƒ¼ã‚º1: ä½œå“è¿½åŠ 
        print("\nğŸ“š ãƒ•ã‚§ãƒ¼ã‚º1: é’ç©ºæ–‡åº«ä½œå“è¿½åŠ ")
        print("-" * 50)
        
        added_works = []
        for i, (author_name, work_title) in enumerate(self.target_works, 1):
            print(f"\nğŸ“– {i}/5: {author_name} - {work_title}")
            work_id = self._add_single_work(author_name, work_title)
            if work_id:
                added_works.append((work_id, author_name, work_title))
            time.sleep(1)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
        
        print(f"\nâœ… ãƒ•ã‚§ãƒ¼ã‚º1å®Œäº†: {len(added_works)}ä½œå“è¿½åŠ ")
        
        # ãƒ•ã‚§ãƒ¼ã‚º2: åœ°åæŠ½å‡º
        print("\nğŸ—ºï¸ ãƒ•ã‚§ãƒ¼ã‚º2: åœ°åæŠ½å‡ºå®Ÿè¡Œ")
        print("-" * 50)
        
        total_places = 0
        for work_id, author_name, work_title in added_works:
            print(f"\nğŸ” åœ°åæŠ½å‡º: {work_title}")
            places_count = self._extract_places_for_work(work_id)
            total_places += places_count
            print(f"  âœ… æŠ½å‡ºåœ°åæ•°: {places_count}")
        
        print(f"\nâœ… ãƒ•ã‚§ãƒ¼ã‚º2å®Œäº†: ç·åœ°åæ•° {total_places}")
        
        # ãƒ•ã‚§ãƒ¼ã‚º3: AI Geocoding
        print("\nğŸŒ ãƒ•ã‚§ãƒ¼ã‚º3: AI Geocodingå®Ÿè¡Œ")
        print("-" * 50)
        
        geocoded_count = self._execute_ai_geocoding_for_all()
        print(f"\nâœ… ãƒ•ã‚§ãƒ¼ã‚º3å®Œäº†: {geocoded_count}ä»¶ã®åº§æ¨™å–å¾—")
        
        # æœ€çµ‚çµ±è¨ˆ
        self._show_final_statistics()
        
        print(f"\nğŸ‰ å®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œå®Œäº†ï¼")
    
    def _add_single_work(self, author_name: str, work_title: str) -> Optional[int]:
        """å˜ä¸€ä½œå“ã®è¿½åŠ """
        try:
            # 1. é’ç©ºæ–‡åº«URLæ¤œç´¢
            aozora_url = self.searcher.search_work_url(author_name, work_title)
            if not aozora_url:
                print(f"  âŒ URLæœªç™ºè¦‹")
                return None
            
            print(f"  ğŸ”— URL: {aozora_url}")
            
            # 2. ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            raw_content = self._fetch_text_content(aozora_url)
            if not raw_content or len(raw_content) < 100:
                print(f"  âŒ ãƒ†ã‚­ã‚¹ãƒˆå–å¾—å¤±æ•—")
                return None
            
            print(f"  ğŸ“„ ãƒ†ã‚­ã‚¹ãƒˆ: {len(raw_content):,}æ–‡å­—")
            
            # 3. ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å‡¦ç†
            processed_result = self.processor.process_work_content(0, raw_content)
            if not processed_result['success']:
                print(f"  âŒ å‡¦ç†å¤±æ•—: {processed_result.get('error', 'Unknown')}")
                return None
            
            sentences = processed_result['sentences']
            main_content = processed_result['main_content']
            print(f"  ğŸ“ æ–‡åˆ†å‰²: {len(sentences)}æ–‡")
            
            # 4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¿½åŠ 
            work_id = self._add_to_database(
                author_name, work_title, aozora_url, main_content, sentences
            )
            
            if work_id:
                print(f"  âœ… è¿½åŠ å®Œäº†: work_id={work_id}")
                return work_id
            else:
                print(f"  âŒ DBè¿½åŠ å¤±æ•—")
                return None
                
        except Exception as e:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _fetch_text_content(self, url: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        try:
            # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã®URLã«å¤‰æ›
            if url.endswith('.html') and 'files' not in url:
                # ã‚«ãƒ¼ãƒ‰ãƒšãƒ¼ã‚¸ã‹ã‚‰å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«URLã‚’æ¨æ¸¬
                card_id = url.split('card')[-1].replace('.html', '')
                file_url = url.replace(f'card{card_id}.html', f'files/{card_id}_14560.html')
            else:
                file_url = url
            
            response = requests.get(file_url, timeout=30)
            content = response.content.decode('shift_jis', errors='ignore')
            return content
            
        except Exception as e:
            print(f"    âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def _add_to_database(self, author_name: str, work_title: str, 
                        aozora_url: str, main_content: str, sentences: List[str]) -> Optional[int]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ """
        try:
            with sqlite3.connect(self.db_path) as conn:
                # ä½œå®¶å–å¾—/ä½œæˆ
                author_id = self._get_or_create_author(conn, author_name)
                
                # ä½œå“è¿½åŠ 
                cursor = conn.execute("""
                    INSERT INTO works (title, author_id, aozora_url, content_length, sentence_count, created_at)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (work_title, author_id, aozora_url, len(main_content), len(sentences), datetime.now()))
                
                work_id = cursor.lastrowid
                
                # ã‚»ãƒ³ãƒ†ãƒ³ã‚¹è¿½åŠ 
                for i, sentence_text in enumerate(sentences):
                    if len(sentence_text.strip()) < 5:
                        continue
                    
                    before_text = sentences[i-1] if i > 0 else ""
                    after_text = sentences[i+1] if i < len(sentences)-1 else ""
                    
                    conn.execute("""
                        INSERT INTO sentences (
                            sentence_text, work_id, author_id, before_text, after_text,
                            position_in_work, created_at
                        )
                        VALUES (?, ?, ?, ?, ?, ?, ?)
                    """, (
                        sentence_text.strip(),
                        work_id,
                        author_id,
                        before_text.strip()[:200],
                        after_text.strip()[:200],
                        i + 1,
                        datetime.now()
                    ))
                
                conn.commit()
                return work_id
                
        except Exception as e:
            print(f"    âš ï¸ DBè¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _get_or_create_author(self, conn: sqlite3.Connection, author_name: str) -> int:
        """ä½œå®¶å–å¾—/ä½œæˆ"""
        cursor = conn.execute("SELECT author_id FROM authors WHERE name = ?", (author_name,))
        result = cursor.fetchone()
        
        if result:
            return result[0]
        
        cursor = conn.execute(
            "INSERT INTO authors (name, created_at) VALUES (?, ?)",
            (author_name, datetime.now())
        )
        return cursor.lastrowid
    
    def _extract_places_for_work(self, work_id: int) -> int:
        """ä½œå“ã®åœ°åæŠ½å‡º"""
        total_places = 0
        
        try:
            # ã‚»ãƒ³ãƒ†ãƒ³ã‚¹å–å¾—
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("""
                    SELECT sentence_id, sentence_text, before_text, after_text
                    FROM sentences WHERE work_id = ?
                """, (work_id,))
                sentences = cursor.fetchall()
            
            # åœ°åæŠ½å‡º
            for sentence_id, sentence_text, before_text, after_text in sentences:
                # SimpleæŠ½å‡ºå™¨
                simple_places = self.simple_extractor.extract_places_from_text(work_id, sentence_text)
                
                # EnhancedæŠ½å‡ºå™¨
                enhanced_places = self.enhanced_extractor.extract_places_from_work(work_id, sentence_text)
                
                # å…¨æŠ½å‡ºçµæœ
                all_places = simple_places + enhanced_places
                
                # places_masterã¨sentence_placesã«è¿½åŠ 
                with sqlite3.connect(self.db_path) as conn:
                    for place in all_places:
                        # places_masterã«è¿½åŠ 
                        cursor = conn.execute("""
                            INSERT OR IGNORE INTO places_master (place_name, canonical_name, place_type, confidence)
                            VALUES (?, ?, ?, ?)
                        """, (place.place_name, place.place_name, 'åœ°å', place.confidence))
                        
                        place_id = cursor.lastrowid or conn.execute(
                            "SELECT place_id FROM places_master WHERE place_name = ?", 
                            (place.place_name,)
                        ).fetchone()[0]
                        
                        # sentence_placesã«è¿½åŠ 
                        conn.execute("""
                            INSERT INTO sentence_places (
                                sentence_id, place_id, extraction_method, confidence,
                                context_before, context_after, matched_text, created_at
                            )
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                        """, (
                            sentence_id, place_id, place.extraction_method, place.confidence,
                            before_text, after_text, place.place_name, datetime.now()
                        ))
                        
                        total_places += 1
                    
                    conn.commit()
        
        except Exception as e:
            print(f"    âš ï¸ åœ°åæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        
        return total_places
    
    def _execute_ai_geocoding_for_all(self) -> int:
        """å…¨åœ°åã®AI Geocoding"""
        geocoded_count = 0
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                # æœªå‡¦ç†åœ°åå–å¾—
                cursor = conn.execute("""
                    SELECT place_id, place_name FROM places_master 
                    WHERE latitude IS NULL OR longitude IS NULL
                """)
                places = cursor.fetchall()
                
                print(f"  ğŸ¯ Geocodingå¯¾è±¡: {len(places)}ä»¶")
                
                for place_id, place_name in places:
                    try:
                        # ã‚»ãƒ³ãƒ†ãƒ³ã‚¹æƒ…å ±å–å¾—
                        cursor = conn.execute("""
                            SELECT s.sentence_text, sp.context_before, sp.context_after
                            FROM sentence_places sp
                            JOIN sentences s ON sp.sentence_id = s.sentence_id
                            WHERE sp.place_id = ? LIMIT 1
                        """, (place_id,))
                        
                        context = cursor.fetchone()
                        if context:
                            sentence_text, context_before, context_after = context
                        else:
                            sentence_text = context_before = context_after = ""
                        
                        # AI Geocodingå®Ÿè¡Œ
                        result = self.ai_geocoding.geocode_place_sync(
                            place_name, sentence_text, context_before, context_after
                        )
                        
                        if result and result.latitude is not None:
                            # åº§æ¨™æ›´æ–°
                            conn.execute("""
                                UPDATE places_master 
                                SET latitude = ?, longitude = ?, 
                                    verification_status = 'verified'
                                WHERE place_id = ?
                            """, (result.latitude, result.longitude, place_id))
                            
                            geocoded_count += 1
                            print(f"    ğŸŒ {place_name}: ({result.latitude:.4f}, {result.longitude:.4f})")
                        
                        time.sleep(0.1)  # APIåˆ¶é™
                        
                    except Exception as e:
                        print(f"    âš ï¸ {place_name}: {e}")
                        continue
                
                conn.commit()
        
        except Exception as e:
            print(f"  âŒ Geocodingã‚¨ãƒ©ãƒ¼: {e}")
        
        return geocoded_count
    
    def _show_final_statistics(self):
        """æœ€çµ‚çµ±è¨ˆè¡¨ç¤º"""
        with sqlite3.connect(self.db_path) as conn:
            # åŸºæœ¬çµ±è¨ˆ
            cursor = conn.execute("SELECT COUNT(*) FROM authors")
            authors_count = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(*) FROM works")
            works_count = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(*) FROM sentences")
            sentences_count = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(*) FROM places_master")
            places_count = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(*) FROM sentence_places")
            sentence_places_count = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(*) FROM places_master WHERE latitude IS NOT NULL")
            geocoded_count = cursor.fetchone()[0]
            
            # æœ€æ–°ä½œå“
            cursor = conn.execute("""
                SELECT a.name, w.title, w.sentence_count
                FROM authors a
                JOIN works w ON a.author_id = w.author_id
                ORDER BY w.created_at DESC
                LIMIT 5
            """)
            recent_works = cursor.fetchall()
        
        print(f"\nğŸ“Š å®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œå¾Œã®çµ±è¨ˆ")
        print("=" * 60)
        print(f"ğŸ‘¥ ä½œå®¶æ•°: {authors_count:,}")
        print(f"ğŸ“š ä½œå“æ•°: {works_count:,}")
        print(f"ğŸ“ ã‚»ãƒ³ãƒ†ãƒ³ã‚¹æ•°: {sentences_count:,}")
        print(f"ğŸ—ºï¸ åœ°åæ•°: {places_count:,}")
        print(f"ğŸ”— æ–‡-åœ°åé–¢ä¿‚æ•°: {sentence_places_count:,}")
        print(f"ğŸŒ Geocodingå®Œäº†: {geocoded_count:,}")
        
        if places_count > 0:
            success_rate = (geocoded_count / places_count) * 100
            print(f"ğŸ“ˆ GeocodingæˆåŠŸç‡: {success_rate:.1f}%")
        
        print(f"\nğŸ“– è¿½åŠ ã•ã‚ŒãŸä½œå“:")
        for author, title, sentences in recent_works:
            print(f"  â€¢ {author} - {title} ({sentences:,}æ–‡)")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ—¾ é’ç©ºæ–‡åº«5ä½œå“â†’å®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ")
    print("=" * 80)
    
    executor = CompleteWorkflowExecutor()
    executor.execute_complete_workflow()


if __name__ == "__main__":
    main() 
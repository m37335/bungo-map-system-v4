#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ—¾ é’ç©ºæ–‡åº«5ä½œå“è¿½åŠ â†’å®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œï¼ˆæ”¹è‰¯ç‰ˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¯¾å¿œï¼‰

æ”¹è‰¯ç‰ˆã®ç‰¹å¾´:
- æ”¹è‰¯ç‰ˆãƒ†ã‚­ã‚¹ãƒˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆrubyã‚¿ã‚°ã€HTMLã‚¿ã‚°ã€æ³¨é‡ˆé™¤å»ï¼‰
- v3åœ°åæŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ çµ±åˆ
- AI Geocodingå¯¾å¿œ
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ¶ç´„ã‚¨ãƒ©ãƒ¼ä¿®æ­£
- åŒ…æ‹¬çš„ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
"""

import sys
import sqlite3
import requests
import re
import time
from datetime import datetime
from typing import Dict, List, Any, Optional

# v3ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, '/app')
sys.path.insert(0, '/app/bungo_map')

# v3ã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from bungo_map.extractors.simple_place_extractor import SimplePlaceExtractor
from bungo_map.ai.context_aware_geocoding import ContextAwareGeocodingService

class ImprovedAozora5WorksProcessor:
    """æ”¹è‰¯ç‰ˆé’ç©ºæ–‡åº«5ä½œå“å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, db_path: str = '/app/bungo-map-v4/data/databases/bungo_v4.db'):
        self.db_path = db_path
        
        print("ğŸ—¾ é’ç©ºæ–‡åº«5ä½œå“è¿½åŠ â†’å®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œï¼ˆæ”¹è‰¯ç‰ˆï¼‰")
        print("=" * 80)
        
        # v3ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        self.simple_extractor = SimplePlaceExtractor()
        try:
            self.ai_geocoding = ContextAwareGeocodingService()
            self.geocoding_available = True
            print("âœ… AI Geocodingã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ AI Geocodingã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–å¤±æ•—: {e}")
            self.geocoding_available = False
        
        # å¯¾è±¡ä½œå“ï¼ˆç¢ºå®ŸãªURLä½¿ç”¨ï¼‰
        self.target_works = [
            {
                'author': 'å¤ç›®æ¼±çŸ³',
                'title': 'ã“ã“ã‚',
                'url': 'https://www.aozora.gr.jp/cards/000148/files/773_14560.html'
            },
            {
                'author': 'èŠ¥å·é¾ä¹‹ä»‹',
                'title': 'ç¾…ç”Ÿé–€',
                'url': 'https://www.aozora.gr.jp/cards/000879/files/127_15260.html'
            },
            {
                'author': 'å¤ªå®°æ²»',
                'title': 'èµ°ã‚Œãƒ¡ãƒ­ã‚¹',
                'url': 'https://www.aozora.gr.jp/cards/000035/files/1567_14913.html'
            },
            {
                'author': 'å®®æ²¢è³¢æ²»',
                'title': 'æ³¨æ–‡ã®å¤šã„æ–™ç†åº—',
                'url': 'https://www.aozora.gr.jp/cards/000081/files/43754_17659.html'
            },
            {
                'author': 'æ¨‹å£ä¸€è‘‰',
                'title': 'ãŸã‘ãã‚‰ã¹',
                'url': 'https://www.aozora.gr.jp/cards/000064/files/893_14763.html'
            }
        ]
        
        # æ”¹è‰¯ç‰ˆãƒ†ã‚­ã‚¹ãƒˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.cleanup_patterns = [
            # rubyã‚¿ã‚°ï¼ˆèª­ã¿ä»®åï¼‰ã®é©åˆ‡ãªå‡¦ç†
            (r'<ruby><rb>([^<]+)</rb><rp>[ï¼ˆ(]</rp><rt>([^<]*)</rt><rp>[ï¼‰)]</rp></ruby>', r'\1ï¼ˆ\2ï¼‰'),
            (r'<ruby><rb>([^<]+)</rb><rp>ï¼ˆ</rp><rt>([^<]*)</rt><rp>ï¼‰</rp></ruby>', r'\1ï¼ˆ\2ï¼‰'),
            (r'<ruby>([^<]+)<rt>([^<]*)</rt></ruby>', r'\1ï¼ˆ\2ï¼‰'),
            
            # HTMLã‚¿ã‚°é™¤å»
            (r'<br\s*/?\s*>', ''),
            (r'<[^>]+>', ''),
            
            # é’ç©ºæ–‡åº«æ³¨é‡ˆè¨˜å·é™¤å»
            (r'ã€Š[^ã€‹]*ã€‹', ''),
            (r'ï¼»[^ï¼½]*ï¼½', ''),
            (r'ã€”[^ã€•]*ã€•', ''),
            (r'ï¼»ï¼ƒ[^ï¼½]*ï¼½', ''),
            
            # åº•æœ¬æƒ…å ±é™¤å»
            (r'åº•æœ¬ï¼š[^\n]*\n?', ''),
            (r'å…¥åŠ›ï¼š[^\n]*\n?', ''),
            (r'æ ¡æ­£ï¼š[^\n]*\n?', ''),
            (r'â€»[^\n]*\n?', ''),
            (r'åˆå‡ºï¼š[^\n]*\n?', ''),
            
            # XMLãƒ˜ãƒƒãƒ€ãƒ¼é™¤å»
            (r'<\?xml[^>]*\?>', ''),
            (r'<!DOCTYPE[^>]*>', ''),
            
            # å¤šé‡ç©ºç™½ãƒ»æ”¹è¡Œã®æ­£è¦åŒ–
            (r'\n\s*\n\s*\n+', '\n\n'),
            (r'[ \t]+', ' '),
            (r'ã€€+', 'ã€€'),
        ]
        
        # place_typeãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆCHECKåˆ¶ç´„å¯¾å¿œï¼‰
        self.place_type_mapping = {
            'éƒ½é“åºœçœŒ': 'éƒ½é“åºœçœŒ',
            'å¸‚åŒºç”ºæ‘': 'å¸‚åŒºç”ºæ‘',
            'æœ‰ååœ°å': 'æœ‰ååœ°å',
            'éƒ¡': 'éƒ¡',
            'æ­´å²åœ°å': 'æ­´å²åœ°å',
            'default': 'æœ‰ååœ°å'
        }
        
        print("âœ… æ”¹è‰¯ç‰ˆå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def run_complete_flow(self):
        """å®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ"""
        print(f"\nğŸš€ å®Œå…¨ãƒ•ãƒ­ãƒ¼é–‹å§‹: {len(self.target_works)}ä½œå“å‡¦ç†")
        print("=" * 80)
        
        results = {
            'processed_works': [],
            'total_sentences': 0,
            'total_places': 0,
            'geocoded_places': 0,
            'errors': []
        }
        
        # å„ä½œå“ã‚’é †æ¬¡å‡¦ç†
        for i, work_info in enumerate(self.target_works, 1):
            print(f"\nğŸ“– {i}/{len(self.target_works)}: {work_info['author']} - {work_info['title']}")
            print("-" * 60)
            
            try:
                work_result = self._process_single_work(work_info)
                if work_result:
                    results['processed_works'].append(work_result)
                    results['total_sentences'] += work_result.get('sentences_count', 0)
                    results['total_places'] += work_result.get('places_count', 0)
                    results['geocoded_places'] += work_result.get('geocoded_count', 0)
                else:
                    results['errors'].append(f"{work_info['author']} - {work_info['title']}")
            
            except Exception as e:
                print(f"âŒ ä½œå“å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                results['errors'].append(f"{work_info['author']} - {work_info['title']}: {str(e)}")
            
            time.sleep(1)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
        
        # æœ€çµ‚çµæœãƒ¬ãƒãƒ¼ãƒˆ
        self._generate_final_report(results)
        return results
    
    def _process_single_work(self, work_info: Dict[str, str]) -> Optional[Dict[str, Any]]:
        """å˜ä¸€ä½œå“ã®å®Œå…¨å‡¦ç†"""
        
        # 1. ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
        print(f"  ğŸ“„ ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ä¸­...")
        raw_content = self._fetch_aozora_content(work_info['url'])
        if not raw_content:
            print(f"  âŒ ãƒ†ã‚­ã‚¹ãƒˆå–å¾—å¤±æ•—")
            return None
        
        print(f"  ğŸ“„ ç”Ÿãƒ†ã‚­ã‚¹ãƒˆ: {len(raw_content):,}æ–‡å­—")
        
        # 2. æ”¹è‰¯ç‰ˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        print(f"  ğŸ§¹ æ”¹è‰¯ç‰ˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ...")
        cleaned_content = self._clean_aozora_text(raw_content)
        
        # 3. æ–‡åˆ†å‰²
        sentences = self._split_into_sentences(cleaned_content)
        print(f"  ğŸ“ æ–‡åˆ†å‰²: {len(sentences)}æ–‡")
        
        # 4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ ¼ç´
        print(f"  ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ ¼ç´...")
        work_id = self._store_work_in_database(work_info, cleaned_content, sentences)
        if not work_id:
            print(f"  âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ ¼ç´å¤±æ•—")
            return None
        
        print(f"  âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ ¼ç´: work_id={work_id}")
        
        # 5. åœ°åæŠ½å‡º
        print(f"  ğŸ—ºï¸ åœ°åæŠ½å‡ºå®Ÿè¡Œ...")
        places_count = self._extract_places_for_work(work_id, sentences[:500])  # æœ€å¤§500æ–‡
        print(f"  ğŸ—ºï¸ åœ°åæŠ½å‡ºçµæœ: {places_count}ä»¶")
        
        # 6. AI Geocoding
        geocoded_count = 0
        if self.geocoding_available:
            print(f"  ğŸŒ AI Geocodingå®Ÿè¡Œ...")
            geocoded_count = self._geocode_places_for_work(work_id)
            print(f"  ğŸŒ Geocodingçµæœ: {geocoded_count}ä»¶")
        
        return {
            'work_id': work_id,
            'author': work_info['author'],
            'title': work_info['title'],
            'content_length': len(cleaned_content),
            'sentences_count': len(sentences),
            'places_count': places_count,
            'geocoded_count': geocoded_count
        }
    
    def _clean_aozora_text(self, raw_text: str) -> str:
        """æ”¹è‰¯ç‰ˆé’ç©ºæ–‡åº«ãƒ†ã‚­ã‚¹ãƒˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
        text = raw_text
        original_length = len(text)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°å‡¦ç†
        total_cleaned = 0
        for pattern, replacement in self.cleanup_patterns:
            before_count = len(re.findall(pattern, text))
            text = re.sub(pattern, replacement, text)
            total_cleaned += before_count
        
        # ç‰¹æ®Šæ–‡å­—ã®æ­£è¦åŒ–
        text = text.replace('&nbsp;', ' ')
        text = text.replace('&amp;', '&')
        text = text.replace('&lt;', '<')
        text = text.replace('&gt;', '>')
        
        # å‰å¾Œã®ç©ºç™½é™¤å»
        text = text.strip()
        
        cleaned_length = len(text)
        reduction = original_length - cleaned_length
        print(f"    âœ… ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†: {cleaned_length:,}æ–‡å­—ï¼ˆ{total_cleaned}è¦ç´ , {reduction:,}æ–‡å­—é™¤å»ï¼‰")
        
        return text
    
    def _fetch_aozora_content(self, url: str) -> str:
        """é’ç©ºæ–‡åº«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            
            # Shift_JISã§ãƒ‡ã‚³ãƒ¼ãƒ‰
            content = response.content.decode('shift_jis', errors='ignore')
            
            if len(content) < 1000:
                print(f"    âš ï¸ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒçŸ­ã™ãã¾ã™: {len(content)}æ–‡å­—")
            
            return content
            
        except Exception as e:
            print(f"    âŒ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def _split_into_sentences(self, content: str) -> List[str]:
        """æ–‡åˆ†å‰²å‡¦ç†"""
        # å¥ç‚¹ãƒ»ç–‘å•ç¬¦ãƒ»æ„Ÿå˜†ç¬¦ã§åˆ†å‰²
        sentences = re.split(r'([ã€‚ï¼ï¼Ÿ])', content)
        
        # åˆ†å‰²çµæœã‚’å†æ§‹æˆ
        result = []
        for i in range(0, len(sentences)-1, 2):
            if i+1 < len(sentences):
                sentence = sentences[i] + sentences[i+1]
                sentence = sentence.strip()
                if len(sentence) >= 5:  # çŸ­ã™ãã‚‹æ–‡ã¯é™¤å¤–
                    result.append(sentence)
        
        return result
    
    def _store_work_in_database(self, work_info: Dict[str, str], content: str, sentences: List[str]) -> Optional[int]:
        """ä½œå“ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ ¼ç´"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                # ä½œå®¶å–å¾—/ä½œæˆ
                author_id = self._get_or_create_author(conn, work_info['author'])
                
                # é‡è¤‡ç¢ºèª
                cursor = conn.execute(
                    "SELECT work_id FROM works WHERE title = ? AND author_id = ?",
                    (work_info['title'], author_id)
                )
                existing = cursor.fetchone()
                if existing:
                    print(f"    âš ï¸ æ—¢å­˜ä½œå“ã‚’æ›´æ–°: work_id={existing[0]}")
                    work_id = existing[0]
                    
                    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿å‰Šé™¤
                    conn.execute("DELETE FROM sentence_places WHERE sentence_id IN (SELECT sentence_id FROM sentences WHERE work_id = ?)", (work_id,))
                    conn.execute("DELETE FROM sentences WHERE work_id = ?", (work_id,))
                    
                    # ä½œå“æƒ…å ±æ›´æ–°
                    conn.execute("""
                        UPDATE works 
                        SET aozora_url = ?, content_length = ?, sentence_count = ?, updated_at = ?
                        WHERE work_id = ?
                    """, (work_info['url'], len(content), len(sentences), datetime.now().isoformat(), work_id))
                else:
                    # æ–°è¦ä½œå“è¿½åŠ 
                    cursor = conn.execute("""
                        INSERT INTO works (title, author_id, aozora_url, content_length, sentence_count, created_at)
                        VALUES (?, ?, ?, ?, ?, ?)
                    """, (work_info['title'], author_id, work_info['url'], len(content), len(sentences), datetime.now().isoformat()))
                    work_id = cursor.lastrowid
                
                # ã‚»ãƒ³ãƒ†ãƒ³ã‚¹è¿½åŠ 
                for i, sentence_text in enumerate(sentences):
                    before_text = sentences[i-1] if i > 0 else ""
                    after_text = sentences[i+1] if i < len(sentences)-1 else ""
                    
                    conn.execute("""
                        INSERT INTO sentences (
                            sentence_text, work_id, author_id, before_text, after_text,
                            position_in_work, created_at
                        )
                        VALUES (?, ?, ?, ?, ?, ?, ?)
                    """, (
                        sentence_text, work_id, author_id,
                        before_text[:200], after_text[:200],
                        i + 1, datetime.now().isoformat()
                    ))
                
                conn.commit()
                return work_id
                
        except Exception as e:
            print(f"    âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ ¼ç´ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _get_or_create_author(self, conn: sqlite3.Connection, author_name: str) -> int:
        """ä½œå®¶å–å¾—/ä½œæˆ"""
        cursor = conn.execute("SELECT author_id FROM authors WHERE name = ?", (author_name,))
        result = cursor.fetchone()
        
        if result:
            return result[0]
        
        cursor = conn.execute(
            "INSERT INTO authors (name, created_at) VALUES (?, ?)",
            (author_name, datetime.now().isoformat())
        )
        return cursor.lastrowid
    
    def _extract_places_for_work(self, work_id: int, sentences: List[str]) -> int:
        """ä½œå“ã®åœ°åæŠ½å‡º"""
        total_places = 0
        
        try:
            # ã‚»ãƒ³ãƒ†ãƒ³ã‚¹æƒ…å ±å–å¾—
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("""
                    SELECT sentence_id, sentence_text, before_text, after_text
                    FROM sentences WHERE work_id = ?
                    ORDER BY position_in_work
                    LIMIT ?
                """, (work_id, len(sentences)))
                sentence_records = cursor.fetchall()
            
            # åœ°åæŠ½å‡ºå‡¦ç†
            for sentence_id, sentence_text, before_text, after_text in sentence_records:
                try:
                    places = self.simple_extractor.extract_places_from_text(work_id, sentence_text)
                    
                    if places:
                        with sqlite3.connect(self.db_path) as conn:
                            for place in places:
                                # place_typeæ±ºå®š
                                category = getattr(place, 'category', 'default')
                                place_type = self.place_type_mapping.get(category, 'æœ‰ååœ°å')
                                
                                # places_masterã«è¿½åŠ /å–å¾—
                                cursor = conn.execute(
                                    "SELECT place_id FROM places_master WHERE place_name = ?",
                                    (place.place_name,)
                                )
                                result = cursor.fetchone()
                                
                                if result:
                                    place_id = result[0]
                                else:
                                    cursor = conn.execute("""
                                        INSERT INTO places_master (place_name, canonical_name, place_type, confidence)
                                        VALUES (?, ?, ?, ?)
                                    """, (
                                        place.place_name, place.place_name, place_type,
                                        getattr(place, 'confidence', 0.8)
                                    ))
                                    place_id = cursor.lastrowid
                                
                                # sentence_placesã«è¿½åŠ ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼‰
                                cursor = conn.execute("""
                                    SELECT 1 FROM sentence_places 
                                    WHERE sentence_id = ? AND place_id = ?
                                """, (sentence_id, place_id))
                                
                                if not cursor.fetchone():
                                    conn.execute("""
                                        INSERT INTO sentence_places (
                                            sentence_id, place_id, extraction_method, confidence,
                                            context_before, context_after, matched_text, created_at
                                        )
                                        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                                    """, (
                                        sentence_id, place_id, 'simple',
                                        getattr(place, 'confidence', 0.8),
                                        before_text[:200], after_text[:200], place.place_name,
                                        datetime.now().isoformat()
                                    ))
                                    total_places += 1
                            
                            conn.commit()
                
                except Exception as e:
                    print(f"    âš ï¸ ã‚»ãƒ³ãƒ†ãƒ³ã‚¹åœ°åæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
                    continue
        
        except Exception as e:
            print(f"    âŒ åœ°åæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        
        return total_places
    
    def _geocode_places_for_work(self, work_id: int) -> int:
        """ä½œå“é–¢é€£åœ°åã®Geocoding"""
        if not self.geocoding_available:
            return 0
        
        geocoded_count = 0
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                # ä½œå“é–¢é€£ã®æœªå‡¦ç†åœ°åå–å¾—
                cursor = conn.execute("""
                    SELECT DISTINCT pm.place_id, pm.place_name
                    FROM places_master pm
                    JOIN sentence_places sp ON pm.place_id = sp.place_id
                    JOIN sentences s ON sp.sentence_id = s.sentence_id
                    WHERE s.work_id = ? 
                    AND (pm.latitude IS NULL OR pm.longitude IS NULL)
                    LIMIT 15
                """, (work_id,))
                places_to_geocode = cursor.fetchall()
                
                for place_id, place_name in places_to_geocode:
                    try:
                        # æ–‡è„ˆæƒ…å ±å–å¾—
                        cursor = conn.execute("""
                            SELECT s.sentence_text, sp.context_before, sp.context_after
                            FROM sentences s
                            JOIN sentence_places sp ON s.sentence_id = sp.sentence_id
                            WHERE sp.place_id = ? AND s.work_id = ?
                            ORDER BY sp.confidence DESC
                            LIMIT 1
                        """, (place_id, work_id))
                        
                        context = cursor.fetchone()
                        if context:
                            sentence_text, before_text, after_text = context
                        else:
                            sentence_text = before_text = after_text = ""
                        
                        # AI Geocodingå®Ÿè¡Œ
                        result = self.ai_geocoding.geocode_place_sync(
                            place_name, sentence_text, before_text, after_text
                        )
                        
                        if result and result.latitude is not None:
                            conn.execute("""
                                UPDATE places_master 
                                SET latitude = ?, longitude = ?, verification_status = 'verified'
                                WHERE place_id = ?
                            """, (result.latitude, result.longitude, place_id))
                            
                            geocoded_count += 1
                            print(f"    ğŸŒ {place_name}: ({result.latitude:.4f}, {result.longitude:.4f})")
                        
                        time.sleep(0.2)  # APIåˆ¶é™
                        
                    except Exception as e:
                        print(f"    âš ï¸ Geocodingã‚¨ãƒ©ãƒ¼ ({place_name}): {e}")
                        continue
                
                conn.commit()
        
        except Exception as e:
            print(f"    âŒ Geocodingã‚¨ãƒ©ãƒ¼: {e}")
        
        return geocoded_count
    
    def _generate_final_report(self, results: Dict[str, Any]):
        """æœ€çµ‚çµæœãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print(f"\nğŸ‰ å®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œå®Œäº†!")
        print("=" * 80)
        
        print(f"ğŸ“Š å‡¦ç†çµæœ:")
        print(f"  âœ… å‡¦ç†æˆåŠŸ: {len(results['processed_works'])}ä½œå“")
        print(f"  âŒ å‡¦ç†å¤±æ•—: {len(results['errors'])}ä½œå“")
        print(f"  ğŸ“ ç·ã‚»ãƒ³ãƒ†ãƒ³ã‚¹: {results['total_sentences']:,}")
        print(f"  ğŸ—ºï¸ ç·åœ°åæŠ½å‡º: {results['total_places']:,}")
        print(f"  ğŸŒ ç·Geocoding: {results['geocoded_places']:,}")
        
        if results['total_places'] > 0:
            success_rate = (results['geocoded_places'] / results['total_places']) * 100
            print(f"  ğŸ“ˆ GeocodingæˆåŠŸç‡: {success_rate:.1f}%")
        
        if results['processed_works']:
            print(f"\nğŸ“– å‡¦ç†æ¸ˆã¿ä½œå“:")
            for work in results['processed_works']:
                print(f"  â€¢ {work['author']} - {work['title']}: {work['sentences_count']}æ–‡, {work['places_count']}åœ°å, {work['geocoded_count']}åº§æ¨™")
        
        if results['errors']:
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼:")
            for error in results['errors']:
                print(f"  â€¢ {error}")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆè¡¨ç¤º
        self._show_database_statistics()
    
    def _show_database_statistics(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆè¡¨ç¤º"""
        print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆ:")
        print("-" * 40)
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                # åŸºæœ¬çµ±è¨ˆ
                cursor = conn.execute("SELECT COUNT(*) FROM authors")
                authors_count = cursor.fetchone()[0]
                
                cursor = conn.execute("SELECT COUNT(*) FROM works")
                works_count = cursor.fetchone()[0]
                
                cursor = conn.execute("SELECT COUNT(*) FROM sentences")
                sentences_count = cursor.fetchone()[0]
                
                cursor = conn.execute("SELECT COUNT(*) FROM places_master")
                places_count = cursor.fetchone()[0]
                
                cursor = conn.execute("SELECT COUNT(*) FROM places_master WHERE latitude IS NOT NULL")
                geocoded_count = cursor.fetchone()[0]
                
                # é »å‡ºåœ°åTOP5
                cursor = conn.execute("""
                    SELECT pm.place_name, COUNT(sp.sentence_id) as mention_count
                    FROM places_master pm
                    LEFT JOIN sentence_places sp ON pm.place_id = sp.place_id
                    GROUP BY pm.place_id
                    HAVING mention_count > 0
                    ORDER BY mention_count DESC
                    LIMIT 5
                """)
                top_places = cursor.fetchall()
                
                print(f"  ğŸ‘¥ ä½œå®¶æ•°: {authors_count}")
                print(f"  ğŸ“š ä½œå“æ•°: {works_count}")
                print(f"  ğŸ“ ã‚»ãƒ³ãƒ†ãƒ³ã‚¹æ•°: {sentences_count:,}")
                print(f"  ğŸ—ºï¸ åœ°åæ•°: {places_count}")
                print(f"  ğŸŒ åº§æ¨™ä»˜ãåœ°å: {geocoded_count}")
                
                if top_places:
                    print(f"\nğŸ—ºï¸ é »å‡ºåœ°åTOP5:")
                    for place_name, count in top_places:
                        print(f"  â€¢ {place_name}: {count}å›")
        
        except Exception as e:
            print(f"âŒ çµ±è¨ˆè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    processor = ImprovedAozora5WorksProcessor()
    results = processor.run_complete_flow()
    
    print(f"\nğŸ å…¨å‡¦ç†å®Œäº†!")
    return results


if __name__ == "__main__":
    main()
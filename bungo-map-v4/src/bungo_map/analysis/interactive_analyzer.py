#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–åˆ†ææ©Ÿèƒ½
"""

import sqlite3
from typing import List, Dict, Any, Optional, Set, Tuple
from dataclasses import dataclass
import pandas as pd
import numpy as np
from datetime import datetime
import json
from collections import defaultdict
import logging
from rich.console import Console
from rich.table import Table
from rich.progress import Progress
from rich.prompt import Prompt, Confirm
from rich.panel import Panel

@dataclass
class AnalysisConfig:
    """åˆ†æè¨­å®š"""
    min_mentions: int = 1
    max_places: int = 1000
    time_range: Optional[Tuple[datetime, datetime]] = None
    prefecture_filter: Optional[List[str]] = None
    place_type_filter: Optional[List[str]] = None
    author_filter: Optional[List[str]] = None
    work_filter: Optional[List[str]] = None

class InteractiveAnalyzer:
    """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, db_path: str, config: Optional[AnalysisConfig] = None):
        self.db_path = db_path
        self.config = config or AnalysisConfig()
        self.console = Console()
        self._init_database()
    
    def _init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS analysis_cache (
                    cache_id INTEGER PRIMARY KEY AUTOINCREMENT,
                    analysis_type TEXT,
                    parameters TEXT,
                    results TEXT,
                    created_at TIMESTAMP
                )
            """)
    
    def start_interactive_session(self):
        """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®é–‹å§‹"""
        self.console.print(Panel.fit(
            "ğŸ¯ åœ°ååˆ†æã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³",
            style="bold blue"
        ))
        
        while True:
            self.console.print("\nåˆ©ç”¨å¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰:")
            self.console.print("1. åŸºæœ¬çµ±è¨ˆã®è¡¨ç¤º")
            self.console.print("2. æ™‚ç³»åˆ—åˆ†æ")
            self.console.print("3. åœ°åŸŸåˆ†æ")
            self.console.print("4. ä½œå®¶åˆ¥åˆ†æ")
            self.console.print("5. ä½œå“åˆ¥åˆ†æ")
            self.console.print("6. ã‚«ã‚¹ã‚¿ãƒ åˆ†æ")
            self.console.print("7. è¨­å®šã®å¤‰æ›´")
            self.console.print("8. çµ‚äº†")
            
            choice = Prompt.ask("ã‚³ãƒãƒ³ãƒ‰ã‚’é¸æŠ", choices=["1", "2", "3", "4", "5", "6", "7", "8"])
            
            if choice == "1":
                self._show_basic_statistics()
            elif choice == "2":
                self._analyze_temporal_patterns()
            elif choice == "3":
                self._analyze_regional_patterns()
            elif choice == "4":
                self._analyze_author_patterns()
            elif choice == "5":
                self._analyze_work_patterns()
            elif choice == "6":
                self._run_custom_analysis()
            elif choice == "7":
                self._update_config()
            elif choice == "8":
                if Confirm.ask("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¾ã™ã‹ï¼Ÿ"):
                    break
    
    def _show_basic_statistics(self):
        """åŸºæœ¬çµ±è¨ˆã®è¡¨ç¤º"""
        with sqlite3.connect(self.db_path) as conn:
            # åŸºæœ¬çµ±è¨ˆã®å–å¾—
            stats = self._get_basic_statistics(conn)
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
            table = Table(title="åŸºæœ¬çµ±è¨ˆ")
            table.add_column("æŒ‡æ¨™", style="cyan")
            table.add_column("å€¤", style="green")
            
            for key, value in stats.items():
                table.add_row(key, str(value))
            
            self.console.print(table)
    
    def _analyze_temporal_patterns(self):
        """æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        with sqlite3.connect(self.db_path) as conn:
            # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
            temporal_data = self._get_temporal_data(conn)
            
            # åˆ†æçµæœã®è¡¨ç¤º
            self.console.print("\nğŸ“ˆ æ™‚ç³»åˆ—åˆ†æçµæœ")
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰ã®è¡¨ç¤º
            trend_table = Table(title="ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ")
            trend_table.add_column("æœŸé–“", style="cyan")
            trend_table.add_column("å‚¾å‘", style="green")
            trend_table.add_column("å¤‰åŒ–ç‡", style="yellow")
            
            for period, trend in temporal_data['trends'].items():
                trend_table.add_row(
                    period,
                    trend['direction'],
                    f"{trend['change_rate']:.1f}%"
                )
            
            self.console.print(trend_table)
            
            # å­£ç¯€æ€§ã®è¡¨ç¤º
            if temporal_data['seasonality']:
                self.console.print("\nğŸ“… å­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³")
                season_table = Table()
                season_table.add_column("æœˆ", style="cyan")
                season_table.add_column("è¨€åŠå›æ•°", style="green")
                
                for month, count in temporal_data['seasonality'].items():
                    season_table.add_row(month, str(count))
                
                self.console.print(season_table)
    
    def _analyze_regional_patterns(self):
        """åœ°åŸŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        with sqlite3.connect(self.db_path) as conn:
            # åœ°åŸŸãƒ‡ãƒ¼ã‚¿ã®å–å¾—
            regional_data = self._get_regional_data(conn)
            
            # åˆ†æçµæœã®è¡¨ç¤º
            self.console.print("\nğŸ—¾ åœ°åŸŸåˆ†æçµæœ")
            
            # éƒ½é“åºœçœŒåˆ¥çµ±è¨ˆ
            prefecture_table = Table(title="éƒ½é“åºœçœŒåˆ¥çµ±è¨ˆ")
            prefecture_table.add_column("éƒ½é“åºœçœŒ", style="cyan")
            prefecture_table.add_column("åœ°åæ•°", style="green")
            prefecture_table.add_column("è¨€åŠå›æ•°", style="yellow")
            prefecture_table.add_column("ä¸»è¦åœ°å", style="blue")
            
            for prefecture, data in regional_data['prefectures'].items():
                prefecture_table.add_row(
                    prefecture,
                    str(data['place_count']),
                    str(data['mention_count']),
                    ", ".join(data['top_places'][:3])
                )
            
            self.console.print(prefecture_table)
            
            # åœ°åŸŸã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®è¡¨ç¤º
            if regional_data['clusters']:
                self.console.print("\nğŸ” åœ°åŸŸã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼")
                cluster_table = Table()
                cluster_table.add_column("ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼", style="cyan")
                cluster_table.add_column("ä¸­å¿ƒåœ°", style="green")
                cluster_table.add_column("é–¢é€£åœ°å", style="blue")
                
                for cluster in regional_data['clusters']:
                    cluster_table.add_row(
                        cluster['name'],
                        cluster['center'],
                        ", ".join(cluster['related_places'][:3])
                    )
                
                self.console.print(cluster_table)
    
    def _analyze_author_patterns(self):
        """ä½œå®¶ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        with sqlite3.connect(self.db_path) as conn:
            # ä½œå®¶ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
            author_data = self._get_author_data(conn)
            
            # åˆ†æçµæœã®è¡¨ç¤º
            self.console.print("\nğŸ‘¤ ä½œå®¶åˆ†æçµæœ")
            
            # ä½œå®¶åˆ¥çµ±è¨ˆ
            author_table = Table(title="ä½œå®¶åˆ¥çµ±è¨ˆ")
            author_table.add_column("ä½œå®¶", style="cyan")
            author_table.add_column("ä½œå“æ•°", style="green")
            author_table.add_column("åœ°åæ•°", style="yellow")
            author_table.add_column("ä¸»è¦åœ°å", style="blue")
            
            for author, data in author_data.items():
                author_table.add_row(
                    author,
                    str(data['work_count']),
                    str(data['place_count']),
                    ", ".join(data['top_places'][:3])
                )
            
            self.console.print(author_table)
            
            # ä½œå®¶é–“ã®é¡ä¼¼æ€§
            if author_data['similarities']:
                self.console.print("\nğŸ”„ ä½œå®¶é–“ã®é¡ä¼¼æ€§")
                similarity_table = Table()
                similarity_table.add_column("ä½œå®¶1", style="cyan")
                similarity_table.add_column("ä½œå®¶2", style="green")
                similarity_table.add_column("é¡ä¼¼åº¦", style="yellow")
                
                for sim in author_data['similarities']:
                    similarity_table.add_row(
                        sim['author1'],
                        sim['author2'],
                        f"{sim['similarity']:.2f}"
                    )
                
                self.console.print(similarity_table)
    
    def _analyze_work_patterns(self):
        """ä½œå“ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        with sqlite3.connect(self.db_path) as conn:
            # ä½œå“ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
            work_data = self._get_work_data(conn)
            
            # åˆ†æçµæœã®è¡¨ç¤º
            self.console.print("\nğŸ“š ä½œå“åˆ†æçµæœ")
            
            # ä½œå“åˆ¥çµ±è¨ˆ
            work_table = Table(title="ä½œå“åˆ¥çµ±è¨ˆ")
            work_table.add_column("ä½œå“", style="cyan")
            work_table.add_column("ä½œå®¶", style="green")
            work_table.add_column("åœ°åæ•°", style="yellow")
            work_table.add_column("ä¸»è¦åœ°å", style="blue")
            
            for work, data in work_data.items():
                work_table.add_row(
                    work,
                    data['author'],
                    str(data['place_count']),
                    ", ".join(data['top_places'][:3])
                )
            
            self.console.print(work_table)
            
            # ä½œå“é–“ã®é–¢é€£æ€§
            if work_data['relationships']:
                self.console.print("\nğŸ”— ä½œå“é–“ã®é–¢é€£æ€§")
                relationship_table = Table()
                relationship_table.add_column("ä½œå“1", style="cyan")
                relationship_table.add_column("ä½œå“2", style="green")
                relationship_table.add_column("é–¢é€£åº¦", style="yellow")
                relationship_table.add_column("å…±é€šåœ°å", style="blue")
                
                for rel in work_data['relationships']:
                    relationship_table.add_row(
                        rel['work1'],
                        rel['work2'],
                        f"{rel['relationship']:.2f}",
                        ", ".join(rel['common_places'][:3])
                    )
                
                self.console.print(relationship_table)
    
    def _run_custom_analysis(self):
        """ã‚«ã‚¹ã‚¿ãƒ åˆ†æã®å®Ÿè¡Œ"""
        self.console.print("\nğŸ” ã‚«ã‚¹ã‚¿ãƒ åˆ†æ")
        
        # åˆ†æã‚¿ã‚¤ãƒ—ã®é¸æŠ
        analysis_type = Prompt.ask(
            "åˆ†æã‚¿ã‚¤ãƒ—ã‚’é¸æŠ",
            choices=["æ™‚ç³»åˆ—", "åœ°åŸŸ", "ä½œå®¶", "ä½œå“", "åœ°å"]
        )
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
        params = {}
        if analysis_type == "æ™‚ç³»åˆ—":
            params['start_date'] = Prompt.ask("é–‹å§‹æ—¥ (YYYY-MM-DD)")
            params['end_date'] = Prompt.ask("çµ‚äº†æ—¥ (YYYY-MM-DD)")
        elif analysis_type == "åœ°åŸŸ":
            params['prefecture'] = Prompt.ask("éƒ½é“åºœçœŒ")
        elif analysis_type == "ä½œå®¶":
            params['author'] = Prompt.ask("ä½œå®¶å")
        elif analysis_type == "ä½œå“":
            params['work'] = Prompt.ask("ä½œå“å")
        elif analysis_type == "åœ°å":
            params['place'] = Prompt.ask("åœ°å")
        
        # åˆ†æã®å®Ÿè¡Œ
        with sqlite3.connect(self.db_path) as conn:
            results = self._execute_custom_analysis(conn, analysis_type, params)
            
            # çµæœã®è¡¨ç¤º
            self.console.print("\nğŸ“Š åˆ†æçµæœ")
            self._display_custom_results(results)
    
    def _update_config(self):
        """è¨­å®šã®æ›´æ–°"""
        self.console.print("\nâš™ï¸ è¨­å®šã®æ›´æ–°")
        
        # æœ€å°è¨€åŠå›æ•°
        self.config.min_mentions = int(Prompt.ask(
            "æœ€å°è¨€åŠå›æ•°",
            default=str(self.config.min_mentions)
        ))
        
        # æœ€å¤§åœ°åæ•°
        self.config.max_places = int(Prompt.ask(
            "æœ€å¤§åœ°åæ•°",
            default=str(self.config.max_places)
        ))
        
        # éƒ½é“åºœçœŒãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        if Confirm.ask("éƒ½é“åºœçœŒã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã—ã¾ã™ã‹ï¼Ÿ"):
            prefectures = Prompt.ask("éƒ½é“åºœçœŒï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰").split(",")
            self.config.prefecture_filter = [p.strip() for p in prefectures]
        
        # åœ°åã‚¿ã‚¤ãƒ—ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        if Confirm.ask("åœ°åã‚¿ã‚¤ãƒ—ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã—ã¾ã™ã‹ï¼Ÿ"):
            types = Prompt.ask("åœ°åã‚¿ã‚¤ãƒ—ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰").split(",")
            self.config.place_type_filter = [t.strip() for t in types]
        
        self.console.print("âœ… è¨­å®šã‚’æ›´æ–°ã—ã¾ã—ãŸ")
    
    def _get_basic_statistics(self, conn: sqlite3.Connection) -> Dict[str, Any]:
        """åŸºæœ¬çµ±è¨ˆã®å–å¾—"""
        stats = {}
        
        # åœ°åæ•°
        cursor = conn.execute("SELECT COUNT(*) FROM places_master")
        stats['ç·åœ°åæ•°'] = cursor.fetchone()[0]
        
        # è¨€åŠå›æ•°
        cursor = conn.execute("SELECT COUNT(*) FROM sentence_places")
        stats['ç·è¨€åŠå›æ•°'] = cursor.fetchone()[0]
        
        # ä½œå®¶æ•°
        cursor = conn.execute("SELECT COUNT(*) FROM authors")
        stats['ä½œå®¶æ•°'] = cursor.fetchone()[0]
        
        # ä½œå“æ•°
        cursor = conn.execute("SELECT COUNT(*) FROM works")
        stats['ä½œå“æ•°'] = cursor.fetchone()[0]
        
        return stats
    
    def _get_temporal_data(self, conn: sqlite3.Connection) -> Dict[str, Any]:
        """æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®å–å¾—"""
        data = {
            'trends': {},
            'seasonality': {}
        }
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        cursor = conn.execute("""
            SELECT 
                strftime('%Y-%m', created_at) as month,
                COUNT(*) as count
            FROM sentence_places
            GROUP BY month
            ORDER BY month
        """)
        
        monthly_data = cursor.fetchall()
        if monthly_data:
            # ãƒˆãƒ¬ãƒ³ãƒ‰ã®è¨ˆç®—
            months = [row[0] for row in monthly_data]
            counts = [row[1] for row in monthly_data]
            
            # å…¨ä½“ãƒˆãƒ¬ãƒ³ãƒ‰
            data['trends']['å…¨ä½“'] = {
                'direction': 'ä¸Šæ˜‡' if counts[-1] > counts[0] else 'ä¸‹é™',
                'change_rate': ((counts[-1] - counts[0]) / counts[0] * 100)
            }
            
            # å­£ç¯€æ€§ã®è¨ˆç®—
            for month, count in monthly_data:
                data['seasonality'][month] = count
        
        return data
    
    def _get_regional_data(self, conn: sqlite3.Connection) -> Dict[str, Any]:
        """åœ°åŸŸãƒ‡ãƒ¼ã‚¿ã®å–å¾—"""
        data = {
            'prefectures': {},
            'clusters': []
        }
        
        # éƒ½é“åºœçœŒåˆ¥çµ±è¨ˆ
        cursor = conn.execute("""
            SELECT 
                prefecture,
                COUNT(DISTINCT place_id) as place_count,
                COUNT(*) as mention_count
            FROM places_master
            GROUP BY prefecture
        """)
        
        for row in cursor.fetchall():
            prefecture = row[0]
            data['prefectures'][prefecture] = {
                'place_count': row[1],
                'mention_count': row[2],
                'top_places': self._get_top_places(conn, prefecture)
            }
        
        return data
    
    def _get_author_data(self, conn: sqlite3.Connection) -> Dict[str, Any]:
        """ä½œå®¶ãƒ‡ãƒ¼ã‚¿ã®å–å¾—"""
        data = {}
        
        # ä½œå®¶åˆ¥çµ±è¨ˆ
        cursor = conn.execute("""
            SELECT 
                a.author_name,
                COUNT(DISTINCT w.work_id) as work_count,
                COUNT(DISTINCT pm.place_id) as place_count
            FROM authors a
            JOIN works w ON a.author_id = w.author_id
            JOIN sentences s ON w.work_id = s.work_id
            JOIN sentence_places sp ON s.sentence_id = sp.sentence_id
            JOIN places_master pm ON sp.place_id = pm.place_id
            GROUP BY a.author_id
        """)
        
        for row in cursor.fetchall():
            author = row[0]
            data[author] = {
                'work_count': row[1],
                'place_count': row[2],
                'top_places': self._get_author_top_places(conn, author)
            }
        
        return data
    
    def _get_work_data(self, conn: sqlite3.Connection) -> Dict[str, Any]:
        """ä½œå“ãƒ‡ãƒ¼ã‚¿ã®å–å¾—"""
        data = {}
        
        # ä½œå“åˆ¥çµ±è¨ˆ
        cursor = conn.execute("""
            SELECT 
                w.work_title,
                a.author_name,
                COUNT(DISTINCT pm.place_id) as place_count
            FROM works w
            JOIN authors a ON w.author_id = a.author_id
            JOIN sentences s ON w.work_id = s.work_id
            JOIN sentence_places sp ON s.sentence_id = sp.sentence_id
            JOIN places_master pm ON sp.place_id = pm.place_id
            GROUP BY w.work_id
        """)
        
        for row in cursor.fetchall():
            work = row[0]
            data[work] = {
                'author': row[1],
                'place_count': row[2],
                'top_places': self._get_work_top_places(conn, work)
            }
        
        return data
    
    def _get_top_places(self, conn: sqlite3.Connection, prefecture: str) -> List[str]:
        """éƒ½é“åºœçœŒã®ä¸»è¦åœ°åã‚’å–å¾—"""
        cursor = conn.execute("""
            SELECT place_name
            FROM places_master
            WHERE prefecture = ?
            ORDER BY mention_count DESC
            LIMIT 5
        """, (prefecture,))
        
        return [row[0] for row in cursor.fetchall()]
    
    def _get_author_top_places(self, conn: sqlite3.Connection, author: str) -> List[str]:
        """ä½œå®¶ã®ä¸»è¦åœ°åã‚’å–å¾—"""
        cursor = conn.execute("""
            SELECT pm.place_name
            FROM places_master pm
            JOIN sentence_places sp ON pm.place_id = sp.place_id
            JOIN sentences s ON sp.sentence_id = s.sentence_id
            JOIN works w ON s.work_id = w.work_id
            JOIN authors a ON w.author_id = a.author_id
            WHERE a.author_name = ?
            GROUP BY pm.place_id
            ORDER BY COUNT(*) DESC
            LIMIT 5
        """, (author,))
        
        return [row[0] for row in cursor.fetchall()]
    
    def _get_work_top_places(self, conn: sqlite3.Connection, work: str) -> List[str]:
        """ä½œå“ã®ä¸»è¦åœ°åã‚’å–å¾—"""
        cursor = conn.execute("""
            SELECT pm.place_name
            FROM places_master pm
            JOIN sentence_places sp ON pm.place_id = sp.place_id
            JOIN sentences s ON sp.sentence_id = s.sentence_id
            JOIN works w ON s.work_id = w.work_id
            WHERE w.work_title = ?
            GROUP BY pm.place_id
            ORDER BY COUNT(*) DESC
            LIMIT 5
        """, (work,))
        
        return [row[0] for row in cursor.fetchall()]
    
    def _execute_custom_analysis(self, conn: sqlite3.Connection,
                               analysis_type: str,
                               params: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚«ã‚¹ã‚¿ãƒ åˆ†æã®å®Ÿè¡Œ"""
        results = {}
        
        if analysis_type == "æ™‚ç³»åˆ—":
            cursor = conn.execute("""
                SELECT 
                    strftime('%Y-%m', created_at) as month,
                    COUNT(*) as count
                FROM sentence_places
                WHERE created_at BETWEEN ? AND ?
                GROUP BY month
                ORDER BY month
            """, (params['start_date'], params['end_date']))
            
            results['data'] = cursor.fetchall()
            
        elif analysis_type == "åœ°åŸŸ":
            cursor = conn.execute("""
                SELECT 
                    place_name,
                    COUNT(*) as mention_count
                FROM places_master
                WHERE prefecture = ?
                GROUP BY place_id
                ORDER BY mention_count DESC
            """, (params['prefecture'],))
            
            results['data'] = cursor.fetchall()
            
        elif analysis_type == "ä½œå®¶":
            cursor = conn.execute("""
                SELECT 
                    pm.place_name,
                    COUNT(*) as mention_count
                FROM places_master pm
                JOIN sentence_places sp ON pm.place_id = sp.place_id
                JOIN sentences s ON sp.sentence_id = s.sentence_id
                JOIN works w ON s.work_id = w.work_id
                JOIN authors a ON w.author_id = a.author_id
                WHERE a.author_name = ?
                GROUP BY pm.place_id
                ORDER BY mention_count DESC
            """, (params['author'],))
            
            results['data'] = cursor.fetchall()
            
        elif analysis_type == "ä½œå“":
            cursor = conn.execute("""
                SELECT 
                    pm.place_name,
                    COUNT(*) as mention_count
                FROM places_master pm
                JOIN sentence_places sp ON pm.place_id = sp.place_id
                JOIN sentences s ON sp.sentence_id = s.sentence_id
                JOIN works w ON s.work_id = w.work_id
                WHERE w.work_title = ?
                GROUP BY pm.place_id
                ORDER BY mention_count DESC
            """, (params['work'],))
            
            results['data'] = cursor.fetchall()
            
        elif analysis_type == "åœ°å":
            cursor = conn.execute("""
                SELECT 
                    w.work_title,
                    a.author_name,
                    COUNT(*) as mention_count
                FROM places_master pm
                JOIN sentence_places sp ON pm.place_id = sp.place_id
                JOIN sentences s ON sp.sentence_id = s.sentence_id
                JOIN works w ON s.work_id = w.work_id
                JOIN authors a ON w.author_id = a.author_id
                WHERE pm.place_name = ?
                GROUP BY w.work_id
                ORDER BY mention_count DESC
            """, (params['place'],))
            
            results['data'] = cursor.fetchall()
        
        return results
    
    def _display_custom_results(self, results: Dict[str, Any]):
        """ã‚«ã‚¹ã‚¿ãƒ åˆ†æçµæœã®è¡¨ç¤º"""
        if not results.get('data'):
            self.console.print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
        table = Table()
        
        # ã‚«ãƒ©ãƒ ã®è¿½åŠ 
        for col in results['data'][0].keys():
            table.add_column(col, style="cyan")
        
        # ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ 
        for row in results['data']:
            table.add_row(*[str(val) for val in row])
        
        self.console.print(table) 
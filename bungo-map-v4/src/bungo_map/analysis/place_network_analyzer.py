#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åœ°åã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†ææ©Ÿèƒ½
"""

import sqlite3
from typing import List, Dict, Any, Optional, Set, Tuple
from dataclasses import dataclass
from collections import defaultdict
import networkx as nx
import numpy as np
from datetime import datetime
import json

@dataclass
class NetworkNode:
    """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒãƒ¼ãƒ‰æƒ…å ±"""
    place_id: int
    place_name: str
    canonical_name: str
    degree: int
    betweenness: float
    pagerank: float
    cluster: Optional[int] = None

@dataclass
class NetworkEdge:
    """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒƒã‚¸æƒ…å ±"""
    source_id: int
    target_id: int
    weight: float
    relation_type: str
    context: str

@dataclass
class NetworkStats:
    """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çµ±è¨ˆæƒ…å ±"""
    total_nodes: int
    total_edges: int
    average_degree: float
    density: float
    average_clustering: float
    diameter: float
    communities: List[Set[str]]

class PlaceNetworkAnalyzer:
    """åœ°åã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self._init_database()
        self.graph = nx.Graph()
    
    def _init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS place_networks (
                    network_id INTEGER PRIMARY KEY AUTOINCREMENT,
                    name TEXT,
                    description TEXT,
                    created_at TIMESTAMP,
                    nodes TEXT,
                    edges TEXT,
                    stats TEXT
                )
            """)
    
    def build_network(self, min_weight: float = 0.1) -> nx.Graph:
        """
        åœ°åãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰
        
        Args:
            min_weight: ã‚¨ãƒƒã‚¸ã®æœ€å°é‡ã¿
            
        Returns:
            æ§‹ç¯‰ã•ã‚ŒãŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
        """
        with sqlite3.connect(self.db_path) as conn:
            # åœ°åãƒãƒ¼ãƒ‰ã®å–å¾—
            cursor = conn.execute("""
                SELECT 
                    pm.place_id,
                    pm.place_name,
                    pm.canonical_name,
                    pm.mention_count
                FROM places_master pm
                WHERE pm.mention_count > 0
            """)
            
            for row in cursor.fetchall():
                self.graph.add_node(
                    row[0],
                    place_name=row[1],
                    canonical_name=row[2],
                    mention_count=row[3]
                )
            
            # é–¢ä¿‚æ€§ã‚¨ãƒƒã‚¸ã®å–å¾—
            cursor = conn.execute("""
                SELECT 
                    source_place_id,
                    target_place_id,
                    strength,
                    relation_type,
                    context
                FROM place_relations
                WHERE strength >= ?
            """, (min_weight,))
            
            for row in cursor.fetchall():
                self.graph.add_edge(
                    row[0],
                    row[1],
                    weight=row[2],
                    relation_type=row[3],
                    context=row[4]
                )
        
        return self.graph
    
    def analyze_network(self) -> NetworkStats:
        """
        ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®åˆ†æã‚’å®Ÿè¡Œ
        
        Returns:
            ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çµ±è¨ˆæƒ…å ±
        """
        if not self.graph.nodes():
            self.build_network()
        
        # åŸºæœ¬çµ±è¨ˆã®è¨ˆç®—
        total_nodes = self.graph.number_of_nodes()
        total_edges = self.graph.number_of_edges()
        average_degree = sum(dict(self.graph.degree()).values()) / total_nodes
        density = nx.density(self.graph)
        average_clustering = nx.average_clustering(self.graph)
        
        # ç›´å¾„ã®è¨ˆç®—ï¼ˆæœ€å¤§æœ€çŸ­çµŒè·¯é•·ï¼‰
        try:
            diameter = nx.diameter(self.graph)
        except nx.NetworkXError:
            diameter = float('inf')
        
        # ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œå‡º
        communities = list(nx.community.greedy_modularity_communities(self.graph))
        
        return NetworkStats(
            total_nodes=total_nodes,
            total_edges=total_edges,
            average_degree=average_degree,
            density=density,
            average_clustering=average_clustering,
            diameter=diameter,
            communities=communities
        )
    
    def get_central_places(self, top_n: int = 10) -> List[NetworkNode]:
        """
        ä¸­å¿ƒçš„ãªåœ°åã‚’å–å¾—
        
        Args:
            top_n: å–å¾—ã™ã‚‹åœ°åã®æ•°
            
        Returns:
            ä¸­å¿ƒçš„ãªåœ°åã®ãƒªã‚¹ãƒˆ
        """
        if not self.graph.nodes():
            self.build_network()
        
        # ä¸­å¿ƒæ€§æŒ‡æ¨™ã®è¨ˆç®—
        degree_centrality = nx.degree_centrality(self.graph)
        betweenness_centrality = nx.betweenness_centrality(self.graph)
        pagerank = nx.pagerank(self.graph)
        
        # ç·åˆã‚¹ã‚³ã‚¢ã®è¨ˆç®—
        scores = {}
        for node in self.graph.nodes():
            scores[node] = (
                degree_centrality[node] +
                betweenness_centrality[node] +
                pagerank[node]
            ) / 3
        
        # ä¸Šä½ãƒãƒ¼ãƒ‰ã®å–å¾—
        top_nodes = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_n]
        
        return [
            NetworkNode(
                place_id=node_id,
                place_name=self.graph.nodes[node_id]['place_name'],
                canonical_name=self.graph.nodes[node_id]['canonical_name'],
                degree=self.graph.degree(node_id),
                betweenness=betweenness_centrality[node_id],
                pagerank=pagerank[node_id]
            )
            for node_id, _ in top_nodes
        ]
    
    def get_related_places(self, place_id: int, max_distance: int = 2) -> List[NetworkNode]:
        """
        é–¢é€£ã™ã‚‹åœ°åã‚’å–å¾—
        
        Args:
            place_id: å¯¾è±¡ã®åœ°åID
            max_distance: æœ€å¤§è·é›¢
            
        Returns:
            é–¢é€£ã™ã‚‹åœ°åã®ãƒªã‚¹ãƒˆ
        """
        if not self.graph.nodes():
            self.build_network()
        
        if place_id not in self.graph:
            return []
        
        # æŒ‡å®šè·é›¢ä»¥å†…ã®ãƒãƒ¼ãƒ‰ã‚’å–å¾—
        related_nodes = set()
        for distance in range(1, max_distance + 1):
            related_nodes.update(
                node for node in self.graph.nodes()
                if nx.shortest_path_length(self.graph, place_id, node) == distance
            )
        
        return [
            NetworkNode(
                place_id=node_id,
                place_name=self.graph.nodes[node_id]['place_name'],
                canonical_name=self.graph.nodes[node_id]['canonical_name'],
                degree=self.graph.degree(node_id),
                betweenness=nx.betweenness_centrality(self.graph)[node_id],
                pagerank=nx.pagerank(self.graph)[node_id]
            )
            for node_id in related_nodes
        ]
    
    def save_network(self, name: str, description: str = ""):
        """
        ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä¿å­˜
        
        Args:
            name: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å
            description: èª¬æ˜
        """
        if not self.graph.nodes():
            self.build_network()
        
        # ãƒãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ã®æƒ…å ±ã‚’JSONå½¢å¼ã«å¤‰æ›
        nodes = {
            str(node): {
                'place_name': self.graph.nodes[node]['place_name'],
                'canonical_name': self.graph.nodes[node]['canonical_name'],
                'mention_count': self.graph.nodes[node]['mention_count']
            }
            for node in self.graph.nodes()
        }
        
        edges = [
            {
                'source': str(edge[0]),
                'target': str(edge[1]),
                'weight': self.graph.edges[edge]['weight'],
                'relation_type': self.graph.edges[edge]['relation_type'],
                'context': self.graph.edges[edge]['context']
            }
            for edge in self.graph.edges()
        ]
        
        # çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—
        stats = self.analyze_network()
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT INTO place_networks
                (name, description, created_at, nodes, edges, stats)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (
                name,
                description,
                datetime.now(),
                json.dumps(nodes),
                json.dumps(edges),
                json.dumps({
                    'total_nodes': stats.total_nodes,
                    'total_edges': stats.total_edges,
                    'average_degree': stats.average_degree,
                    'density': stats.density,
                    'average_clustering': stats.average_clustering,
                    'diameter': stats.diameter
                })
            ))
    
    def generate_network_report(self, stats: NetworkStats) -> str:
        """
        ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
        
        Args:
            stats: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çµ±è¨ˆæƒ…å ±
            
        Returns:
            ãƒ¬ãƒãƒ¼ãƒˆæ–‡å­—åˆ—
        """
        report = []
        report.append("ğŸ“Š ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        report.append("=" * 40)
        
        report.append("\nåŸºæœ¬çµ±è¨ˆ:")
        report.append(f"- ãƒãƒ¼ãƒ‰æ•°: {stats.total_nodes:,}")
        report.append(f"- ã‚¨ãƒƒã‚¸æ•°: {stats.total_edges:,}")
        report.append(f"- å¹³å‡æ¬¡æ•°: {stats.average_degree:.2f}")
        report.append(f"- å¯†åº¦: {stats.density:.4f}")
        report.append(f"- å¹³å‡ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä¿‚æ•°: {stats.average_clustering:.4f}")
        report.append(f"- ç›´å¾„: {stats.diameter}")
        
        report.append("\nã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£:")
        for i, community in enumerate(stats.communities, 1):
            report.append(f"\nã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ {i}:")
            for place in sorted(community):
                report.append(f"- {place}")
        
        return "\n".join(report) 
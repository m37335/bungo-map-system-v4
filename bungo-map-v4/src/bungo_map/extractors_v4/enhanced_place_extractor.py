#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¼·åŒ–ç‰ˆåœ°åæŠ½å‡ºå™¨ v4
v3ã‹ã‚‰ã®ç§»æ¤ãƒ»æ”¹è‰¯ç‰ˆ - æ­£è¦è¡¨ç¾å¼·åŒ–ã‚·ã‚¹ãƒ†ãƒ 
"""

import re
import logging
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class EnhancedPlace:
    """å¼·åŒ–ç‰ˆåœ°åãƒ‡ãƒ¼ã‚¿"""
    work_id: int
    place_name: str
    sentence: str
    before_text: str = ""
    after_text: str = ""
    sentence_index: int = 0
    char_position: int = 0
    confidence: float = 0.0
    extraction_method: str = "enhanced_regex"
    aozora_url: str = ""

class EnhancedPlaceExtractor:
    """å¼·åŒ–ç‰ˆåœ°åæŠ½å‡ºå™¨ v4 - æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³å¼·åŒ–"""
    
    def __init__(self):
        self.patterns = self._build_enhanced_patterns()
        logger.info("ğŸ—ºï¸ å¼·åŒ–ç‰ˆåœ°åæŠ½å‡ºå™¨v4åˆæœŸåŒ–å®Œäº†")
    
    def _build_enhanced_patterns(self) -> List[Dict]:
        """å¼·åŒ–ã•ã‚ŒãŸåœ°åæŠ½å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³"""
        return [
            # 1. éƒ½é“åºœçœŒï¼ˆå¢ƒç•Œæ¡ä»¶å¼·åŒ–ï¼‰
            {
                'pattern': r'(?<![ä¸€-é¾¯])[åŒ—æµ·é’æ£®å²©æ‰‹å®®åŸç§‹ç”°å±±å½¢ç¦å³¶èŒ¨åŸæ ƒæœ¨ç¾¤é¦¬åŸ¼ç‰åƒè‘‰æ±äº¬ç¥å¥ˆå·æ–°æ½Ÿå¯Œå±±çŸ³å·ç¦äº•å±±æ¢¨é•·é‡å²é˜œé™å²¡æ„›çŸ¥ä¸‰é‡æ»‹è³€äº¬éƒ½å¤§é˜ªå…µåº«å¥ˆè‰¯å’Œæ­Œå±±é³¥å–å³¶æ ¹å²¡å±±åºƒå³¶å±±å£å¾³å³¶é¦™å·æ„›åª›é«˜çŸ¥ç¦å²¡ä½è³€é•·å´ç†Šæœ¬å¤§åˆ†å®®å´é¹¿å…å³¶æ²–ç¸„][éƒ½é“åºœçœŒ](?![ä¸€-é¾¯])',
                'category': 'éƒ½é“åºœçœŒ',
                'confidence': 0.95,
                'priority': 1
            },
            
            # 2. å®Œå…¨åœ°åï¼ˆéƒ½é“åºœçœŒ+å¸‚åŒºç”ºæ‘ï¼‰ - æœ€é«˜å„ªå…ˆåº¦
            {
                'pattern': r'(?<![ä¸€-é¾¯])[åŒ—æµ·é’æ£®å²©æ‰‹å®®åŸç§‹ç”°å±±å½¢ç¦å³¶èŒ¨åŸæ ƒæœ¨ç¾¤é¦¬åŸ¼ç‰åƒè‘‰æ±äº¬ç¥å¥ˆå·æ–°æ½Ÿå¯Œå±±çŸ³å·ç¦äº•å±±æ¢¨é•·é‡å²é˜œé™å²¡æ„›çŸ¥ä¸‰é‡æ»‹è³€äº¬éƒ½å¤§é˜ªå…µåº«å¥ˆè‰¯å’Œæ­Œå±±é³¥å–å³¶æ ¹å²¡å±±åºƒå³¶å±±å£å¾³å³¶é¦™å·æ„›åª›é«˜çŸ¥ç¦å²¡ä½è³€é•·å´ç†Šæœ¬å¤§åˆ†å®®å´é¹¿å…å³¶æ²–ç¸„][éƒ½é“åºœçœŒ][ä¸€-é¾¯]{2,8}[å¸‚åŒºç”ºæ‘](?![ä¸€-é¾¯])',
                'category': 'å®Œå…¨åœ°å',
                'confidence': 0.98,
                'priority': 0
            },
            
            # 3. å¸‚åŒºç”ºæ‘ï¼ˆå¢ƒç•Œæ¡ä»¶å¼·åŒ–ï¼‰
            {
                'pattern': r'(?<![ä¸€-é¾¯])[ä¸€-é¾¯]{2,6}[å¸‚åŒºç”ºæ‘](?![ä¸€-é¾¯])',
                'category': 'å¸‚åŒºç”ºæ‘',
                'confidence': 0.85,
                'priority': 2
            },
            
            # 4. æœ‰ååœ°åï¼ˆæ˜ç¤ºãƒªã‚¹ãƒˆï¼‰
            {
                'pattern': r'(?:' + '|'.join([
                    'éŠ€åº§', 'æ–°å®¿', 'æ¸‹è°·', 'ä¸Šé‡', 'æµ…è‰', 'å“å·', 'æ± è¢‹', 'æ–°æ©‹', 'æœ‰æ¥½ç”º',
                    'æ¨ªæµœ', 'å·å´', 'åƒè‘‰', 'èˆ¹æ©‹', 'æŸ', 'éŒå€‰', 'æ¹˜å—', 'ç®±æ ¹',
                    'äº¬éƒ½', 'å¤§é˜ª', 'ç¥æˆ¸', 'å¥ˆè‰¯', 'æ±Ÿæˆ¸', 'æœ¬éƒ·', 'ç¥ç”°', 'æ—¥æœ¬æ©‹',
                    'æ´¥è»½', 'æ¾å±±', 'å››å›½', 'ä¹å·', 'æœ¬å·', 'åŒ—æµ·é“'
                ]) + r')',
                'category': 'æœ‰ååœ°å',
                'confidence': 0.90,
                'priority': 3
            },
            
            # 5. è‡ªç„¶åœ°åãƒ‘ã‚¿ãƒ¼ãƒ³
            {
                'pattern': r'(?<![ä¸€-é¾¯])[ä¸€-é¾¯]{1,4}[å·å±±æ¹–æµ·å³ è°·é‡åŸå³¶å²¬æµ¦å´](?![ä¸€-é¾¯])',
                'category': 'è‡ªç„¶åœ°å',
                'confidence': 0.80,
                'priority': 4
            }
        ]
    
    def extract_places(self, text: str) -> List[EnhancedPlace]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰åœ°åã‚’æŠ½å‡ºï¼ˆãƒ¡ã‚¤ãƒ³æ©Ÿèƒ½ï¼‰"""
        if not text or len(text) < 10:
            logger.warning(f"ãƒ†ã‚­ã‚¹ãƒˆãŒçŸ­ã™ãã¾ã™: {len(text)}æ–‡å­—")
            return []
        all_matches = []
        sentences = self._split_into_sentences(text)
        logger.info(f"ğŸ“„ æ–‡æ•°: {len(sentences)}, æ–‡å­—æ•°: {len(text)}")
        for sentence_idx, sentence in enumerate(sentences):
            sentence_matches = self._extract_from_sentence(
                sentence, sentence_idx, sentences
            )
            # é‡è¤‡æ’é™¤å‡¦ç†
            deduplicated_matches = self._deduplicate_overlapping_matches(sentence_matches)
            all_matches.extend(deduplicated_matches)
        # EnhancedPlaceã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
        places = []
        for match in all_matches:
            place = EnhancedPlace(
                work_id=0,  # work_idã¯ä½¿ã‚ãªã„
                place_name=match['text'],
                sentence=match['sentence'],
                before_text=match['before_text'][:300],
                after_text=match['after_text'][:300],
                sentence_index=match.get('sentence_index', 0),
                char_position=match.get('start', 0),
                confidence=match['confidence'],
                extraction_method=f"enhanced_{match['category']}",
                aozora_url=""
            )
            places.append(place)
        logger.info(f"âœ… åœ°åæŠ½å‡ºå®Œäº†: {len(places)}ä»¶")
        return places
    
    def _extract_from_sentence(self, sentence: str, sentence_idx: int, sentences: List[str]) -> List[Dict]:
        """å˜ä¸€æ–‡ã‹ã‚‰ã®åœ°åæŠ½å‡º"""
        matches = []
        
        for pattern_info in self.patterns:
            pattern_matches = list(re.finditer(pattern_info['pattern'], sentence))
            
            for match in pattern_matches:
                place_name = match.group(0)
                
                # å‰å¾Œã®æ–‡è„ˆå–å¾—
                before_text = sentences[sentence_idx - 1] if sentence_idx > 0 else ""
                after_text = sentences[sentence_idx + 1] if sentence_idx < len(sentences) - 1 else ""
                
                matches.append({
                    'text': place_name,
                    'start': match.start(),
                    'end': match.end(),
                    'sentence': sentence,
                    'before_text': before_text,
                    'after_text': after_text,
                    'sentence_index': sentence_idx,
                    'category': pattern_info['category'],
                    'confidence': pattern_info['confidence'],
                    'priority': pattern_info['priority']
                })
        
        return matches
    
    def _deduplicate_overlapping_matches(self, matches: List[Dict]) -> List[Dict]:
        """é‡è¤‡ã™ã‚‹åœ°åã®æ’é™¤"""
        if not matches:
            return []
        
        # å„ªå…ˆåº¦é †ã§ã‚½ãƒ¼ãƒˆï¼ˆpriority 0ãŒæœ€é«˜å„ªå…ˆåº¦ï¼‰
        matches.sort(key=lambda x: (x['priority'], -x['confidence'], -len(x['text'])))
        
        deduplicated = []
        used_ranges = []
        
        for match in matches:
            match_range = (match['start'], match['end'])
            
            # æ—¢ã«ä½¿ç”¨ã•ã‚ŒãŸç¯„å›²ã¨é‡è¤‡ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            is_overlapping = any(
                self._ranges_overlap(match_range, used_range) 
                for used_range in used_ranges
            )
            
            if not is_overlapping:
                deduplicated.append(match)
                used_ranges.append(match_range)
        
        return deduplicated
    
    def _ranges_overlap(self, range1: Tuple[int, int], range2: Tuple[int, int]) -> bool:
        """2ã¤ã®ç¯„å›²ãŒé‡è¤‡ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        start1, end1 = range1
        start2, end2 = range2
        return not (end1 <= start2 or end2 <= start1)
    
    def _split_into_sentences(self, text: str) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’æ–‡ã«åˆ†å‰²"""
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
        return [s.strip() for s in sentences if s.strip()]
    
    def test_extraction(self, test_text: str) -> Dict:
        """æŠ½å‡ºæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ§ª Enhanced Place Extractor ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        places = self.extract_places(test_text)
        
        # çµ±è¨ˆä½œæˆ
        categories = {}
        for place in places:
            method = place.extraction_method
            categories[method] = categories.get(method, 0) + 1
        
        return {
            'test_text_length': len(test_text),
            'total_places': len(places),
            'places': [
                {
                    'name': place.place_name,
                    'confidence': place.confidence,
                    'method': place.extraction_method,
                    'sentence': place.sentence[:50] + '...' if len(place.sentence) > 50 else place.sentence
                }
                for place in places[:10]  # æœ€åˆã®10ä»¶ã®ã¿
            ],
            'categories': categories,
            'success': len(places) > 0
        }

if __name__ == "__main__":
    # ç°¡å˜ãªãƒ†ã‚¹ãƒˆ
    extractor = EnhancedPlaceExtractor()
    
    test_text = """
    ç§ã¯æ±äº¬éƒ½æ–°å®¿åŒºã«ä½ã‚“ã§ã„ã¾ã™ã€‚
    éŒå€‰ã®å¤§ä»ã‚’è¦‹ã«è¡Œãã¾ã—ãŸã€‚
    æ´¥è»½æµ·å³¡ã‚’æ¸¡ã£ã¦åŒ—æµ·é“ã«å‘ã‹ã„ã¾ã—ãŸã€‚
    """
    
    result = extractor.test_extraction(test_text)
    
    print("âœ… Enhanced Place Extractor v4 ãƒ†ã‚¹ãƒˆå®Œäº†")
    print(f"ğŸ“Š æŠ½å‡ºåœ°åæ•°: {result['total_places']}")
    for place in result['places']:
        print(f"ğŸ—ºï¸ {place['name']} (ä¿¡é ¼åº¦: {place['confidence']:.2f})")

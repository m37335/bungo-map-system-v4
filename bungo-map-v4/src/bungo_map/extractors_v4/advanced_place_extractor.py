#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜ç²¾åº¦åœ°åæŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ  v4 (MeCab + å¼·åŒ–æ­£è¦è¡¨ç¾)
v3ã‹ã‚‰ã®ç§»æ¤ãƒ»æ”¹è‰¯ç‰ˆ - è¤‡é›‘åœ°åå¯¾å¿œ
"""

import re
import logging
from typing import List, Dict, Set, Optional, Any
from dataclasses import dataclass

logger = logging.getLogger(__name__)

# MeCabã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ä¾å­˜ï¼‰
try:
    import MeCab
    MECAB_AVAILABLE = True
    logger.info("âœ… MeCabåˆ©ç”¨å¯èƒ½")
except ImportError:
    MECAB_AVAILABLE = False
    logger.warning("âš ï¸ MeCabæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« - æ­£è¦è¡¨ç¾ã®ã¿ã§å‹•ä½œ")

@dataclass
class AdvancedPlace:
    """é«˜ç²¾åº¦åœ°åãƒ‡ãƒ¼ã‚¿"""
    work_id: int
    place_name: str
    sentence: str
    before_text: str = ""
    after_text: str = ""
    category: str = ""
    confidence: float = 0.0
    method: str = "advanced_regex"
    reading: str = ""
    pos: str = ""
    subpos: str = ""
    start_pos: int = 0
    end_pos: int = 0
    aozora_url: str = ""

class AdvancedPlaceExtractor:
    """é«˜ç²¾åº¦åœ°åæŠ½å‡ºã‚¯ãƒ©ã‚¹ v4"""
    
    def __init__(self):
        # MeCabåˆæœŸåŒ–ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        self.tagger = None
        if MECAB_AVAILABLE:
            try:
                self.tagger = MeCab.Tagger()
                logger.info("âœ… MeCabåˆæœŸåŒ–æˆåŠŸ")
            except Exception as e:
                logger.warning(f"âš ï¸ MeCabåˆæœŸåŒ–å¤±æ•—: {e}")
                self.tagger = None
        
        # åœ°åãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆåŒ…æ‹¬çš„ï¼‰
        self.place_patterns = self._build_place_patterns()
        
        # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.exclusions = self._build_exclusions()
        
        logger.info("ğŸŒŸ é«˜ç²¾åº¦åœ°åæŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ v4åˆæœŸåŒ–å®Œäº†")
    
    def _build_place_patterns(self) -> Dict[str, Any]:
        """åœ°åãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰"""
        return {
            # éƒ½é“åºœçœŒ
            'prefectures': [
                'åŒ—æµ·é“', 'é’æ£®çœŒ', 'å²©æ‰‹çœŒ', 'å®®åŸçœŒ', 'ç§‹ç”°çœŒ', 'å±±å½¢çœŒ', 'ç¦å³¶çœŒ',
                'èŒ¨åŸçœŒ', 'æ ƒæœ¨çœŒ', 'ç¾¤é¦¬çœŒ', 'åŸ¼ç‰çœŒ', 'åƒè‘‰çœŒ', 'æ±äº¬éƒ½', 'ç¥å¥ˆå·çœŒ',
                'æ–°æ½ŸçœŒ', 'å¯Œå±±çœŒ', 'çŸ³å·çœŒ', 'ç¦äº•çœŒ', 'å±±æ¢¨çœŒ', 'é•·é‡çœŒ', 'å²é˜œçœŒ',
                'é™å²¡çœŒ', 'æ„›çŸ¥çœŒ', 'ä¸‰é‡çœŒ', 'æ»‹è³€çœŒ', 'äº¬éƒ½åºœ', 'å¤§é˜ªåºœ', 'å…µåº«çœŒ',
                'å¥ˆè‰¯çœŒ', 'å’Œæ­Œå±±çœŒ', 'é³¥å–çœŒ', 'å³¶æ ¹çœŒ', 'å²¡å±±çœŒ', 'åºƒå³¶çœŒ', 'å±±å£çœŒ',
                'å¾³å³¶çœŒ', 'é¦™å·çœŒ', 'æ„›åª›çœŒ', 'é«˜çŸ¥çœŒ', 'ç¦å²¡çœŒ', 'ä½è³€çœŒ', 'é•·å´çœŒ',
                'ç†Šæœ¬çœŒ', 'å¤§åˆ†çœŒ', 'å®®å´çœŒ', 'é¹¿å…å³¶çœŒ', 'æ²–ç¸„çœŒ'
            ],
            
            # ä¸»è¦éƒ½å¸‚
            'major_cities': [
                'æœ­å¹Œ', 'ä»™å°', 'æ±äº¬', 'æ¨ªæµœ', 'åå¤å±‹', 'äº¬éƒ½', 'å¤§é˜ª', 'ç¥æˆ¸', 
                'åºƒå³¶', 'ç¦å²¡', 'é‚£è¦‡', 'æ–°å®¿', 'æ¸‹è°·', 'æ± è¢‹', 'éŠ€åº§', 'æµ…è‰',
                'ä¸Šé‡', 'å“å·', 'æ–°æ©‹', 'æœ‰æ¥½ç”º', 'ç§‹è‘‰åŸ', 'å…­æœ¬æœ¨', 'èµ¤å‚'
            ],
            
            # å¤å…¸åœ°åãƒ»æ–‡å­¦åœ°å
            'classical_places': [
                'æ±Ÿæˆ¸', 'å¹³å®‰äº¬', 'æ­¦è”µ', 'ç›¸æ¨¡', 'ç”²æ–', 'ä¿¡æ¿ƒ', 'è¶Šå¾Œ', 'ä¸‹é‡', 'ä¸Šé‡',
                'èœ€å·', 'ç¾…ç”Ÿé–€', 'æ´¥è»½', 'æ¾å±±', 'é¾å®®', 'è“¬è±', 'æ¡ƒæºéƒ·'
            ],
            
            # è‡ªç„¶åœ°åãƒ‘ã‚¿ãƒ¼ãƒ³
            'nature_patterns': [
                r'[ä¸€-é¾¯]{1,4}å·', r'[ä¸€-é¾¯]{1,4}å±±', r'[ä¸€-é¾¯]{1,4}æ¹–', r'[ä¸€-é¾¯]{1,4}æµ·',
                r'[ä¸€-é¾¯]{1,3}å³ ', r'[ä¸€-é¾¯]{1,3}è°·', r'[ä¸€-é¾¯]{1,3}å³¶', r'[ä¸€-é¾¯]{1,3}å²¬'
            ]
        }
    
    def _build_exclusions(self) -> Dict[str, Set[str]]:
        """é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³æ§‹ç¯‰"""
        return {
            'æ™‚é–“é–¢é€£': {'æ—¥', 'æœˆ', 'å¹´', 'æ™‚', 'åˆ†', 'ç§’', 'æ˜¥', 'å¤', 'ç§‹', 'å†¬'},
            'æ–¹å‘é–¢é€£': {'ä¸Š', 'ä¸‹', 'å·¦', 'å³', 'å‰', 'å¾Œ', 'ä¸­', 'å†…', 'å¤–'},
            'ä¸€èˆ¬åè©': {'äºº', 'ç‰©', 'äº‹', 'è€…', 'å®¶', 'å±‹', 'åº—', 'å ´', 'æ‰€'}
        }
    
    def extract_places(self, text: str) -> List[AdvancedPlace]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰åœ°åã‚’æŠ½å‡ºï¼ˆãƒ¡ã‚¤ãƒ³æ©Ÿèƒ½ï¼‰"""
        if not text or len(text) < 10:
            logger.warning(f"ãƒ†ã‚­ã‚¹ãƒˆãŒçŸ­ã™ãã¾ã™: {len(text)}æ–‡å­—")
            return []
        # work_idã‚„aozora_urlã¯ä½¿ã‚ãšã€textã®ã¿ã§æŠ½å‡º
        all_places = []
        # æ­£è¦è¡¨ç¾æŠ½å‡º
        regex_places = self._extract_places_regex(0, text, "")
        all_places.extend(regex_places)
        # MeCabæŠ½å‡ºï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        if hasattr(self, 'tagger') and self.tagger:
            mecab_places = self._extract_places_mecab(0, text, "")
            all_places.extend(mecab_places)
        # é‡è¤‡é™¤å»ã¨ãƒãƒ¼ã‚¸
        unique_places = self._deduplicate_and_merge(all_places)
        logger.info(f"âœ… é«˜ç²¾åº¦åœ°åæŠ½å‡ºå®Œäº†: {len(unique_places)}ä»¶")
        return unique_places
    
    def _extract_places_regex(self, work_id: int, text: str, aozora_url: str) -> List[AdvancedPlace]:
        """å¼·åŒ–æ­£è¦è¡¨ç¾ã«ã‚ˆã‚‹åœ°åæŠ½å‡º"""
        places = []
        
        try:
            # æ˜ç¤ºçš„åœ°åãƒªã‚¹ãƒˆã‹ã‚‰æŠ½å‡º
            for category, place_list in self.place_patterns.items():
                if category.endswith('_patterns'):
                    # æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
                    for pattern in place_list:
                        matches = re.finditer(pattern, text)
                        for match in matches:
                            place_name = match.group()
                            if self._is_valid_place(place_name):
                                place = AdvancedPlace(
                                    work_id=work_id,
                                    place_name=place_name,
                                    sentence=self._get_context(text, place_name),
                                    category=category,
                                    confidence=self._calculate_regex_confidence(place_name, category),
                                    method='regex',
                                    start_pos=match.start(),
                                    end_pos=match.end(),
                                    aozora_url=aozora_url
                                )
                                places.append(place)
                else:
                    # æ˜ç¤ºçš„ãƒªã‚¹ãƒˆ
                    for place in place_list:
                        if place in text:
                            start = text.find(place)
                            place_obj = AdvancedPlace(
                                work_id=work_id,
                                place_name=place,
                                sentence=self._get_context(text, place),
                                category=category,
                                confidence=self._calculate_regex_confidence(place, category),
                                method='regex',
                                start_pos=start,
                                end_pos=start + len(place),
                                aozora_url=aozora_url
                            )
                            places.append(place_obj)
        
        except Exception as e:
            logger.error(f"âŒ æ­£è¦è¡¨ç¾æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        
        return places
    
    def _extract_places_mecab(self, work_id: int, text: str, aozora_url: str) -> List[AdvancedPlace]:
        """MeCabã‚’ä½¿ã£ãŸåœ°åæŠ½å‡ºï¼ˆã‚¹ã‚¿ãƒ–å®Ÿè£…ï¼‰"""
        # å®Ÿéš›ã®MeCabå®Ÿè£…ã¯è¤‡é›‘ãªã®ã§ã€åŸºæœ¬æ©Ÿèƒ½ã®ã¿
        return []
    
    def _is_valid_place(self, place_name: str) -> bool:
        """åœ°åã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯"""
        if not place_name or len(place_name.strip()) <= 1:
            return False
        
        # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        for category, exclusions in self.exclusions.items():
            if place_name in exclusions:
                return False
        
        return True
    
    def _calculate_regex_confidence(self, place_name: str, category: str) -> float:
        """æ­£è¦è¡¨ç¾åœ°åã®ä¿¡é ¼åº¦è¨ˆç®—"""
        confidence_map = {
            'prefectures': 0.95,
            'major_cities': 0.90,
            'classical_places': 0.85,
            'nature_patterns': 0.75
        }
        return confidence_map.get(category, 0.65)
    
    def _get_context(self, text: str, place_name: str, context_len: int = 50) -> str:
        """åœ°åå‘¨è¾ºã®æ–‡è„ˆã‚’å–å¾—"""
        try:
            start = text.find(place_name)
            if start == -1:
                return ""
            
            context_start = max(0, start - context_len)
            context_end = min(len(text), start + len(place_name) + context_len)
            
            return text[context_start:context_end]
        except Exception:
            return ""
    
    def _deduplicate_and_merge(self, places: List[AdvancedPlace]) -> List[AdvancedPlace]:
        """é‡è¤‡é™¤å»ã¨ãƒãƒ¼ã‚¸"""
        seen = set()
        unique_places = []
        
        # ä¿¡é ¼åº¦é †ã§ã‚½ãƒ¼ãƒˆ
        places.sort(key=lambda x: x.confidence, reverse=True)
        
        for place in places:
            # åœ°åã¨ä½œå“IDã®çµ„ã¿åˆã‚ã›ã§é‡è¤‡ãƒã‚§ãƒƒã‚¯
            key = (place.work_id, place.place_name)
            if key not in seen:
                seen.add(key)
                unique_places.append(place)
        
        return unique_places
    
    def test_extraction(self, test_text: str) -> Dict[str, Any]:
        """æŠ½å‡ºæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ§ª Advanced Place Extractor ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        places = self.extract_places(test_text)
        
        # çµ±è¨ˆä½œæˆ
        methods = {}
        categories = {}
        for place in places:
            methods[place.method] = methods.get(place.method, 0) + 1
            categories[place.category] = categories.get(place.category, 0) + 1
        
        return {
            'test_text_length': len(test_text),
            'total_places': len(places),
            'mecab_available': MECAB_AVAILABLE,
            'places': [
                {
                    'name': place.place_name,
                    'category': place.category,
                    'confidence': place.confidence,
                    'method': place.method
                }
                for place in places[:10]  # æœ€åˆã®10ä»¶ã®ã¿
            ],
            'stats': {
                'methods': methods,
                'categories': categories
            },
            'success': len(places) > 0
        }

if __name__ == "__main__":
    # åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ
    extractor = AdvancedPlaceExtractor()
    
    test_text = """
    ç§ã¯æ±äº¬éƒ½æ–°å®¿åŒºã«ä½ã‚“ã§ã„ã¾ã™ã€‚
    éŒå€‰ã®å¤§ä»ã‚’è¦‹ã«è¡Œãã¾ã—ãŸã€‚
    æ´¥è»½æµ·å³¡ã‚’æ¸¡ã£ã¦åŒ—æµ·é“ã«å‘ã‹ã„ã¾ã—ãŸã€‚
    äº¬éƒ½åºœäº¬éƒ½å¸‚ã‚’çµŒç”±ã—ã¦å¥ˆè‰¯çœŒå¥ˆè‰¯å¸‚ã«åˆ°ç€ã—ã¾ã—ãŸã€‚
    å¯Œå£«å±±ã®å±±é ‚ã‹ã‚‰è¦‹ãŸæ™¯è‰²ã¯ç´ æ™´ã‚‰ã—ã‹ã£ãŸã€‚
    æ±Ÿæˆ¸æ™‚ä»£ã®æ­¦è”µå›½ã‹ã‚‰ç›¸æ¨¡å›½ã¸ã®æ—…è·¯ã¯å›°é›£ã§ã—ãŸã€‚
    """
    
    result = extractor.test_extraction(test_text)
    
    print("âœ… Advanced Place Extractor v4 ãƒ†ã‚¹ãƒˆå®Œäº†")
    print(f"ğŸ“Š æŠ½å‡ºåœ°åæ•°: {result['total_places']}")
    print(f"ğŸ”§ MeCabåˆ©ç”¨å¯èƒ½: {result['mecab_available']}")
    
    for place in result['places']:
        print(f"ğŸ—ºï¸ {place['name']} [{place['category']}] "
              f"({place['method']}, ä¿¡é ¼åº¦: {place['confidence']:.2f})")
    
    print(f"\nğŸ“ˆ æŠ½å‡ºæ‰‹æ³•åˆ¥çµ±è¨ˆ: {result['stats']['methods']}")
    print(f"ğŸ“‹ ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥çµ±è¨ˆ: {result['stats']['categories']}") 
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ—ºï¸ å¼·åŒ–ç‰ˆåœ°åæŠ½å‡ºå™¨
æ”¹å–„ã•ã‚ŒãŸé’ç©ºæ–‡åº«å‡¦ç† + AIæ–‡è„ˆåˆ¤æ–­ + é©åˆ‡ãªæ–‡è„ˆå–å¾—

Features:
- é’ç©ºæ–‡åº«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®é©åˆ‡ãªå‡¦ç†
- è‡ªç„¶ãªæ–‡åˆ†å‰²ã¨æ–‡è„ˆå–å¾—
- åœ°åå‘¨è¾ºã®æ­£ç¢ºãªå‰å¾Œæ–‡è„ˆ
- SimplePlaceExtractorã¨ã®çµ±åˆ
"""

import logging
from typing import List, Dict, Optional
from dataclasses import dataclass, asdict

from ..processors.aozora_content_processor import AozoraContentProcessor
from .simple_place_extractor import SimplePlaceExtractor

logger = logging.getLogger(__name__)

@dataclass
class EnhancedPlace:
    """å¼·åŒ–ç‰ˆåœ°åãƒ‡ãƒ¼ã‚¿"""
    work_id: int
    place_name: str
    sentence: str           # ã‚¯ãƒªãƒ¼ãƒ³ãªæ–‡
    before_text: str        # å‰æ–‡è„ˆ
    after_text: str         # å¾Œæ–‡è„ˆ
    sentence_index: int     # æ–‡ç•ªå·
    char_position: int      # æ–‡å­—ä½ç½®
    confidence: float       # ä¿¡é ¼åº¦
    extraction_method: str  # æŠ½å‡ºæ‰‹æ³•
    aozora_url: str = ""

class EnhancedPlaceExtractor:
    """å¼·åŒ–ç‰ˆåœ°åæŠ½å‡ºå™¨"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.content_processor = AozoraContentProcessor()
        self.simple_extractor = SimplePlaceExtractor()
        
        print("ğŸ—ºï¸ å¼·åŒ–ç‰ˆåœ°åæŠ½å‡ºå™¨åˆæœŸåŒ–å®Œäº†")
    
    def extract_places_from_work(self, work_id: int, raw_content: str, aozora_url: str = "") -> List[EnhancedPlace]:
        """ä½œå“ã‹ã‚‰ã®åœ°åæŠ½å‡ºï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        
        if not raw_content or len(raw_content) < 100:
            logger.warning(f"âš ï¸ ä½œå“{work_id}: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒçŸ­ã™ãã¾ã™")
            return []
        
        # 1. é’ç©ºæ–‡åº«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å‡¦ç†
        result = self.content_processor.process_work_content(work_id, raw_content)
        
        if not result['success']:
            logger.warning(f"âš ï¸ ä½œå“{work_id}: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å‡¦ç†å¤±æ•— - {result['error']}")
            return []
        
        sentences = result['sentences']
        main_content = result['main_content']
        
        # 2. å„æ–‡ã‹ã‚‰åœ°åæŠ½å‡º
        all_places = []
        
        for sentence_index, sentence in enumerate(sentences):
            # æ–‡è„ˆå–å¾—
            context = self.content_processor.get_sentence_context(
                sentences, sentence_index, context_length=1
            )
            
            # åŸºæœ¬åœ°åæŠ½å‡ºï¼ˆã“ã®æ–‡ã®ã¿ï¼‰
            sentence_places = self.simple_extractor.extract_places_from_text(
                work_id, sentence, aozora_url
            )
            
            # EnhancedPlaceã«å¤‰æ›
            for place in sentence_places:
                enhanced_place = EnhancedPlace(
                    work_id=work_id,
                    place_name=place.place_name,
                    sentence=context.sentence,
                    before_text=context.before_text,
                    after_text=context.after_text,
                    sentence_index=context.sentence_index,
                    char_position=context.char_position,
                    confidence=place.confidence,
                    extraction_method=place.extraction_method,
                    aozora_url=aozora_url
                )
                
                all_places.append(enhanced_place)
        
        logger.info(f"âœ… ä½œå“{work_id}: {len(all_places)}ä»¶ã®åœ°åæŠ½å‡ºå®Œäº†")
        return all_places
    
    def convert_to_simple_places(self, enhanced_places: List[EnhancedPlace]) -> List:
        """SimplePlaceã¨äº’æ›æ€§ã®ã‚ã‚‹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›"""
        from bungo_map.extractors.simple_place_extractor import Place
        
        simple_places = []
        for enhanced in enhanced_places:
            simple_place = Place(
                work_id=enhanced.work_id,
                place_name=enhanced.place_name,
                before_text=enhanced.before_text,
                sentence=enhanced.sentence,
                after_text=enhanced.after_text,
                aozora_url=enhanced.aozora_url,
                confidence=enhanced.confidence,
                extraction_method=enhanced.extraction_method
            )
            simple_places.append(simple_place)
        
        return simple_places

# ãƒ†ã‚¹ãƒˆç”¨é–¢æ•°
def test_enhanced_extractor():
    """å¼·åŒ–ç‰ˆæŠ½å‡ºå™¨ã®ãƒ†ã‚¹ãƒˆ"""
    import sqlite3
    
    extractor = EnhancedPlaceExtractor()
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰é•·ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ä½œå“ã‚’ãƒ†ã‚¹ãƒˆ
    with sqlite3.connect('data/bungo_production.db') as conn:
        cursor = conn.execute("""
            SELECT work_id, title, content 
            FROM works 
            WHERE length(content) > 30000 
            LIMIT 2
        """)
        
        for work_id, title, content in cursor.fetchall():
            print(f"\n{'='*50}")
            print(f"ğŸ“š ä½œå“: {title}")
            print(f"ğŸ“Š å…ƒãƒ‡ãƒ¼ã‚¿: {len(content):,}æ–‡å­—")
            
            enhanced_places = extractor.extract_places_from_work(work_id, content)
            
            print(f"âœ… æŠ½å‡ºçµæœ: {len(enhanced_places)}ä»¶")
            
            # åœ°åã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
            for i, place in enumerate(enhanced_places[:5]):
                print(f"\nğŸ—ºï¸ åœ°å{i+1}: {place.place_name}")
                print(f"  ğŸ“ æ–‡: {place.sentence[:80]}...")
                print(f"  â¬…ï¸ å‰: {place.before_text[:30]}...")
                print(f"  â¡ï¸ å¾Œ: {place.after_text[:30]}...")
                print(f"  ğŸ“Š ä½ç½®: æ–‡{place.sentence_index}, æ–‡å­—{place.char_position}")
            
            # ç°¡æ˜“çµ±è¨ˆ
            methods = {}
            for place in enhanced_places:
                method = place.extraction_method
                methods[method] = methods.get(method, 0) + 1
            
            print(f"\nğŸ“‹ æŠ½å‡ºæ‰‹æ³•åˆ¥çµ±è¨ˆ:")
            for method, count in sorted(methods.items(), key=lambda x: x[1], reverse=True):
                print(f"  {method}: {count}ä»¶")

if __name__ == "__main__":
    test_enhanced_extractor() 
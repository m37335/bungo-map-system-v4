#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸŒŸ é«˜ç²¾åº¦åœ°åæŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ  (MeCab + å¼·åŒ–æ­£è¦è¡¨ç¾)
"""

import re
import MeCab
from typing import List, Dict, Set

class AdvancedPlaceExtractor:
    """é«˜ç²¾åº¦åœ°åæŠ½å‡ºã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.tagger = MeCab.Tagger()
        
        # åœ°åãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆåŒ…æ‹¬çš„ï¼‰
        self.place_patterns = {
            # éƒ½é“åºœçœŒ
            'prefectures': [
                'åŒ—æµ·é“', 'é’æ£®çœŒ', 'å²©æ‰‹çœŒ', 'å®®åŸçœŒ', 'ç§‹ç”°çœŒ', 'å±±å½¢çœŒ', 'ç¦å³¶çœŒ',
                'èŒ¨åŸçœŒ', 'æ ƒæœ¨çœŒ', 'ç¾¤é¦¬çœŒ', 'åŸ¼ç‰çœŒ', 'åƒè‘‰çœŒ', 'æ±äº¬éƒ½', 'ç¥å¥ˆå·çœŒ',
                'æ–°æ½ŸçœŒ', 'å¯Œå±±çœŒ', 'çŸ³å·çœŒ', 'ç¦äº•çœŒ', 'å±±æ¢¨çœŒ', 'é•·é‡çœŒ', 'å²é˜œçœŒ',
                'é™å²¡çœŒ', 'æ„›çŸ¥çœŒ', 'ä¸‰é‡çœŒ', 'æ»‹è³€çœŒ', 'äº¬éƒ½åºœ', 'å¤§é˜ªåºœ', 'å…µåº«çœŒ',
                'å¥ˆè‰¯çœŒ', 'å’Œæ­Œå±±çœŒ', 'é³¥å–çœŒ', 'å³¶æ ¹çœŒ', 'å²¡å±±çœŒ', 'åºƒå³¶çœŒ', 'å±±å£çœŒ',
                'å¾³å³¶çœŒ', 'é¦™å·çœŒ', 'æ„›åª›çœŒ', 'é«˜çŸ¥çœŒ', 'ç¦å²¡çœŒ', 'ä½è³€çœŒ', 'é•·å´çœŒ',
                'ç†Šæœ¬çœŒ', 'å¤§åˆ†çœŒ', 'å®®å´çœŒ', 'é¹¿å…å³¶çœŒ', 'æ²–ç¸„çœŒ'
            ],
            
            # ä¸»è¦éƒ½å¸‚
            'major_cities': [
                'æœ­å¹Œ', 'ä»™å°', 'æ±äº¬', 'æ¨ªæµœ', 'åå¤å±‹', 'äº¬éƒ½', 'å¤§é˜ª', 'ç¥æˆ¸', 
                'åºƒå³¶', 'ç¦å²¡', 'é‚£è¦‡', 'æ–°å®¿', 'æ¸‹è°·', 'æ± è¢‹', 'éŠ€åº§', 'æµ…è‰',
                'ä¸Šé‡', 'å“å·', 'æ–°æ©‹', 'æœ‰æ¥½ç”º', 'ç§‹è‘‰åŸ', 'å…­æœ¬æœ¨', 'èµ¤å‚'
            ],
            
            # å¤å…¸åœ°åãƒ»æ–‡å­¦åœ°å
            'classical_places': [
                'æ±Ÿæˆ¸', 'å¹³å®‰äº¬', 'æ­¦è”µ', 'ç›¸æ¨¡', 'ç”²æ–', 'ä¿¡æ¿ƒ', 'è¶Šå¾Œ', 'ä¸‹é‡', 'ä¸Šé‡',
                'èœ€å·', 'é˜¿ä¿®ç¾…', 'å¸é‡ˆå¤©', 'é ˆå¼¥å±±', 'å…œç‡å¤©', 'å¿‰åˆ©å¤©', 'æ¥µæ¥½', 'æµ„åœŸ',
                'é¾å®®', 'è“¬è±', 'æ¡ƒæºéƒ·', 'å¤©ç«º', 'éœ‡æ—¦', 'ç¾…ç”Ÿé–€'
            ],
            
            # å¤–å›½åœ°å
            'foreign_places': [
                'ãƒ­ãƒ³ãƒ‰ãƒ³', 'ãƒ‘ãƒª', 'ãƒ™ãƒ«ãƒªãƒ³', 'ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯', 'ã‚·ã‚«ã‚´', 'ãƒœã‚¹ãƒˆãƒ³',
                'ä¸­å›½', 'æœé®®', 'æº€å·', 'å°æ¹¾', 'æ¨ºå¤ª', 'ã‚·ãƒ™ãƒªã‚¢', 'ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘', 'ã‚¢ãƒ¡ãƒªã‚«',
                'æœé®®', 'é«˜éº—', 'ç™¾æ¸ˆ', 'æ–°ç¾…'
            ],
            
            # è‡ªç„¶åœ°åãƒ‘ã‚¿ãƒ¼ãƒ³
            'nature_patterns': [
                r'[ä¸€-é¾¯]{1,4}å·', r'[ä¸€-é¾¯]{1,4}å±±', r'[ä¸€-é¾¯]{1,4}æ¹–', r'[ä¸€-é¾¯]{1,4}æµ·',
                r'[ä¸€-é¾¯]{1,3}å³ ', r'[ä¸€-é¾¯]{1,3}è°·', r'[ä¸€-é¾¯]{1,3}é‡', r'[ä¸€-é¾¯]{1,3}åŸ',
                r'[ä¸€-é¾¯]{1,3}å³¶', r'[ä¸€-é¾¯]{1,3}å²¬', r'[ä¸€-é¾¯]{1,3}æµ¦', r'[ä¸€-é¾¯]{1,3}å´'
            ],
            
            # å»ºé€ ç‰©ãƒ»æ–½è¨­
            'facility_patterns': [
                r'[ä¸€-é¾¯]{1,4}å¯º', r'[ä¸€-é¾¯]{1,4}ç¥ç¤¾', r'[ä¸€-é¾¯]{1,3}é™¢', r'[ä¸€-é¾¯]{1,3}å®®',
                r'[ä¸€-é¾¯]{1,3}åŸ', r'[ä¸€-é¾¯]{1,3}å®¿', r'[ä¸€-é¾¯]{1,3}é§…', r'[ä¸€-é¾¯]{1,3}æ¸¯'
            ]
        }
        
        # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.exclusions = {
            'æ™‚é–“é–¢é€£': {'æ—¥', 'æœˆ', 'å¹´', 'æ™‚', 'åˆ†', 'ç§’', 'æ˜¥', 'å¤', 'ç§‹', 'å†¬'},
            'æ–¹å‘é–¢é€£': {'ä¸Š', 'ä¸‹', 'å·¦', 'å³', 'å‰', 'å¾Œ', 'ä¸­', 'å†…', 'å¤–'},
            'å¤§å°é–¢é€£': {'å¤§', 'å°', 'é«˜', 'ä½', 'é•·', 'çŸ­'},
            'ä¸€èˆ¬åè©': {'äºº', 'ç‰©', 'äº‹', 'è€…', 'å®¶', 'å±‹', 'åº—', 'å ´', 'æ‰€'}
        }

    def extract_places_mecab(self, text: str) -> List[Dict]:
        """MeCabã‚’ä½¿ã£ãŸåœ°åæŠ½å‡º"""
        places = []
        
        try:
            node = self.tagger.parseToNode(text)
            
            while node:
                if node.surface and len(node.surface) >= 2:
                    features = node.feature.split(',')
                    
                    # åè©ãƒ»å›ºæœ‰åè©ãƒ»åœ°åã‚’ãƒã‚§ãƒƒã‚¯
                    if len(features) > 6:
                        pos = features[0]  # å“è©
                        subpos = features[1] if len(features) > 1 else ''  # ç´°åˆ†é¡
                        reading = features[7] if len(features) > 7 else ''  # èª­ã¿
                        
                        if (pos == 'åè©' and 
                            ('å›ºæœ‰' in subpos or 'åœ°åŸŸ' in subpos or 'ä¸€èˆ¬' in subpos)):
                            
                            place_info = {
                                'text': node.surface,
                                'reading': reading,
                                'pos': pos,
                                'subpos': subpos,
                                'method': 'mecab',
                                'confidence': self._calculate_mecab_confidence(node.surface, subpos)
                            }
                            places.append(place_info)
                
                node = node.next
                
        except Exception as e:
            print(f"âŒ MeCabè§£æã‚¨ãƒ©ãƒ¼: {e}")
        
        return places

    def extract_places_regex(self, text: str) -> List[Dict]:
        """å¼·åŒ–æ­£è¦è¡¨ç¾ã«ã‚ˆã‚‹åœ°åæŠ½å‡º"""
        places = []
        
        try:
            # æ˜ç¤ºçš„åœ°åãƒªã‚¹ãƒˆã‹ã‚‰æŠ½å‡º
            for category, place_list in self.place_patterns.items():
                if category.endswith('_patterns'):
                    # æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
                    for pattern in place_list:
                        matches = re.finditer(pattern, text)
                        for match in matches:
                            place_name = match.group()
                            if self._is_valid_place(place_name):
                                places.append({
                                    'text': place_name,
                                    'category': category,
                                    'method': 'regex',
                                    'start': match.start(),
                                    'end': match.end(),
                                    'confidence': self._calculate_regex_confidence(place_name, category)
                                })
                else:
                    # æ˜ç¤ºçš„ãƒªã‚¹ãƒˆ
                    for place in place_list:
                        if place in text:
                            start = text.find(place)
                            places.append({
                                'text': place,
                                'category': category,
                                'method': 'regex',
                                'start': start,
                                'end': start + len(place),
                                'confidence': self._calculate_regex_confidence(place, category)
                            })
        
        except Exception as e:
            print(f"âŒ æ­£è¦è¡¨ç¾æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        
        return places

    def extract_places_combined(self, text: str, work_info: Dict = None) -> List[Dict]:
        """MeCab + æ­£è¦è¡¨ç¾ã®çµ±åˆæŠ½å‡º"""
        mecab_places = self.extract_places_mecab(text)
        regex_places = self.extract_places_regex(text)
        
        # çµæœã‚’ãƒãƒ¼ã‚¸ã—ã¦é‡è¤‡é™¤å»
        all_places = []
        seen_places = set()
        
        # MeCabçµæœã‚’è¿½åŠ 
        for place in mecab_places:
            key = place['text']
            if key not in seen_places and self._is_valid_place(key):
                place.update({
                    'author_name': work_info.get('author_name', '') if work_info else '',
                    'work_title': work_info.get('title', '') if work_info else '',
                    'context': self._get_context(text, place['text'])
                })
                all_places.append(place)
                seen_places.add(key)
        
        # æ­£è¦è¡¨ç¾çµæœã‚’è¿½åŠ 
        for place in regex_places:
            key = place['text']
            if key not in seen_places and self._is_valid_place(key):
                place.update({
                    'author_name': work_info.get('author_name', '') if work_info else '',
                    'work_title': work_info.get('title', '') if work_info else ''
                })
                all_places.append(place)
                seen_places.add(key)
        
        # ä¿¡é ¼åº¦é †ã§ã‚½ãƒ¼ãƒˆ
        all_places.sort(key=lambda x: x.get('confidence', 0), reverse=True)
        
        return all_places

    def _is_valid_place(self, place_name: str) -> bool:
        """åœ°åã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯"""
        if not place_name or len(place_name.strip()) == 0:
            return False
        
        # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        for category, exclusions in self.exclusions.items():
            if place_name in exclusions:
                return False
        
        # æ•°å­—ã®ã¿ã¯é™¤å¤–
        if place_name.isdigit():
            return False
        
        # ä¸€æ–‡å­—ã¯ç‰¹å®šã®ã‚‚ã®ã®ã¿è¨±å¯
        if len(place_name) == 1:
            allowed_single = {'äº¬', 'æ±Ÿ', 'æµ·', 'å±±', 'å·', 'å³¶'}
            return place_name in allowed_single
        
        return True

    def _calculate_mecab_confidence(self, place_name: str, subpos: str) -> float:
        """MeCabçµæœã®ä¿¡é ¼åº¦è¨ˆç®—"""
        confidence = 0.7  # ãƒ™ãƒ¼ã‚¹ä¿¡é ¼åº¦
        
        if 'å›ºæœ‰' in subpos:
            confidence += 0.2
        if 'åœ°åŸŸ' in subpos:
            confidence += 0.15
        if len(place_name) >= 3:
            confidence += 0.1
        
        return min(confidence, 1.0)

    def _calculate_regex_confidence(self, place_name: str, category: str) -> float:
        """æ­£è¦è¡¨ç¾çµæœã®ä¿¡é ¼åº¦è¨ˆç®—"""
        confidence = 0.6  # ãƒ™ãƒ¼ã‚¹ä¿¡é ¼åº¦
        
        confidence_boost = {
            'prefectures': 0.3,
            'major_cities': 0.25,
            'classical_places': 0.2,
            'foreign_places': 0.15,
            'nature_patterns': 0.1,
            'facility_patterns': 0.1
        }
        
        confidence += confidence_boost.get(category, 0)
        
        # ç‰¹åˆ¥ãªåœ°åã®ãƒ–ãƒ¼ã‚¹ãƒˆ
        special_places = {'èœ€å·', 'é˜¿ä¿®ç¾…', 'å¸é‡ˆå¤©', 'æ±Ÿæˆ¸', 'å¹³å®‰äº¬'}
        if place_name in special_places:
            confidence += 0.15
        
        return min(confidence, 1.0)

    def _get_context(self, text: str, place_name: str, context_len: int = 50) -> str:
        """åœ°åã®æ–‡è„ˆã‚’å–å¾—"""
        start = text.find(place_name)
        if start == -1:
            return ""
        
        context_start = max(0, start - context_len)
        context_end = min(len(text), start + len(place_name) + context_len)
        
        return text[context_start:context_end]

def test_advanced_extractor():
    """é«˜ç²¾åº¦åœ°åæŠ½å‡ºã®ãƒ†ã‚¹ãƒˆ"""
    extractor = AdvancedPlaceExtractor()
    
    # ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆï¼ˆé’ç©ºæ–‡åº«é¢¨ï¼‰
    test_text = """
    æ±äº¬ã§å¤ç›®æ¼±çŸ³ã¯ç”Ÿã¾ã‚Œã¾ã—ãŸã€‚äº¬éƒ½ã«ã‚‚ä½ã‚“ã§ã„ã¾ã—ãŸã€‚
    èœ€å·ã‚„é˜¿ä¿®ç¾…ã€å¸é‡ˆå¤©ã¨ã„ã†è¨€è‘‰ã‚‚å‡ºã¦ãã¾ã™ã€‚
    æ±Ÿæˆ¸æ™‚ä»£ã®å¹³å®‰äº¬ã§ã¯ã€å¤šãã®ä½œå®¶ãŒéš…ç”°å·ã®ã»ã¨ã‚Šã§åŸ·ç­†ã—ã¦ã„ã¾ã—ãŸã€‚
    ãƒ­ãƒ³ãƒ‰ãƒ³ã‚„ãƒ‘ãƒªã¨ã„ã£ãŸå¤–å›½ã®éƒ½å¸‚ã«ã¤ã„ã¦ã‚‚è¨€åŠã•ã‚Œã¦ã„ã¾ã™ã€‚
    """
    
    print("ğŸŒŸ é«˜ç²¾åº¦åœ°åæŠ½å‡ºãƒ†ã‚¹ãƒˆé–‹å§‹")
    print(f"ğŸ“– ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆ ({len(test_text)}æ–‡å­—)")
    
    # MeCabæŠ½å‡º
    mecab_places = extractor.extract_places_mecab(test_text)
    print(f"\nğŸ”§ MeCabæŠ½å‡º: {len(mecab_places)}ä»¶")
    for place in mecab_places[:5]:
        print(f"  - {place['text']} (ä¿¡é ¼åº¦: {place['confidence']:.2f})")
    
    # æ­£è¦è¡¨ç¾æŠ½å‡º
    regex_places = extractor.extract_places_regex(test_text)
    print(f"\nğŸ“ æ­£è¦è¡¨ç¾æŠ½å‡º: {len(regex_places)}ä»¶")
    for place in regex_places[:5]:
        print(f"  - {place['text']} (ä¿¡é ¼åº¦: {place['confidence']:.2f})")
    
    # çµ±åˆæŠ½å‡º
    combined_places = extractor.extract_places_combined(test_text)
    print(f"\nğŸ¯ çµ±åˆæŠ½å‡º: {len(combined_places)}ä»¶")
    for place in combined_places:
        print(f"  - {place['text']} (ä¿¡é ¼åº¦: {place['confidence']:.2f}, æ‰‹æ³•: {place['method']})")

if __name__ == "__main__":
    test_advanced_extractor() 
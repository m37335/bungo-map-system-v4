#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é’ç©ºæ–‡åº«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
ä½œå“ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨å‰å‡¦ç†ã‚’è¡Œã†
"""

import os
import re
import zipfile
import logging
import requests
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from pathlib import Path

logger = logging.getLogger(__name__)

@dataclass
class AozoraWork:
    """é’ç©ºæ–‡åº«ä½œå“ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    work_id: str
    title: str
    author: str
    copyright_flag: int
    text_url: str
    text: Optional[str] = None
    processed_text: Optional[str] = None

class AozoraClient:
    """é’ç©ºæ–‡åº«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(self, cache_dir: str = "data/aozora_cache"):
        """åˆæœŸåŒ–"""
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # é’ç©ºæ–‡åº«ã®URL
        self.base_url = "https://www.aozora.gr.jp"
        self.catalog_url = f"{self.base_url}/cards/000000/files/catalog.csv.zip"
        
        logger.info(f"ğŸ“š é’ç©ºæ–‡åº«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª={self.cache_dir}")
    
    def download_catalog(self) -> List[Dict]:
        """ã‚«ã‚¿ãƒ­ã‚°ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨è§£æ"""
        try:
            # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            response = requests.get(self.catalog_url)
            response.raise_for_status()
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            zip_path = self.cache_dir / "catalog.zip"
            with open(zip_path, "wb") as f:
                f.write(response.content)
            
            # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®å±•é–‹
            with zipfile.ZipFile(zip_path) as z:
                z.extractall(self.cache_dir)
            
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
            csv_path = self.cache_dir / "catalog.csv"
            works = []
            with open(csv_path, "r", encoding="utf-8") as f:
                for line in f:
                    if line.startswith("ä½œå“ID"):
                        continue
                    
                    fields = line.strip().split(",")
                    if len(fields) >= 4:
                        work = {
                            "work_id": fields[0],
                            "title": fields[1],
                            "author": fields[2],
                            "copyright_flag": int(fields[3])
                        }
                        works.append(work)
            
            logger.info(f"âœ… ã‚«ã‚¿ãƒ­ã‚°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(works)}ä»¶ã®ä½œå“")
            return works
            
        except Exception as e:
            logger.error(f"âŒ ã‚«ã‚¿ãƒ­ã‚°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
            return []
    
    def download_work(self, work_id: str) -> Optional[AozoraWork]:
        """ä½œå“ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç¢ºèª
            cache_path = self.cache_dir / f"{work_id}.txt"
            if cache_path.exists():
                with open(cache_path, "r", encoding="utf-8") as f:
                    text = f.read()
                return AozoraWork(
                    work_id=work_id,
                    title="",  # ã‚«ã‚¿ãƒ­ã‚°ã‹ã‚‰å–å¾—
                    author="",  # ã‚«ã‚¿ãƒ­ã‚°ã‹ã‚‰å–å¾—
                    copyright_flag=0,
                    text_url="",
                    text=text
                )
            
            # ä½œå“ãƒšãƒ¼ã‚¸ã®URL
            work_url = f"{self.base_url}/cards/{work_id}/files/{work_id}.html"
            
            # ä½œå“ãƒšãƒ¼ã‚¸ã®å–å¾—
            response = requests.get(work_url)
            response.raise_for_status()
            
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®URLã‚’æŠ½å‡º
            text_url_match = re.search(r'href="(.*?\.txt)"', response.text)
            if not text_url_match:
                logger.error(f"âŒ ãƒ†ã‚­ã‚¹ãƒˆURLãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {work_id}")
                return None
            
            text_url = f"{self.base_url}/cards/{work_id}/files/{text_url_match.group(1)}"
            
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            response = requests.get(text_url)
            response.raise_for_status()
            text = response.text
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            with open(cache_path, "w", encoding="utf-8") as f:
                f.write(text)
            
            logger.info(f"âœ… ä½œå“ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {work_id}")
            return AozoraWork(
                work_id=work_id,
                title="",  # ã‚«ã‚¿ãƒ­ã‚°ã‹ã‚‰å–å¾—
                author="",  # ã‚«ã‚¿ãƒ­ã‚°ã‹ã‚‰å–å¾—
                copyright_flag=0,
                text_url=text_url,
                text=text
            )
            
        except Exception as e:
            logger.error(f"âŒ ä½œå“ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {work_id} - {e}")
            return None
    
    def process_text(self, text: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†"""
        # ãƒ«ãƒ“ã®é™¤å»
        text = re.sub(r'ã€Š.*?ã€‹', '', text)
        
        # æ³¨è¨˜ã®é™¤å»
        text = re.sub(r'ï¼».*?ï¼½', '', text)
        
        # ç©ºè¡Œã®é™¤å»
        text = re.sub(r'\n\s*\n', '\n', text)
        
        # å‰å¾Œã®ç©ºç™½ã‚’é™¤å»
        text = text.strip()
        
        return text
    
    def get_work_with_context(self, work_id: str, sentence: str, context_size: int = 1) -> Tuple[str, str, str]:
        """æ–‡ã®å‰å¾Œæ–‡ã‚’å–å¾—"""
        work = self.download_work(work_id)
        if not work or not work.text:
            return "", "", ""
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡Œã«åˆ†å‰²
        lines = work.text.split('\n')
        
        # æ–‡ã‚’å«ã‚€è¡Œã‚’æ¢ã™
        for i, line in enumerate(lines):
            if sentence in line:
                # å‰å¾Œã®æ–‡ã‚’å–å¾—
                before = '\n'.join(lines[max(0, i-context_size):i])
                after = '\n'.join(lines[i+1:i+1+context_size])
                return before, line, after
        
        return "", "", "" 
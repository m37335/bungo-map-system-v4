#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é’ç©ºæ–‡åº«ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†
ä½œå“ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†ã¨åœ°åæŠ½å‡ºã®æº–å‚™ã‚’è¡Œã†
"""

import re
import logging
from typing import List, Dict, Optional
from dataclasses import dataclass
from pathlib import Path

from .aozora_client import AozoraClient, AozoraWork

logger = logging.getLogger(__name__)

@dataclass
class ProcessedWork:
    """å‡¦ç†æ¸ˆã¿ä½œå“ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    work_id: str
    title: str
    author: str
    text: str
    sentences: List[str]
    metadata: Dict

class AozoraProcessor:
    """é’ç©ºæ–‡åº«ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, client: Optional[AozoraClient] = None):
        """åˆæœŸåŒ–"""
        self.client = client or AozoraClient()
        
        # æ–‡åˆ†å‰²ç”¨ã®æ­£è¦è¡¨ç¾
        self.sentence_pattern = re.compile(r'[ã€‚ï¼ï¼ï¼Ÿ!?]+')
        
        logger.info("ğŸ“ é’ç©ºæ–‡åº«ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚¯ãƒ©ã‚¹åˆæœŸåŒ–å®Œäº†")
    
    def process_work(self, work: AozoraWork) -> Optional[ProcessedWork]:
        """ä½œå“ã®å‡¦ç†"""
        if not work.text:
            logger.error(f"âŒ ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™: {work.work_id}")
            return None
        
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†
            processed_text = self.client.process_text(work.text)
            
            # æ–‡ã®åˆ†å‰²
            sentences = self._split_sentences(processed_text)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
            metadata = self._extract_metadata(processed_text)
            
            logger.info(f"âœ… ä½œå“å‡¦ç†å®Œäº†: {work.work_id} - {len(sentences)}æ–‡")
            
            return ProcessedWork(
                work_id=work.work_id,
                title=work.title,
                author=work.author,
                text=processed_text,
                sentences=sentences,
                metadata=metadata
            )
            
        except Exception as e:
            logger.error(f"âŒ ä½œå“å‡¦ç†å¤±æ•—: {work.work_id} - {e}")
            return None
    
    def _split_sentences(self, text: str) -> List[str]:
        """æ–‡ã®åˆ†å‰²"""
        # æ”¹è¡Œã‚’ç©ºç™½ã«ç½®æ›
        text = text.replace('\n', ' ')
        
        # æ–‡æœ«è¨˜å·ã§åˆ†å‰²
        sentences = []
        current = ""
        
        for char in text:
            current += char
            if self.sentence_pattern.search(char):
                if current.strip():
                    sentences.append(current.strip())
                current = ""
        
        # æœ€å¾Œã®æ–‡ã‚’è¿½åŠ 
        if current.strip():
            sentences.append(current.strip())
        
        return sentences
    
    def _extract_metadata(self, text: str) -> Dict:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º"""
        metadata = {}
        
        # ã‚¿ã‚¤ãƒˆãƒ«
        title_match = re.search(r'ã€ã‚¿ã‚¤ãƒˆãƒ«ã€‘\s*(.*?)(?:\n|$)', text)
        if title_match:
            metadata['title'] = title_match.group(1).strip()
        
        # ä½œè€…
        author_match = re.search(r'ã€ä½œè€…ã€‘\s*(.*?)(?:\n|$)', text)
        if author_match:
            metadata['author'] = author_match.group(1).strip()
        
        # åº•æœ¬
        source_match = re.search(r'ã€åº•æœ¬ã€‘\s*(.*?)(?:\n|$)', text)
        if source_match:
            metadata['source'] = source_match.group(1).strip()
        
        # å…¥åŠ›
        input_match = re.search(r'ã€å…¥åŠ›ã€‘\s*(.*?)(?:\n|$)', text)
        if input_match:
            metadata['input'] = input_match.group(1).strip()
        
        # æ ¡æ­£
        proof_match = re.search(r'ã€æ ¡æ­£ã€‘\s*(.*?)(?:\n|$)', text)
        if proof_match:
            metadata['proof'] = proof_match.group(1).strip()
        
        return metadata
    
    def get_sentence_with_context(self, work_id: str, sentence: str, context_size: int = 1) -> tuple[str, str, str]:
        """æ–‡ã®å‰å¾Œæ–‡ã‚’å–å¾—"""
        return self.client.get_work_with_context(work_id, sentence, context_size) 
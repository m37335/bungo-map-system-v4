#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡æ›¸æ§‹é€ è§£æã‚·ã‚¹ãƒ†ãƒ  v4
æ–‡è±ªä½œå“ã®è¤‡é›‘ãªæ§‹é€ ï¼ˆç« ãƒ»ç¯€ãƒ»æ®µè½ãƒ»è©©æ­Œå½¢å¼ï¼‰ã‚’è‡ªå‹•èªè­˜ãƒ»è§£æ
"""

import re
import logging
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass
from enum import Enum
import unicodedata

logger = logging.getLogger(__name__)

class DocumentType(Enum):
    """æ–‡æ›¸ã‚¿ã‚¤ãƒ—"""
    NOVEL = "å°èª¬"
    SHORT_STORY = "çŸ­ç·¨"
    ESSAY = "éšç­†"
    POETRY = "è©©æ­Œ"
    TANKA = "çŸ­æ­Œ"
    HAIKU = "ä¿³å¥"
    DRAMA = "æˆ¯æ›²"
    LETTER = "æ›¸ç°¡"
    DIARY = "æ—¥è¨˜"
    CRITICISM = "è©•è«–"
    UNKNOWN = "ä¸æ˜"

class StructureType(Enum):
    """æ§‹é€ ã‚¿ã‚¤ãƒ—"""
    CHAPTER = "ç« "
    SECTION = "ç¯€"
    PARAGRAPH = "æ®µè½"
    VERSE = "è©©ç¯€"
    DIALOGUE = "å¯¾è©±"
    NARRATION = "åœ°ã®æ–‡"
    DESCRIPTION = "æå†™"
    MONOLOGUE = "ç‹¬ç™½"

@dataclass
class StructureElement:
    """æ§‹é€ è¦ç´ """
    type: StructureType
    content: str
    level: int
    line_start: int
    line_end: int
    char_start: int
    char_end: int
    metadata: Dict[str, Any]

@dataclass
class DocumentAnalysis:
    """æ–‡æ›¸è§£æçµæœ"""
    document_type: DocumentType
    title: str
    author: str
    structure_elements: List[StructureElement]
    metadata: Dict[str, Any]
    statistics: Dict[str, Any]
    confidence_score: float

class DocumentStructureAnalyzer:
    """æ–‡æ›¸æ§‹é€ è§£æã‚·ã‚¹ãƒ†ãƒ  v4"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        
        # ç« ãƒ»ç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.chapter_patterns = [
            # æ•°å­—ã«ã‚ˆã‚‹ç« ç«‹ã¦
            r'^[ã€€\s]*ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡å£±å¼å‚æ‹¾]*[ç« ç·¨éƒ¨å·»å†Œ][ã€€\s]*(.*)$',
            r'^[ã€€\s]*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡å£±å¼å‚æ‹¾]{1,4}[ã€€\s]*(.*)$',
            r'^[ã€€\s]*[ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼]{1,3}[ã€€\s]*(.*)$',
            r'^[ã€€\s]*[0-9]{1,3}[\.ã€\s][ã€€\s]*(.*)$',
            
            # æ–‡å­—ã«ã‚ˆã‚‹ç« ç«‹ã¦
            r'^[ã€€\s]*[åºç ´æ€¥ä¸Šä¸­ä¸‹å‰å¾Œå·¦å³ç”²ä¹™ä¸™ä¸][ç·¨éƒ¨å·»å†Œ][ã€€\s]*(.*)$',
            r'^[ã€€\s]*[æ˜¥å¤ç§‹å†¬][ã®ç« ç·¨][ã€€\s]*(.*)$',
            r'^[ã€€\s]*[æœæ˜¼å¤•å¤œ][ã®ç« ç·¨][ã€€\s]*(.*)$',
            
            # å°è¦‹å‡ºã—å½¢å¼
            r'^[ã€€\s]*ãã®[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]{1,3}[ã€€\s]*(.*)$',
            r'^[ã€€\s]*[åºç« çµ‚ç« åºæ–‡å¾Œæ›¸ãã¯ã˜ã‚ã«ãŠã‚ã‚Šã«][ã€€\s]*(.*)$',
            
            # ç‰¹æ®Šãªç« ç«‹ã¦
            r'^[ã€€\s]*[â—â—‹â—†â—‡â– â–¡â–²â–³â–¼â–½][ã€€\s]*(.*)$',
            r'^[ã€€\s]*[ï¼Šï¼Šï¼Šï¼Šï¼Š][ã€€\s]*(.*)$',
            r'^[ã€€\s]*[-ï¼=ï¼]{3,}[ã€€\s]*(.*)$',
        ]
        
        # è©©æ­Œãƒ‘ã‚¿ãƒ¼ãƒ³
        self.poetry_patterns = {
            'tanka': [
                r'^[ã€€\s]*[äº”ä¸ƒäº”ä¸ƒä¸ƒèª¿]',  # çŸ­æ­Œã®åŸºæœ¬å½¢
                r'[ã‚-ã‚“]{5,7}[ã€€\s]*[ã‚-ã‚“]{5,7}[ã€€\s]*[ã‚-ã‚“]{5,7}',  # ã²ã‚‰ãŒãªçŸ­æ­Œ
            ],
            'haiku': [
                r'^[ã€€\s]*[ã‚-ã‚“]{5,7}[ã€€\s]*[ã‚-ã‚“]{5,7}[ã€€\s]*[ã‚-ã‚“]{5,7}[ã€€\s]*$',  # ä¿³å¥
                r'[äº”ä¸ƒäº”èª¿]',
            ],
            'free_verse': [
                r'^[ã€€\s]*[^ã€‚ã€]*\n[ã€€\s]*[^ã€‚ã€]*\n[ã€€\s]*[^ã€‚ã€]*$',  # è‡ªç”±è©©
            ]
        }
        
        # å¯¾è©±ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.dialogue_patterns = [
            r'^[ã€€\s]*[ã€Œã€]([^ã€ã€]+)[ã€ã€]',  # åŸºæœ¬çš„ãªå¯¾è©±
            r'^[ã€€\s]*ã€Œ([^ã€]+)ã€\s*ã¨[^ã€‚]*[ã€‚]',  # ã€Œã€œã€ã¨è¨€ã£ãŸå½¢å¼
            r'^[ã€€\s]*ã€([^ã€]+)ã€',  # å¼•ç”¨ãƒ»æ€è€ƒ
            r'^[ã€€\s]*â€•([^â€•]+)â€•',  # ãƒ€ãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹å¯¾è©±
        ]
        
        # æ–‡ä½“ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.style_patterns = {
            'descriptive': [
                r'[ã¯].*[ã§ã‚ã‚‹]',  # ã§ã‚ã‚‹èª¿
                r'[ãŒ][ã€ã€‚].*[ã ]',  # ã èª¿
                r'[ç¾ã—ã„|ç¾ã—ã|éº—ã—ã„|å„ªé›…ãª|é™å¯‚ãª]',  # ç¾çš„æå†™
            ],
            'narrative': [
                r'[ç§|åƒ•|ä¿º|ã‚ãŸã—|ã‚ãŸãã—][ã¯|ãŒ]',  # ä¸€äººç§°
                r'[å½¼|å½¼å¥³|ãã®äºº][ã¯|ãŒ]',  # ä¸‰äººç§°
                r'[ã—ãŸ|ã ã£ãŸ|ã§ã‚ã£ãŸ][ã€‚]',  # éå»æ™‚åˆ¶
            ],
            'classical': [
                r'[ãªã‚Š|ã‘ã‚Š|ãŸã‚Š|ã¬|ã¤][ã€‚]',  # å¤å…¸èªå°¾
                r'[å€™|ãã†ã‚ã†|ã•ã¶ã‚‰ã„]',  # å€™æ–‡
                r'[ã‹ãª|å“‰|å“‰][ã€‚]',  # æ„Ÿå˜†ã®å¤èª
            ]
        }
        
        # æ–‡æ›¸ã‚¿ã‚¤ãƒ—åˆ¤å®šãƒ‘ã‚¿ãƒ¼ãƒ³
        self.document_type_patterns = {
            DocumentType.NOVEL: [
                r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ç« ',
                r'[æ˜¥å¤ç§‹å†¬]ã®[ç« ç·¨]',
                r'[ä¸Šä¸­ä¸‹][å·»ç·¨]',
                r'[åºç ´æ€¥][ç·¨]',
            ],
            DocumentType.SHORT_STORY: [
                r'^[ã€€\s]*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]$',
                r'ãã®[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]',
                r'[â—â—‹â—†][ã€€\s]*',
            ],
            DocumentType.POETRY: [
                r'^[ã‚-ã‚“]{5,7}$',  # ã²ã‚‰ãŒãªè¡Œ
                r'^[ã€€\s]*[^ã€‚ã€]+[ã€€\s]*$',  # å¥ç‚¹ãªã—çŸ­è¡Œ
                r'[äº”ä¸ƒäº”|ä¸ƒäº”èª¿]',
            ],
            DocumentType.DRAMA: [
                r'^[ã€€\s]*[A-Za-z][^ï¼š]*ï¼š',  # ç™»å ´äººç‰©åï¼š
                r'^[ã€€\s]*[ä¸€-é¾¯]+[ï¼š]',  # æ¼¢å­—åï¼š
                r'[å¹•å ´]ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+',
            ],
            DocumentType.ESSAY: [
                r'ã«ã¤ã„ã¦',
                r'ã«é–¢ã—ã¦',
                r'ã‚’è«–ã˜ã‚‹',
                r'è€ƒå¯Ÿ',
            ]
        }
        
        logger.info("ğŸ“– æ–‡æ›¸æ§‹é€ è§£æã‚·ã‚¹ãƒ†ãƒ  v4 åˆæœŸåŒ–å®Œäº†")
    
    def analyze_document_structure(self, text: str, author_hint: str = "", title_hint: str = "") -> DocumentAnalysis:
        """æ–‡æ›¸æ§‹é€ ã®åŒ…æ‹¬çš„è§£æ"""
        
        if not text:
            return self._create_empty_analysis()
        
        lines = text.split('\n')
        
        # åŸºæœ¬æƒ…å ±æŠ½å‡º
        title = self._extract_title(text, title_hint)
        author = self._extract_author(text, author_hint)
        
        # æ–‡æ›¸ã‚¿ã‚¤ãƒ—åˆ¤å®š
        document_type = self._determine_document_type(text)
        
        # æ§‹é€ è¦ç´ æŠ½å‡º
        structure_elements = self._extract_structure_elements(lines, document_type)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        metadata = self._extract_metadata(text, lines)
        
        # çµ±è¨ˆè¨ˆç®—
        statistics = self._calculate_statistics(text, structure_elements)
        
        # ä¿¡é ¼åº¦è¨ˆç®—
        confidence_score = self._calculate_confidence(text, structure_elements, document_type)
        
        analysis = DocumentAnalysis(
            document_type=document_type,
            title=title,
            author=author,
            structure_elements=structure_elements,
            metadata=metadata,
            statistics=statistics,
            confidence_score=confidence_score
        )
        
        logger.info(f"ğŸ“– æ–‡æ›¸è§£æå®Œäº†: ã‚¿ã‚¤ãƒ—={document_type.value}, æ§‹é€ è¦ç´ ={len(structure_elements)}å€‹")
        
        return analysis
    
    def _extract_title(self, text: str, hint: str = "") -> str:
        """ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡º"""
        
        if hint:
            return hint
        
        lines = text.split('\n')[:20]  # æœ€åˆã®20è¡Œã‚’ç¢ºèª
        
        for line in lines:
            line = line.strip()
            
            # æ˜ç¤ºçš„ãªã‚¿ã‚¤ãƒˆãƒ«è¡¨è¨˜
            title_patterns = [
                r'^ä½œå“å[ï¼š:]\s*(.+)$',
                r'^é¡Œå[ï¼š:]\s*(.+)$',
                r'^ã‚¿ã‚¤ãƒˆãƒ«[ï¼š:]\s*(.+)$',
                r'^Title[ï¼š:]\s*(.+)$',
            ]
            
            for pattern in title_patterns:
                match = re.match(pattern, line)
                if match:
                    return match.group(1).strip()
            
            # æ¨å®šã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæœ€åˆã®éç©ºè¡Œã§çŸ­ã„ã‚‚ã®ï¼‰
            if line and len(line) <= 50 and not self._is_metadata_line(line):
                return line
        
        return "ä¸æ˜"
    
    def _extract_author(self, text: str, hint: str = "") -> str:
        """è‘—è€…æŠ½å‡º"""
        
        if hint:
            return hint
        
        lines = text.split('\n')[:20]
        
        for line in lines:
            line = line.strip()
            
            # æ˜ç¤ºçš„ãªè‘—è€…è¡¨è¨˜
            author_patterns = [
                r'^è‘—è€…å[ï¼š:]\s*(.+)$',
                r'^ä½œè€…[ï¼š:]\s*(.+)$',
                r'^ä½œå®¶å[ï¼š:]\s*(.+)$',
                r'^Author[ï¼š:]\s*(.+)$',
                r'^by\s+(.+)$',
            ]
            
            for pattern in author_patterns:
                match = re.match(pattern, line, re.IGNORECASE)
                if match:
                    return match.group(1).strip()
        
        return "ä¸æ˜"
    
    def _determine_document_type(self, text: str) -> DocumentType:
        """æ–‡æ›¸ã‚¿ã‚¤ãƒ—åˆ¤å®š"""
        
        scores = {doc_type: 0 for doc_type in DocumentType}
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã«ã‚ˆã‚‹åˆ¤å®š
        for doc_type, patterns in self.document_type_patterns.items():
            for pattern in patterns:
                matches = len(re.findall(pattern, text, re.MULTILINE))
                scores[doc_type] += matches
        
        # è¿½åŠ çš„ãªåˆ¤å®šåŸºæº–
        lines = text.split('\n')
        
        # è©©æ­Œã®åˆ¤å®š
        short_lines = sum(1 for line in lines if line.strip() and len(line.strip()) < 20)
        if short_lines > len(lines) * 0.6:
            scores[DocumentType.POETRY] += 10
        
        # å¯¾è©±ã®å¤šã•ã§æˆ¯æ›²åˆ¤å®š
        dialogue_lines = sum(1 for line in lines if any(re.match(p, line) for p in self.dialogue_patterns))
        if dialogue_lines > len(lines) * 0.3:
            scores[DocumentType.DRAMA] += 5
        
        # é•·ã•ã§å°èª¬ãƒ»çŸ­ç·¨åˆ¤å®š
        if len(text) > 10000:
            scores[DocumentType.NOVEL] += 3
        elif len(text) > 3000:
            scores[DocumentType.SHORT_STORY] += 3
        
        # æœ€é«˜ã‚¹ã‚³ã‚¢ã®æ–‡æ›¸ã‚¿ã‚¤ãƒ—ã‚’è¿”ã™
        best_type = max(scores, key=scores.get)
        
        if scores[best_type] == 0:
            return DocumentType.UNKNOWN
        
        return best_type
    
    def _extract_structure_elements(self, lines: List[str], doc_type: DocumentType) -> List[StructureElement]:
        """æ§‹é€ è¦ç´ ã®æŠ½å‡º"""
        
        elements = []
        char_position = 0
        
        for line_num, line in enumerate(lines):
            original_line = line
            line = line.strip()
            
            if not line:
                char_position += len(original_line) + 1
                continue
            
            # ç« ãƒ»ç¯€ã®æ¤œå‡º
            chapter_element = self._detect_chapter(line, line_num, char_position)
            if chapter_element:
                elements.append(chapter_element)
            
            # æ®µè½ã®æ¤œå‡º
            elif self._is_paragraph_start(line, doc_type):
                para_element = StructureElement(
                    type=StructureType.PARAGRAPH,
                    content=line,
                    level=0,
                    line_start=line_num,
                    line_end=line_num,
                    char_start=char_position,
                    char_end=char_position + len(line),
                    metadata={'paragraph_type': 'standard'}
                )
                elements.append(para_element)
            
            # å¯¾è©±ã®æ¤œå‡º
            dialogue_element = self._detect_dialogue(line, line_num, char_position)
            if dialogue_element:
                elements.append(dialogue_element)
            
            # è©©æ­Œã®æ¤œå‡º
            if doc_type == DocumentType.POETRY:
                verse_element = self._detect_verse(line, line_num, char_position)
                if verse_element:
                    elements.append(verse_element)
            
            char_position += len(original_line) + 1
        
        # éšå±¤æ§‹é€ ã®æ§‹ç¯‰
        elements = self._build_hierarchy(elements)
        
        return elements
    
    def _detect_chapter(self, line: str, line_num: int, char_pos: int) -> Optional[StructureElement]:
        """ç« ãƒ»ç¯€ã®æ¤œå‡º"""
        
        for level, pattern in enumerate(self.chapter_patterns):
            match = re.match(pattern, line)
            if match:
                title = match.group(1).strip() if match.groups() else ""
                
                return StructureElement(
                    type=StructureType.CHAPTER if level < 4 else StructureType.SECTION,
                    content=line,
                    level=level,
                    line_start=line_num,
                    line_end=line_num,
                    char_start=char_pos,
                    char_end=char_pos + len(line),
                    metadata={
                        'title': title,
                        'pattern_level': level,
                        'structural_marker': True
                    }
                )
        
        return None
    
    def _detect_dialogue(self, line: str, line_num: int, char_pos: int) -> Optional[StructureElement]:
        """å¯¾è©±ã®æ¤œå‡º"""
        
        for pattern in self.dialogue_patterns:
            match = re.match(pattern, line)
            if match:
                dialogue_text = match.group(1) if match.groups() else line
                
                return StructureElement(
                    type=StructureType.DIALOGUE,
                    content=line,
                    level=0,
                    line_start=line_num,
                    line_end=line_num,
                    char_start=char_pos,
                    char_end=char_pos + len(line),
                    metadata={
                        'dialogue_text': dialogue_text,
                        'speech_type': 'direct'
                    }
                )
        
        return None
    
    def _detect_verse(self, line: str, line_num: int, char_pos: int) -> Optional[StructureElement]:
        """è©©æ­Œã®æ¤œå‡º"""
        
        # çŸ­æ­Œãƒ»ä¿³å¥ã®æ¤œå‡º
        for verse_type, patterns in self.poetry_patterns.items():
            for pattern in patterns:
                if re.match(pattern, line):
                    return StructureElement(
                        type=StructureType.VERSE,
                        content=line,
                        level=0,
                        line_start=line_num,
                        line_end=line_num,
                        char_start=char_pos,
                        char_end=char_pos + len(line),
                        metadata={
                            'verse_type': verse_type,
                            'syllable_count': len(re.sub(r'[^ã‚-ã‚“]', '', line))
                        }
                    )
        
        return None
    
    def _is_paragraph_start(self, line: str, doc_type: DocumentType) -> bool:
        """æ®µè½é–‹å§‹ã®åˆ¤å®š"""
        
        # è©©æ­Œã®å ´åˆã¯æ®µè½æ¦‚å¿µãŒç•°ãªã‚‹
        if doc_type in [DocumentType.POETRY, DocumentType.TANKA, DocumentType.HAIKU]:
            return False
        
        # æ¨™æº–çš„ãªæ®µè½é–‹å§‹
        paragraph_indicators = [
            r'^[ã€€\s]+[^ã€€\s]',  # ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚ã‚Š
            r'^[ç§åƒ•ä¿ºå½¼å½¼å¥³]',  # ä¸»èªã‹ã‚‰é–‹å§‹
            r'^[ãã®æ™‚ã‚ã‚‹]',    # æ™‚é–“è¡¨ç¾
            r'^[ã—ã‹ã—ã ãŒã¨ã“ã‚ãŒ]',  # æ¥ç¶šè©
        ]
        
        for pattern in paragraph_indicators:
            if re.match(pattern, line):
                return True
        
        return False
    
    def _build_hierarchy(self, elements: List[StructureElement]) -> List[StructureElement]:
        """éšå±¤æ§‹é€ ã®æ§‹ç¯‰"""
        
        if not elements:
            return elements
        
        # ç« ãƒ»ç¯€è¦ç´ ã®ãƒ¬ãƒ™ãƒ«ã«åŸºã¥ã„ã¦è¦ªå­é–¢ä¿‚ã‚’æ§‹ç¯‰
        hierarchical_elements = []
        current_chapter = None
        current_section = None
        
        for element in elements:
            if element.type == StructureType.CHAPTER:
                current_chapter = element
                current_section = None
                element.metadata['children'] = []
                hierarchical_elements.append(element)
            
            elif element.type == StructureType.SECTION:
                if current_chapter:
                    current_chapter.metadata['children'].append(element)
                    element.metadata['parent'] = current_chapter
                current_section = element
                hierarchical_elements.append(element)
            
            else:
                # ãã®ä»–ã®è¦ç´ ã¯ç¾åœ¨ã®ç¯€ã¾ãŸã¯ç« ã«å±ã™ã‚‹
                if current_section:
                    current_section.metadata.setdefault('children', []).append(element)
                    element.metadata['parent'] = current_section
                elif current_chapter:
                    current_chapter.metadata.setdefault('children', []).append(element)
                    element.metadata['parent'] = current_chapter
                
                hierarchical_elements.append(element)
        
        return hierarchical_elements
    
    def _extract_metadata(self, text: str, lines: List[str]) -> Dict[str, Any]:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡º"""
        
        metadata = {}
        
        # åŸºæœ¬çµ±è¨ˆ
        metadata['total_chars'] = len(text)
        metadata['total_lines'] = len(lines)
        metadata['non_empty_lines'] = len([line for line in lines if line.strip()])
        
        # æ–‡ä½“åˆ†æ
        metadata['style_analysis'] = self._analyze_writing_style(text)
        
        # æ™‚ä»£æ€§ã®åˆ†æ
        metadata['period_analysis'] = self._analyze_historical_period(text)
        
        # æ–‡å­—ä½¿ç”¨çµ±è¨ˆ
        metadata['character_stats'] = self._analyze_character_usage(text)
        
        return metadata
    
    def _analyze_writing_style(self, text: str) -> Dict[str, Any]:
        """æ–‡ä½“åˆ†æ"""
        
        style_scores = {}
        
        for style_type, patterns in self.style_patterns.items():
            score = 0
            for pattern in patterns:
                matches = len(re.findall(pattern, text))
                score += matches
            style_scores[style_type] = score
        
        total_score = sum(style_scores.values())
        if total_score > 0:
            style_ratios = {k: v/total_score for k, v in style_scores.items()}
        else:
            style_ratios = style_scores
        
        return {
            'scores': style_scores,
            'ratios': style_ratios,
            'dominant_style': max(style_scores, key=style_scores.get) if style_scores else 'unknown'
        }
    
    def _analyze_historical_period(self, text: str) -> Dict[str, Any]:
        """æ™‚ä»£æ€§åˆ†æ"""
        
        period_indicators = {
            'classical': [r'[ãªã‚Š|ã‘ã‚Š|ãŸã‚Š|ã¬|ã¤]', r'[å€™|ãã†ã‚ã†]', r'[ã‹ãª|å“‰]'],
            'modern': [r'ã§ã‚ã‚‹', r'ã§ã—ãŸ', r'ã—ã¾ã™'],
            'contemporary': [r'ã [ã€‚]', r'ã§ã‚ã‚‹[ã€‚]', r'ã§ã™[ã€‚]']
        }
        
        period_scores = {}
        for period, patterns in period_indicators.items():
            score = sum(len(re.findall(pattern, text)) for pattern in patterns)
            period_scores[period] = score
        
        return {
            'scores': period_scores,
            'estimated_period': max(period_scores, key=period_scores.get) if period_scores else 'unknown'
        }
    
    def _analyze_character_usage(self, text: str) -> Dict[str, Any]:
        """æ–‡å­—ä½¿ç”¨çµ±è¨ˆ"""
        
        stats = {
            'hiragana': len(re.findall(r'[ã‚-ã‚“]', text)),
            'katakana': len(re.findall(r'[ã‚¢-ãƒ³]', text)),
            'kanji': len(re.findall(r'[ä¸€-é¾¯]', text)),
            'ascii': len(re.findall(r'[a-zA-Z0-9]', text)),
            'punctuation': len(re.findall(r'[ã€‚ã€ï¼ï¼Ÿ]', text)),
        }
        
        total_chars = sum(stats.values())
        if total_chars > 0:
            ratios = {k: v/total_chars for k, v in stats.items()}
        else:
            ratios = {k: 0 for k in stats.keys()}
        
        return {
            'counts': stats,
            'ratios': ratios,
            'total_analyzed': total_chars
        }
    
    def _calculate_statistics(self, text: str, elements: List[StructureElement]) -> Dict[str, Any]:
        """çµ±è¨ˆè¨ˆç®—"""
        
        element_counts = {}
        for element in elements:
            element_type = element.type.value
            element_counts[element_type] = element_counts.get(element_type, 0) + 1
        
        # å¹³å‡æ–‡é•·
        sentences = text.split('ã€‚')
        avg_sentence_length = sum(len(s.strip()) for s in sentences if s.strip()) / len(sentences) if sentences else 0
        
        # æ®µè½çµ±è¨ˆ
        paragraphs = text.split('\n\n')
        avg_paragraph_length = sum(len(p.strip()) for p in paragraphs if p.strip()) / len(paragraphs) if paragraphs else 0
        
        return {
            'element_counts': element_counts,
            'total_elements': len(elements),
            'avg_sentence_length': round(avg_sentence_length, 2),
            'avg_paragraph_length': round(avg_paragraph_length, 2),
            'structural_complexity': len(element_counts),
        }
    
    def _calculate_confidence(self, text: str, elements: List[StructureElement], doc_type: DocumentType) -> float:
        """ä¿¡é ¼åº¦è¨ˆç®—"""
        
        confidence_factors = {
            'text_length': min(1.0, len(text) / 1000),  # 1000æ–‡å­—ã§æº€ç‚¹
            'structure_detected': min(1.0, len(elements) / 10),  # 10è¦ç´ ã§æº€ç‚¹
            'type_confidence': 0.8 if doc_type != DocumentType.UNKNOWN else 0.2,
            'pattern_matches': 0.0,
        }
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒã®ä¿¡é ¼åº¦
        if doc_type in self.document_type_patterns:
            pattern_matches = 0
            for pattern in self.document_type_patterns[doc_type]:
                pattern_matches += len(re.findall(pattern, text))
            confidence_factors['pattern_matches'] = min(1.0, pattern_matches / 5)
        
        # é‡ã¿ä»˜ãä¿¡é ¼åº¦
        weights = {
            'text_length': 0.2,
            'structure_detected': 0.3,
            'type_confidence': 0.3,
            'pattern_matches': 0.2,
        }
        
        confidence = sum(confidence_factors[key] * weights[key] for key in weights)
        
        return round(confidence, 3)
    
    def _is_metadata_line(self, line: str) -> bool:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¡Œã®åˆ¤å®š"""
        
        metadata_patterns = [
            r'^ä½œå“å[ï¼š:]',
            r'^è‘—è€…å[ï¼š:]',
            r'^åˆ†é¡[ï¼š:]',
            r'^åˆå‡º[ï¼š:]',
            r'^åº•æœ¬[ï¼š:]',
            r'é’ç©ºæ–‡åº«',
            r'^[-=]{3,}$',
            r'^â€»',
        ]
        
        for pattern in metadata_patterns:
            if re.match(pattern, line):
                return True
        
        return False
    
    def _create_empty_analysis(self) -> DocumentAnalysis:
        """ç©ºã®è§£æçµæœä½œæˆ"""
        return DocumentAnalysis(
            document_type=DocumentType.UNKNOWN,
            title="ä¸æ˜",
            author="ä¸æ˜",
            structure_elements=[],
            metadata={},
            statistics={},
            confidence_score=0.0
        )
    
    def export_structure_analysis(self, analysis: DocumentAnalysis, format: str = 'dict') -> Any:
        """æ§‹é€ è§£æçµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        
        if format == 'dict':
            return {
                'document_type': analysis.document_type.value,
                'title': analysis.title,
                'author': analysis.author,
                'structure_elements': [
                    {
                        'type': elem.type.value,
                        'content': elem.content[:100] + '...' if len(elem.content) > 100 else elem.content,
                        'level': elem.level,
                        'line_range': f"{elem.line_start}-{elem.line_end}",
                        'char_range': f"{elem.char_start}-{elem.char_end}",
                        'metadata': elem.metadata
                    }
                    for elem in analysis.structure_elements
                ],
                'metadata': analysis.metadata,
                'statistics': analysis.statistics,
                'confidence_score': analysis.confidence_score
            }
        
        elif format == 'summary':
            return {
                'title': analysis.title,
                'author': analysis.author,
                'type': analysis.document_type.value,
                'structure_summary': {
                    elem_type.value: len([e for e in analysis.structure_elements if e.type == elem_type])
                    for elem_type in set(elem.type for elem in analysis.structure_elements)
                },
                'confidence': analysis.confidence_score
            }
        
        else:
            return analysis

def main():
    """æ–‡æ›¸æ§‹é€ è§£æã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    
    analyzer = DocumentStructureAnalyzer()
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ
    sample_text = """
ä½œå“åï¼šç¾…ç”Ÿé–€
è‘—è€…åï¼šèŠ¥å·é¾ä¹‹ä»‹

ä¸€

ã€€ã‚ã‚‹æ—¥ã®æš®æ–¹ã®äº‹ã§ã‚ã‚‹ã€‚ä¸€äººã®ä¸‹äººãŒã€ç¾…ç”Ÿé–€ã®ä¸‹ã§é›¨ã‚„ã¿ã‚’å¾…ã£ã¦ã„ãŸã€‚
ã€€åºƒã„é–€ã®ä¸‹ã«ã¯ã€ã“ã®ç”·ã®ã»ã‹ã«èª°ã‚‚ã„ãªã„ã€‚

äºŒ

ã€€ä¸‹äººã¯ã€é›¨ã‚’ã¤ãã¥ãã¨è¦‹ã¦ã„ãŸã€‚
ã€Œå›°ã£ãŸã“ã¨ã«ãªã£ãŸã€ã¨æ€ã£ãŸã€‚
    """
    
    analysis = analyzer.analyze_document_structure(sample_text)
    
    print("ğŸ“– æ–‡æ›¸æ§‹é€ è§£æçµæœ:")
    summary = analyzer.export_structure_analysis(analysis, 'summary')
    for key, value in summary.items():
        print(f"  {key}: {value}")
    
    return analysis

if __name__ == '__main__':
    main() 
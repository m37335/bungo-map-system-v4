#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ v4
å…¨ã‚·ã‚¹ãƒ†ãƒ æ©Ÿèƒ½ã®åŒ…æ‹¬çš„å‹•ä½œç¢ºèªãƒ»å“è³ªä¿è¨¼
"""

import os
import sys
import time
import logging
import subprocess
import psutil
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from datetime import datetime
import json

# Rich UIã‚µãƒãƒ¼ãƒˆ
try:
    from rich.console import Console
    from rich.table import Table
    from rich.progress import Progress
    from rich.panel import Panel
    from rich.columns import Columns
    from rich.tree import Tree
    console = Console()
    RICH_AVAILABLE = True
except ImportError:
    console = None
    RICH_AVAILABLE = False

logger = logging.getLogger(__name__)

class IntegrationTestSuite:
    """çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    def __init__(self):
        self.test_results = {}
        self.performance_metrics = {}
        self.error_log = []
        self.start_time = None
        self.base_path = Path(__file__).parent.parent.parent.parent
        
    def run_full_test_suite(self) -> Dict[str, Any]:
        """ãƒ•ãƒ«çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        if RICH_AVAILABLE:
            console.print("[bold green]ğŸ§ª çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ v4 é–‹å§‹[/bold green]")
        
        self.start_time = time.time()
        
        # ãƒ†ã‚¹ãƒˆã‚«ãƒ†ã‚´ãƒªãƒ¼
        test_categories = [
            ('system_health', 'ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯'),
            ('cli_integration', 'ğŸ–¥ï¸ CLIçµ±åˆãƒ†ã‚¹ãƒˆ'),
            ('ai_system', 'ğŸ¤– AIæ©Ÿèƒ½çµ±åˆãƒ†ã‚¹ãƒˆ'),
            ('data_pipeline', 'ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆ'),
            ('performance', 'âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ'),
            ('error_handling', 'ğŸ›¡ï¸ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°'),
            ('memory_usage', 'ğŸ’¾ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒ†ã‚¹ãƒˆ'),
            ('concurrent_ops', 'ğŸ”„ ä¸¦è¡Œå‡¦ç†ãƒ†ã‚¹ãƒˆ')
        ]
        
        overall_results = {}
        
        if RICH_AVAILABLE:
            with Progress() as progress:
                main_task = progress.add_task("çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...", total=len(test_categories))
                
                for category, description in test_categories:
                    progress.update(main_task, description=f"å®Ÿè¡Œä¸­: {description}")
                    
                    result = self._run_test_category(category)
                    overall_results[category] = result
                    
                    progress.update(main_task, advance=1)
        else:
            for category, description in test_categories:
                print(f"å®Ÿè¡Œä¸­: {description}")
                result = self._run_test_category(category)
                overall_results[category] = result
        
        # ç·åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self._generate_integration_report(overall_results)
        
        return overall_results
    
    def _run_test_category(self, category: str) -> Dict[str, Any]:
        """ãƒ†ã‚¹ãƒˆã‚«ãƒ†ã‚´ãƒªãƒ¼å®Ÿè¡Œ"""
        if category == 'system_health':
            return self._test_system_health()
        elif category == 'cli_integration':
            return self._test_cli_integration()
        elif category == 'ai_system':
            return self._test_ai_system()
        elif category == 'data_pipeline':
            return self._test_data_pipeline()
        elif category == 'performance':
            return self._test_performance()
        elif category == 'error_handling':
            return self._test_error_handling()
        elif category == 'memory_usage':
            return self._test_memory_usage()
        elif category == 'concurrent_ops':
            return self._test_concurrent_operations()
        else:
            return {'success': False, 'error': f'Unknown category: {category}'}
    
    def _test_system_health(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        health_checks = []
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        required_files = [
            'src/bungo_map/ai/ai_manager.py',
            'src/bungo_map/cli/search_cli.py',
            'src/bungo_map/cli/export_cli.py',
            'src/bungo_map/cli/geocode_cli.py',
            'src/bungo_map/cli/aozora_cli.py',
            'src/bungo_map/cli/expand_cli.py',
            'src/bungo_map/cli/add_cli.py'
        ]
        
        file_check_success = 0
        for file_path in required_files:
            full_path = self.base_path / file_path
            if full_path.exists():
                file_check_success += 1
                health_checks.append(f"âœ… {file_path}")
            else:
                health_checks.append(f"âŒ {file_path}")
        
        # Pythonç’°å¢ƒç¢ºèª
        python_version = sys.version_info
        python_ok = python_version.major == 3 and python_version.minor >= 8
        health_checks.append(f"{'âœ…' if python_ok else 'âŒ'} Python {python_version.major}.{python_version.minor}")
        
        # ä¾å­˜é–¢ä¿‚ç¢ºèª
        dependencies = ['click', 'rich', 'psutil']
        deps_ok = 0
        for dep in dependencies:
            try:
                __import__(dep)
                health_checks.append(f"âœ… {dep}")
                deps_ok += 1
            except ImportError:
                health_checks.append(f"âŒ {dep}")
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç¢ºèª
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        memory_ok = memory.available > 1024 * 1024 * 1024  # 1GBä»¥ä¸Š
        disk_ok = disk.free > 1024 * 1024 * 1024  # 1GBä»¥ä¸Š
        
        health_checks.append(f"{'âœ…' if memory_ok else 'âŒ'} ãƒ¡ãƒ¢ãƒª: {memory.available / 1024**3:.1f}GBåˆ©ç”¨å¯èƒ½")
        health_checks.append(f"{'âœ…' if disk_ok else 'âŒ'} ãƒ‡ã‚£ã‚¹ã‚¯: {disk.free / 1024**3:.1f}GBåˆ©ç”¨å¯èƒ½")
        
        success_rate = (file_check_success + deps_ok + int(python_ok) + int(memory_ok) + int(disk_ok)) / (len(required_files) + len(dependencies) + 3)
        
        return {
            'success': success_rate >= 0.8,
            'success_rate': success_rate,
            'checks': health_checks,
            'details': {
                'files_ok': f"{file_check_success}/{len(required_files)}",
                'deps_ok': f"{deps_ok}/{len(dependencies)}",
                'python_ok': python_ok,
                'resources_ok': memory_ok and disk_ok
            }
        }
    
    def _test_cli_integration(self) -> Dict[str, Any]:
        """CLIçµ±åˆãƒ†ã‚¹ãƒˆ"""
        cli_tests = [
            ('search', 'python src/bungo_map/cli/search_cli.py --help'),
            ('export', 'python src/bungo_map/cli/export_cli.py --help'),
            ('geocode', 'python src/bungo_map/cli/geocode_cli.py --help'),
            ('aozora', 'python src/bungo_map/cli/aozora_cli.py --help'),
            ('expand', 'python src/bungo_map/cli/expand_cli.py --help'),
            ('add', 'python src/bungo_map/cli/add_cli.py --help')
        ]
        
        results = []
        success_count = 0
        
        for cli_name, command in cli_tests:
            try:
                result = subprocess.run(
                    command.split(),
                    cwd=self.base_path,
                    capture_output=True,
                    text=True,
                    timeout=10
                )
                
                if result.returncode == 0:
                    results.append(f"âœ… {cli_name} CLI")
                    success_count += 1
                else:
                    results.append(f"âŒ {cli_name} CLI")
                    
            except Exception as e:
                results.append(f"âŒ {cli_name} CLI - {str(e)[:50]}")
        
        # æ©Ÿèƒ½åˆ¥ãƒ†ã‚¹ãƒˆ
        functional_tests = [
            ('search_places', 'python src/bungo_map/cli/search_cli.py places æ±äº¬ --limit 3'),
            ('export_csv', 'python src/bungo_map/cli/export_cli.py csv test_integration.csv --format places'),
            ('geocode_single', 'python src/bungo_map/cli/geocode_cli.py single æ±äº¬é§…'),
            ('expand_stats', 'python src/bungo_map/cli/expand_cli.py stats')
        ]
        
        for test_name, command in functional_tests:
            try:
                result = subprocess.run(
                    command.split(),
                    cwd=self.base_path,
                    capture_output=True,
                    text=True,
                    timeout=15
                )
                
                if result.returncode == 0:
                    results.append(f"âœ… {test_name}")
                    success_count += 1
                else:
                    results.append(f"âŒ {test_name}")
                    
            except Exception as e:
                results.append(f"âŒ {test_name} - {str(e)[:50]}")
        
        total_tests = len(cli_tests) + len(functional_tests)
        success_rate = success_count / total_tests
        
        return {
            'success': success_rate >= 0.8,
            'success_rate': success_rate,
            'results': results,
            'total_tests': total_tests,
            'passed': success_count
        }
    
    def _test_ai_system(self) -> Dict[str, Any]:
        """AIæ©Ÿèƒ½çµ±åˆãƒ†ã‚¹ãƒˆ"""
        try:
            sys.path.append(str(self.base_path / 'src'))
            from bungo_map.ai.ai_manager import AIManager
            
            ai_manager = AIManager()
            
            # AIæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
            tests = []
            success_count = 0
            
            # 1. åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ
            try:
                if ai_manager:
                    tests.append("âœ… AI ManageråˆæœŸåŒ–")
                    success_count += 1
                else:
                    tests.append("âŒ AI ManageråˆæœŸåŒ–")
            except Exception as e:
                tests.append(f"âŒ AI ManageråˆæœŸåŒ– - {str(e)[:50]}")
            
            # 2. æ¥ç¶šãƒ†ã‚¹ãƒˆ
            try:
                connection_result = ai_manager.test_connection()
                if connection_result.get('success', False):
                    tests.append("âœ… APIæ¥ç¶šãƒ†ã‚¹ãƒˆ")
                    success_count += 1
                else:
                    tests.append("âŒ APIæ¥ç¶šãƒ†ã‚¹ãƒˆ")
            except Exception as e:
                tests.append(f"âŒ APIæ¥ç¶šãƒ†ã‚¹ãƒˆ - {str(e)[:50]}")
            
            # 3. ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ†ã‚¹ãƒˆ
            try:
                sample_data = [
                    {'place_name': 'æ±äº¬', 'confidence': 0.95, 'category': 'major_city'},
                    {'place_name': 'äº¬éƒ½', 'confidence': 0.90, 'category': 'major_city'}
                ]
                analysis = ai_manager.analyze_place_data(sample_data)
                
                if analysis and 'quality_score' in analysis:
                    tests.append("âœ… ãƒ‡ãƒ¼ã‚¿åˆ†ææ©Ÿèƒ½")
                    success_count += 1
                else:
                    tests.append("âŒ ãƒ‡ãƒ¼ã‚¿åˆ†ææ©Ÿèƒ½")
            except Exception as e:
                tests.append(f"âŒ ãƒ‡ãƒ¼ã‚¿åˆ†ææ©Ÿèƒ½ - {str(e)[:50]}")
            
            # 4. çµ±è¨ˆç”Ÿæˆãƒ†ã‚¹ãƒˆ
            try:
                stats = ai_manager.get_statistics()
                if stats:
                    tests.append("âœ… çµ±è¨ˆç”Ÿæˆæ©Ÿèƒ½")
                    success_count += 1
                else:
                    tests.append("âŒ çµ±è¨ˆç”Ÿæˆæ©Ÿèƒ½")
            except Exception as e:
                tests.append(f"âŒ çµ±è¨ˆç”Ÿæˆæ©Ÿèƒ½ - {str(e)[:50]}")
            
            total_tests = 4
            success_rate = success_count / total_tests
            
            return {
                'success': success_rate >= 0.75,
                'success_rate': success_rate,
                'tests': tests,
                'total_tests': total_tests,
                'passed': success_count
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f"AI ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}",
                'tests': [f"âŒ AI ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ - {str(e)[:50]}"]
            }
    
    def _test_data_pipeline(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆãƒ†ã‚¹ãƒˆ"""
        pipeline_tests = []
        success_count = 0
        
        # 1. åœ°åæŠ½å‡ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
        try:
            sys.path.append(str(self.base_path / 'src'))
            
            # æŠ½å‡ºå™¨å­˜åœ¨ç¢ºèª
            extractor_files = [
                'src/bungo_map/extractors_v4/ginza_place_extractor.py',
                'src/bungo_map/extractors_v4/enhanced_place_extractor.py',
                'src/bungo_map/extractors_v4/advanced_place_extractor.py'
            ]
            
            extractor_count = 0
            for extractor_file in extractor_files:
                if (self.base_path / extractor_file).exists():
                    extractor_count += 1
            
            if extractor_count >= 2:
                pipeline_tests.append("âœ… åœ°åæŠ½å‡ºå™¨ç¾¤")
                success_count += 1
            else:
                pipeline_tests.append("âŒ åœ°åæŠ½å‡ºå™¨ç¾¤")
                
        except Exception as e:
            pipeline_tests.append(f"âŒ åœ°åæŠ½å‡ºå™¨ç¾¤ - {str(e)[:50]}")
        
        # 2. ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
        try:
            # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
            export_result = subprocess.run(
                ['python', 'src/bungo_map/cli/export_cli.py', 'stats'],
                cwd=self.base_path,
                capture_output=True,
                text=True,
                timeout=10
            )
            
            if export_result.returncode == 0:
                pipeline_tests.append("âœ… ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
                success_count += 1
            else:
                pipeline_tests.append("âŒ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
                
        except Exception as e:
            pipeline_tests.append(f"âŒ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ - {str(e)[:50]}")
        
        # 3. ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
        try:
            geocode_result = subprocess.run(
                ['python', 'src/bungo_map/cli/geocode_cli.py', 'stats'],
                cwd=self.base_path,
                capture_output=True,
                text=True,
                timeout=10
            )
            
            if geocode_result.returncode == 0:
                pipeline_tests.append("âœ… ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°")
                success_count += 1
            else:
                pipeline_tests.append("âŒ ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°")
                
        except Exception as e:
            pipeline_tests.append(f"âŒ ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° - {str(e)[:50]}")
        
        # 4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ‹¡å¼µãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
        try:
            expand_result = subprocess.run(
                ['python', 'src/bungo_map/cli/expand_cli.py', 'stats'],
                cwd=self.base_path,
                capture_output=True,
                text=True,
                timeout=10
            )
            
            if expand_result.returncode == 0:
                pipeline_tests.append("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ‹¡å¼µ")
                success_count += 1
            else:
                pipeline_tests.append("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ‹¡å¼µ")
                
        except Exception as e:
            pipeline_tests.append(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ‹¡å¼µ - {str(e)[:50]}")
        
        total_tests = 4
        success_rate = success_count / total_tests
        
        return {
            'success': success_rate >= 0.75,
            'success_rate': success_rate,
            'tests': pipeline_tests,
            'total_tests': total_tests,
            'passed': success_count
        }
    
    def _test_performance(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        performance_results = {}
        
        # 1. CLIå¿œç­”æ™‚é–“ãƒ†ã‚¹ãƒˆ
        cli_commands = [
            ('help_response', 'python src/bungo_map/cli/search_cli.py --help'),
            ('stats_response', 'python src/bungo_map/cli/expand_cli.py stats'),
            ('export_response', 'python src/bungo_map/cli/export_cli.py stats')
        ]
        
        for test_name, command in cli_commands:
            start_time = time.time()
            try:
                result = subprocess.run(
                    command.split(),
                    cwd=self.base_path,
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                
                end_time = time.time()
                response_time = end_time - start_time
                
                performance_results[test_name] = {
                    'response_time': response_time,
                    'success': result.returncode == 0,
                    'benchmark': response_time < 5.0  # 5ç§’ä»¥å†…
                }
                
            except Exception as e:
                performance_results[test_name] = {
                    'response_time': None,
                    'success': False,
                    'error': str(e)
                }
        
        # 2. ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¸¬å®š
        process = psutil.Process()
        memory_before = process.memory_info().rss
        
        # è»½é‡å‡¦ç†å®Ÿè¡Œ
        try:
            subprocess.run(
                ['python', 'src/bungo_map/cli/search_cli.py', '--help'],
                cwd=self.base_path,
                capture_output=True,
                text=True,
                timeout=10
            )
        except:
            pass
        
        memory_after = process.memory_info().rss
        memory_usage = memory_after - memory_before
        
        performance_results['memory_usage'] = {
            'memory_delta': memory_usage,
            'memory_mb': memory_usage / 1024 / 1024,
            'benchmark': memory_usage < 50 * 1024 * 1024  # 50MBä»¥å†…
        }
        
        # ç·åˆè©•ä¾¡
        benchmark_passed = sum(1 for r in performance_results.values() if r.get('benchmark', False))
        total_benchmarks = len(performance_results)
        
        return {
            'success': benchmark_passed >= total_benchmarks * 0.8,
            'benchmark_rate': benchmark_passed / total_benchmarks,
            'results': performance_results,
            'summary': {
                'avg_response_time': sum(r.get('response_time', 0) for r in performance_results.values() if r.get('response_time')]),
                'memory_usage_mb': performance_results['memory_usage']['memory_mb'],
                'benchmarks_passed': f"{benchmark_passed}/{total_benchmarks}"
            }
        }
    
    def _test_error_handling(self) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        error_tests = []
        success_count = 0
        
        # 1. ä¸æ­£ãªã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°
        try:
            result = subprocess.run(
                ['python', 'src/bungo_map/cli/search_cli.py', 'invalid_command'],
                cwd=self.base_path,
                capture_output=True,
                text=True,
                timeout=10
            )
            
            # ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
            if result.returncode != 0 and ('Usage:' in result.stdout or 'Error' in result.stderr):
                error_tests.append("âœ… ä¸æ­£ã‚³ãƒãƒ³ãƒ‰å‡¦ç†")
                success_count += 1
            else:
                error_tests.append("âŒ ä¸æ­£ã‚³ãƒãƒ³ãƒ‰å‡¦ç†")
                
        except Exception as e:
            error_tests.append(f"âŒ ä¸æ­£ã‚³ãƒãƒ³ãƒ‰å‡¦ç† - {str(e)[:50]}")
        
        # 2. å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«æŒ‡å®š
        try:
            result = subprocess.run(
                ['python', 'src/bungo_map/cli/export_cli.py', 'csv', '/nonexistent/path/file.csv'],
                cwd=self.base_path,
                capture_output=True,
                text=True,
                timeout=10
            )
            
            # ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
            if result.returncode != 0:
                error_tests.append("âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼å‡¦ç†")
                success_count += 1
            else:
                error_tests.append("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼å‡¦ç†")
                
        except Exception as e:
            error_tests.append(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼å‡¦ç† - {str(e)[:50]}")
        
        # 3. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        try:
            # APIæ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆå¤±æ•—æœŸå¾…ï¼‰
            sys.path.append(str(self.base_path / 'src'))
            from bungo_map.ai.ai_manager import AIManager
            
            ai_manager = AIManager()
            # å®Ÿéš›ã®APIå‘¼ã³å‡ºã—ã‚’è¡Œã‚ãšãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‹•ä½œç¢ºèª
            connection_result = ai_manager.test_connection()
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‹•ä½œãŒé©åˆ‡ã«å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ã‹
            if 'success' in connection_result:
                error_tests.append("âœ… ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼å‡¦ç†")
                success_count += 1
            else:
                error_tests.append("âŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼å‡¦ç†")
                
        except Exception as e:
            error_tests.append(f"âŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼å‡¦ç† - {str(e)[:50]}")
        
        total_tests = 3
        success_rate = success_count / total_tests
        
        return {
            'success': success_rate >= 0.67,
            'success_rate': success_rate,
            'tests': error_tests,
            'total_tests': total_tests,
            'passed': success_count
        }
    
    def _test_memory_usage(self) -> Dict[str, Any]:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒ†ã‚¹ãƒˆ"""
        memory_results = {}
        
        # åˆæœŸãƒ¡ãƒ¢ãƒªçŠ¶æ³
        process = psutil.Process()
        initial_memory = process.memory_info().rss
        
        # å„CLIå®Ÿè¡Œæ™‚ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¸¬å®š
        cli_commands = [
            'python src/bungo_map/cli/search_cli.py --help',
            'python src/bungo_map/cli/export_cli.py stats',
            'python src/bungo_map/cli/geocode_cli.py stats'
        ]
        
        memory_measurements = []
        
        for command in cli_commands:
            try:
                start_memory = process.memory_info().rss
                
                subprocess.run(
                    command.split(),
                    cwd=self.base_path,
                    capture_output=True,
                    text=True,
                    timeout=15
                )
                
                end_memory = process.memory_info().rss
                memory_delta = end_memory - start_memory
                memory_measurements.append(memory_delta)
                
            except Exception:
                memory_measurements.append(0)
        
        avg_memory_usage = sum(memory_measurements) / len(memory_measurements)
        max_memory_usage = max(memory_measurements)
        
        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯: å¹³å‡50MBä»¥å†…ã€æœ€å¤§100MBä»¥å†…
        avg_benchmark = avg_memory_usage < 50 * 1024 * 1024
        max_benchmark = max_memory_usage < 100 * 1024 * 1024
        
        return {
            'success': avg_benchmark and max_benchmark,
            'avg_memory_mb': avg_memory_usage / 1024 / 1024,
            'max_memory_mb': max_memory_usage / 1024 / 1024,
            'benchmarks': {
                'avg_passed': avg_benchmark,
                'max_passed': max_benchmark
            },
            'measurements': [m / 1024 / 1024 for m in memory_measurements]
        }
    
    def _test_concurrent_operations(self) -> Dict[str, Any]:
        """ä¸¦è¡Œå‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        import threading
        import queue
        
        results_queue = queue.Queue()
        
        def run_cli_command(command, result_queue):
            try:
                result = subprocess.run(
                    command.split(),
                    cwd=self.base_path,
                    capture_output=True,
                    text=True,
                    timeout=20
                )
                result_queue.put(('success', result.returncode == 0))
            except Exception as e:
                result_queue.put(('error', str(e)))
        
        # ä¸¦è¡Œå®Ÿè¡Œã™ã‚‹ã‚³ãƒãƒ³ãƒ‰
        concurrent_commands = [
            'python src/bungo_map/cli/search_cli.py --help',
            'python src/bungo_map/cli/export_cli.py stats',
            'python src/bungo_map/cli/geocode_cli.py stats',
            'python src/bungo_map/cli/expand_cli.py stats'
        ]
        
        # ä¸¦è¡Œå®Ÿè¡Œ
        threads = []
        start_time = time.time()
        
        for command in concurrent_commands:
            thread = threading.Thread(target=run_cli_command, args=(command, results_queue))
            thread.start()
            threads.append(thread)
        
        # ã‚¹ãƒ¬ãƒƒãƒ‰å®Œäº†å¾…æ©Ÿ
        for thread in threads:
            thread.join()
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # çµæœåé›†
        results = []
        success_count = 0
        
        while not results_queue.empty():
            result_type, result_value = results_queue.get()
            results.append((result_type, result_value))
            
            if result_type == 'success' and result_value:
                success_count += 1
        
        success_rate = success_count / len(concurrent_commands)
        time_benchmark = total_time < 30  # 30ç§’ä»¥å†…
        
        return {
            'success': success_rate >= 0.75 and time_benchmark,
            'success_rate': success_rate,
            'total_time': total_time,
            'time_benchmark': time_benchmark,
            'results': results,
            'concurrent_operations': len(concurrent_commands)
        }
    
    def _generate_integration_report(self, results: Dict[str, Any]):
        """çµ±åˆãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        total_time = time.time() - self.start_time
        
        # æˆåŠŸç‡è¨ˆç®—
        category_scores = []
        for category, result in results.items():
            if 'success_rate' in result:
                category_scores.append(result['success_rate'])
            elif 'success' in result:
                category_scores.append(1.0 if result['success'] else 0.0)
        
        overall_success_rate = sum(category_scores) / len(category_scores) if category_scores else 0.0
        
        # ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
        if RICH_AVAILABLE:
            console.print("\n" + "=" * 80)
            console.print("[bold blue]ğŸ“‹ çµ±åˆãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ[/bold blue]")
            console.print("=" * 80)
            
            # ç·åˆçµæœ
            overall_panel = Panel.fit(
                f"[bold]ç·åˆæˆåŠŸç‡: {overall_success_rate:.1%}[/bold]\n"
                f"å®Ÿè¡Œæ™‚é–“: {total_time:.1f}ç§’\n"
                f"ãƒ†ã‚¹ãƒˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {'ğŸ‰ åˆæ ¼' if overall_success_rate >= 0.8 else 'âš ï¸ è¦æ”¹å–„'}",
                title="ğŸ¯ ç·åˆçµæœ"
            )
            console.print(overall_panel)
            
            # ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥çµæœãƒ†ãƒ¼ãƒ–ãƒ«
            table = Table(title="ğŸ“Š ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ãƒ†ã‚¹ãƒˆçµæœ")
            table.add_column("ã‚«ãƒ†ã‚´ãƒªãƒ¼", style="cyan")
            table.add_column("æˆåŠŸç‡", style="yellow")
            table.add_column("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", style="green")
            table.add_column("è©³ç´°", style="magenta")
            
            category_names = {
                'system_health': 'ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹',
                'cli_integration': 'ğŸ–¥ï¸ CLIçµ±åˆ',
                'ai_system': 'ğŸ¤– AIæ©Ÿèƒ½',
                'data_pipeline': 'ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³',
                'performance': 'âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹',
                'error_handling': 'ğŸ›¡ï¸ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°',
                'memory_usage': 'ğŸ’¾ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡',
                'concurrent_ops': 'ğŸ”„ ä¸¦è¡Œå‡¦ç†'
            }
            
            for category, result in results.items():
                name = category_names.get(category, category)
                
                if 'success_rate' in result:
                    success_rate = result['success_rate']
                    status = "âœ… åˆæ ¼" if success_rate >= 0.8 else "âš ï¸ è¦æ”¹å–„" if success_rate >= 0.6 else "âŒ ä¸åˆæ ¼"
                    details = f"{result.get('passed', 0)}/{result.get('total_tests', 0)} æˆåŠŸ"
                elif 'success' in result:
                    success_rate = 1.0 if result['success'] else 0.0
                    status = "âœ… åˆæ ¼" if result['success'] else "âŒ ä¸åˆæ ¼"
                    details = "å®Ÿè¡Œå®Œäº†" if result['success'] else "å®Ÿè¡Œå¤±æ•—"
                else:
                    success_rate = 0.0
                    status = "â“ ä¸æ˜"
                    details = "çµæœä¸æ˜"
                
                table.add_row(
                    name,
                    f"{success_rate:.1%}",
                    status,
                    details
                )
            
            console.print(table)
            
        else:
            print("\n" + "=" * 80)
            print("ğŸ“‹ çµ±åˆãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ")
            print("=" * 80)
            print(f"ç·åˆæˆåŠŸç‡: {overall_success_rate:.1%}")
            print(f"å®Ÿè¡Œæ™‚é–“: {total_time:.1f}ç§’")
            print(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {'ğŸ‰ åˆæ ¼' if overall_success_rate >= 0.8 else 'âš ï¸ è¦æ”¹å–„'}")
            
            for category, result in results.items():
                if 'success_rate' in result:
                    print(f"{category}: {result['success_rate']:.1%}")
                elif 'success' in result:
                    print(f"{category}: {'âœ…' if result['success'] else 'âŒ'}")
        
        # JSON ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'overall_success_rate': overall_success_rate,
            'execution_time': total_time,
            'categories': results
        }
        
        report_file = self.base_path / 'integration_test_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False, default=str)
        
        if RICH_AVAILABLE:
            console.print(f"\nğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")
        else:
            print(f"\nğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")

def main():
    """çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ"""
    suite = IntegrationTestSuite()
    results = suite.run_full_test_suite()
    
    return results

if __name__ == '__main__':
    main() 
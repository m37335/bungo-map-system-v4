#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIè¤‡åˆåœ°åæŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ  v4 (OpenAI APIçµ±åˆ)
v3ã‹ã‚‰ã®ç§»æ¤ãƒ»æ”¹è‰¯ç‰ˆ - è¤‡åˆåœ°åã€Œæ±äº¬é§…å‰ã€ç­‰ã®é«˜ç²¾åº¦æŠ½å‡º
"""

import re
import os
import json
import logging
from typing import List, Dict, Set, Optional, Any
from dataclasses import dataclass

logger = logging.getLogger(__name__)

# OpenAI APIã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ä¾å­˜ï¼‰
try:
    import openai
    OPENAI_AVAILABLE = True
    logger.info("âœ… OpenAI APIåˆ©ç”¨å¯èƒ½")
except ImportError:
    OPENAI_AVAILABLE = False
    logger.warning("âš ï¸ OpenAIæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã§å‹•ä½œ")

@dataclass
class CompoundPlace:
    """AIè¤‡åˆåœ°åãƒ‡ãƒ¼ã‚¿"""
    work_id: int
    place_name: str
    sentence: str
    category: str = ""
    confidence: float = 0.0
    method: str = "ai_compound"
    compound_type: str = ""
    base_place: str = ""
    modifier: str = ""
    start_pos: int = 0
    end_pos: int = 0
    ai_reasoning: str = ""
    aozora_url: str = ""

class PreciseCompoundExtractor:
    """AIè¤‡åˆåœ°åæŠ½å‡ºã‚¯ãƒ©ã‚¹ v4"""
    
    def __init__(self):
        # OpenAI APIåˆæœŸåŒ–
        self.client = None
        self.api_key = os.getenv('OPENAI_API_KEY')
        
        if OPENAI_AVAILABLE and self.api_key:
            try:
                openai.api_key = self.api_key
                self.client = openai
                logger.info("âœ… OpenAI APIåˆæœŸåŒ–æˆåŠŸ")
            except Exception as e:
                logger.warning(f"âš ï¸ OpenAI APIåˆæœŸåŒ–å¤±æ•—: {e}")
                self.client = None
        else:
            logger.warning("âš ï¸ OpenAI API Keyæœªè¨­å®š - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã§å‹•ä½œ")
        
        # è¤‡åˆåœ°åãƒ‘ã‚¿ãƒ¼ãƒ³
        self.compound_patterns = self._build_compound_patterns()
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¤‡åˆåœ°åãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
        self.fallback_compounds = self._build_fallback_compounds()
        
        logger.info("ğŸŒŸ AIè¤‡åˆåœ°åæŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ v4åˆæœŸåŒ–å®Œäº†")
    
    def _build_compound_patterns(self) -> Dict[str, Any]:
        """è¤‡åˆåœ°åãƒ‘ã‚¿ãƒ¼ãƒ³æ§‹ç¯‰"""
        return {
            # æ–¹å‘ãƒ»ä½ç½®ãƒ‘ã‚¿ãƒ¼ãƒ³
            'direction_patterns': [
                r'([ä¸€-é¾¯]{2,})(é§…å‰|é§…å¾Œ|é§…å‘¨è¾º)',
                r'([ä¸€-é¾¯]{2,})(å—|åŒ—|æ±|è¥¿)(å£|å´|éƒ¨|åœ°åŒº)',
                r'([ä¸€-é¾¯]{2,})(ä¸Š|ä¸‹|ä¸­)(ç”º|åœ°|éƒ¨)',
                r'([ä¸€-é¾¯]{2,})(å†…|å¤–)(åœ°|éƒ¨|å´)'
            ],
            
            # æ–½è¨­è¤‡åˆãƒ‘ã‚¿ãƒ¼ãƒ³
            'facility_patterns': [
                r'([ä¸€-é¾¯]{2,})(å¤§å­¦å‰|å­¦æ ¡å‰)',
                r'([ä¸€-é¾¯]{2,})(ç¥ç¤¾å‰|å¯ºå‰)',
                r'([ä¸€-é¾¯]{2,})(å¸‚å½¹æ‰€å‰|å½¹å ´å‰)',
                r'([ä¸€-é¾¯]{2,})(ç—…é™¢å‰|å…¬åœ’å‰)'
            ],
            
            # åœ°å½¢è¤‡åˆãƒ‘ã‚¿ãƒ¼ãƒ³
            'terrain_patterns': [
                r'([ä¸€-é¾¯]{2,})(å·æ²¿ã„|å·å²¸|æ²³ç•”)',
                r'([ä¸€-é¾¯]{2,})(å±±éº“|å±±é ‚|å±±ä¸­)',
                r'([ä¸€-é¾¯]{2,})(æµ·å²¸|æ¹–ç•”|æ°´è¾º)'
            ]
        }
    
    def _build_fallback_compounds(self) -> Set[str]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¤‡åˆåœ°åãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹"""
        return {
            # æ±äº¬åœ
            'æ–°å®¿é§…å‰', 'æ¸‹è°·é§…å‰', 'æ± è¢‹é§…å‰', 'å“å·é§…å‰', 'ä¸Šé‡é§…å‰',
            'æ±äº¬é§…å‰', 'æœ‰æ¥½ç”ºé§…å‰', 'éŠ€åº§å‘¨è¾º', 'ç§‹è‘‰åŸå‘¨è¾º',
            
            # é–¢è¥¿åœ
            'å¤§é˜ªé§…å‰', 'æ¢…ç”°é§…å‰', 'é›£æ³¢å‘¨è¾º', 'äº¬éƒ½é§…å‰', 'ç¥æˆ¸é§…å‰',
            
            # ãã®ä»–ä¸»è¦éƒ½å¸‚
            'æœ­å¹Œé§…å‰', 'ä»™å°é§…å‰', 'åå¤å±‹é§…å‰', 'åºƒå³¶é§…å‰', 'ç¦å²¡é§…å‰',
            
            # å¤å…¸è¤‡åˆåœ°å
            'æ±Ÿæˆ¸åŸä¸‹', 'äº¬éƒ½å¾¡æ‰€å‘¨è¾º', 'å¥ˆè‰¯å…¬åœ’å‘¨è¾º'
        }
    
    def extract_compound_places(self, work_id: int, text: str, aozora_url: str = "") -> List[CompoundPlace]:
        """AIè¤‡åˆåœ°åæŠ½å‡ºï¼ˆãƒ¡ã‚¤ãƒ³æ©Ÿèƒ½ï¼‰"""
        if not text or len(text) < 20:
            logger.warning(f"ãƒ†ã‚­ã‚¹ãƒˆãŒçŸ­ã™ãã¾ã™: {len(text)}æ–‡å­—")
            return []
        
        places = []
        
        # æ­£è¦è¡¨ç¾ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æŠ½å‡º
        regex_places = self._extract_with_regex(work_id, text, aozora_url)
        places.extend(regex_places)
        logger.info(f"ğŸ“Š æ­£è¦è¡¨ç¾æŠ½å‡º: {len(regex_places)}ä»¶")
        
        # é‡è¤‡é™¤å»
        unique_places = self._deduplicate_places(places)
        
        logger.info(f"âœ… AIè¤‡åˆåœ°åæŠ½å‡ºå®Œäº†: {len(unique_places)}ä»¶")
        return unique_places
    
    def _extract_with_regex(self, work_id: int, text: str, aozora_url: str) -> List[CompoundPlace]:
        """æ­£è¦è¡¨ç¾ã«ã‚ˆã‚‹è¤‡åˆåœ°åæŠ½å‡ºï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        places = []
        
        try:
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
            for category, patterns in self.compound_patterns.items():
                for pattern in patterns:
                    matches = re.finditer(pattern, text)
                    for match in matches:
                        place_name = match.group()
                        base_place = match.group(1) if match.groups() else ''
                        modifier = match.group(2) if len(match.groups()) > 1 else ''
                        
                        if self._is_valid_compound(place_name):
                            place = CompoundPlace(
                                work_id=work_id,
                                place_name=place_name,
                                sentence=self._get_context(text, place_name),
                                category=category,
                                confidence=self._calculate_regex_confidence(category),
                                method='regex',
                                compound_type=category.replace('_patterns', ''),
                                base_place=base_place,
                                modifier=modifier,
                                start_pos=match.start(),
                                end_pos=match.end(),
                                aozora_url=aozora_url
                            )
                            places.append(place)
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¤‡åˆåœ°åãƒã‚§ãƒƒã‚¯
            for compound in self.fallback_compounds:
                if compound in text:
                    start = text.find(compound)
                    place = CompoundPlace(
                        work_id=work_id,
                        place_name=compound,
                        sentence=self._get_context(text, compound),
                        category='fallback_compound',
                        confidence=0.85,
                        method='fallback',
                        compound_type='known_compound',
                        start_pos=start,
                        end_pos=start + len(compound),
                        aozora_url=aozora_url
                    )
                    places.append(place)
        
        except Exception as e:
            logger.error(f"âŒ æ­£è¦è¡¨ç¾æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        
        return places
    
    def _is_valid_compound(self, place_name: str) -> bool:
        """è¤‡åˆåœ°åã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯"""
        if not place_name or len(place_name) < 3:
            return False
        
        # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³
        exclusions = {'ä»Šæ—¥', 'æ˜¨æ—¥', 'æ˜æ—¥', 'æ™‚é–“', 'å ´åˆ', 'å•é¡Œ'}
        return place_name not in exclusions
    
    def _calculate_regex_confidence(self, category: str) -> float:
        """æ­£è¦è¡¨ç¾ã®ä¿¡é ¼åº¦è¨ˆç®—"""
        confidence_map = {
            'direction_patterns': 0.80,
            'facility_patterns': 0.85,
            'terrain_patterns': 0.80
        }
        return confidence_map.get(category, 0.70)
    
    def _get_context(self, text: str, place_name: str, context_len: int = 60) -> str:
        """åœ°åå‘¨è¾ºã®æ–‡è„ˆã‚’å–å¾—"""
        try:
            start = text.find(place_name)
            if start == -1:
                return ""
            
            context_start = max(0, start - context_len)
            context_end = min(len(text), start + len(place_name) + context_len)
            
            return text[context_start:context_end]
        except Exception:
            return ""
    
    def _deduplicate_places(self, places: List[CompoundPlace]) -> List[CompoundPlace]:
        """é‡è¤‡é™¤å»"""
        seen = set()
        unique_places = []
        
        # ä¿¡é ¼åº¦é †ã§ã‚½ãƒ¼ãƒˆ
        places.sort(key=lambda x: x.confidence, reverse=True)
        
        for place in places:
            key = (place.work_id, place.place_name)
            if key not in seen:
                seen.add(key)
                unique_places.append(place)
        
        return unique_places
    
    def test_extraction(self, test_text: str) -> Dict[str, Any]:
        """æŠ½å‡ºæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ§ª AIè¤‡åˆåœ°åæŠ½å‡ºå™¨ ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        places = self.extract_compound_places(999, test_text)
        
        # çµ±è¨ˆä½œæˆ
        categories = {}
        compound_types = {}
        for place in places:
            categories[place.category] = categories.get(place.category, 0) + 1
            compound_types[place.compound_type] = compound_types.get(place.compound_type, 0) + 1
        
        return {
            'test_text_length': len(test_text),
            'total_places': len(places),
            'openai_available': OPENAI_AVAILABLE,
            'api_key_configured': self.api_key is not None,
            'places': [
                {
                    'name': place.place_name,
                    'base_place': place.base_place,
                    'modifier': place.modifier,
                    'compound_type': place.compound_type,
                    'confidence': place.confidence,
                    'method': place.method
                }
                for place in places[:10]
            ],
            'stats': {
                'categories': categories,
                'compound_types': compound_types
            },
            'success': len(places) > 0
        }

if __name__ == "__main__":
    extractor = PreciseCompoundExtractor()
    
    test_text = """
    æ–°å®¿é§…å‰ã®å–«èŒ¶åº—ã§å¾…ã¡åˆã‚ã›ã‚’ã—ã¾ã—ãŸã€‚
    æ±äº¬é§…å‘¨è¾ºã¯å¤šãã®äººã§è³‘ã‚ã£ã¦ã„ã¾ã—ãŸã€‚
    å¤§é˜ªåŸå‘¨è¾ºã‚’æ•£æ­©ã—ã¦ã„ã‚‹ã¨ã€ç¾ã—ã„æ¡œãŒå’²ã„ã¦ã„ã¾ã—ãŸã€‚
    å¯Œå£«å±±éº“ã®æ¹–ç•”ã§é™ã‹ãªæ™‚é–“ã‚’éã”ã—ã¾ã—ãŸã€‚
    """
    
    result = extractor.test_extraction(test_text)
    
    print("âœ… AIè¤‡åˆåœ°åæŠ½å‡ºå™¨ v4 ãƒ†ã‚¹ãƒˆå®Œäº†")
    print(f"ğŸ“Š æŠ½å‡ºè¤‡åˆåœ°åæ•°: {result['total_places']}")
    print(f"ğŸ”§ OpenAIåˆ©ç”¨å¯èƒ½: {result['openai_available']}")
    print(f"ğŸ”‘ API Keyè¨­å®šæ¸ˆã¿: {result['api_key_configured']}")
    
    for place in result['places']:
        print(f"ğŸ—ºï¸ {place['name']} = {place['base_place']} + {place['modifier']}")
        print(f"    ã‚¿ã‚¤ãƒ—: {place['compound_type']}, ä¿¡é ¼åº¦: {place['confidence']:.2f}")
    
    print(f"\nğŸ“ˆ è¤‡åˆã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ: {result['stats']['compound_types']}") 
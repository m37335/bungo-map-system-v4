#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é’ç©ºæ–‡åº«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰CLI
"""

import asyncio
import sys
from pathlib import Path
from typing import List, Optional, Dict
from datetime import datetime

import click
import aiohttp
from rich.console import Console
from rich.progress import Progress, TaskID
from rich.table import Table

# Add parent directory to path for imports
sys.path.append(str(Path(__file__).parent.parent.parent))

from bungo_map.core.database import Database
from bungo_map.extractors.aozora_csv_downloader import AozoraCSVDownloader
from bungo_map.utils.logger import setup_logger

console = Console()
logger = setup_logger(__name__)


@click.group()
def aozora():
    """é’ç©ºæ–‡åº«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ã‚³ãƒãƒ³ãƒ‰"""
    pass


@aozora.command()
@click.option('--force', '-f', is_flag=True, help='å¼·åˆ¶çš„ã«CSVã‚’å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰')
def download_csv(force: bool):
    """é’ç©ºæ–‡åº«å…¬å¼CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    console.print("ğŸ“š é’ç©ºæ–‡åº«CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...", style="blue")
    
    try:
        downloader = AozoraCSVDownloader()
        csv_content = downloader.download_csv_data()
        
        if csv_content:
            console.print("âœ… CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ", style="green")
            
            # çµ±è¨ˆè¡¨ç¤º
            works = downloader.parse_csv_data(csv_content)
            table = Table(title="é’ç©ºæ–‡åº«çµ±è¨ˆ")
            table.add_column("é …ç›®", style="cyan")
            table.add_column("ä»¶æ•°", style="magenta")
            
            table.add_row("ç·ä½œå“æ•°", f"{len(works):,}")
            
            copyright_free = [w for w in works if w.get('copyright_flag') == 'ãªã—']
            table.add_row("è‘—ä½œæ¨©ãƒ•ãƒªãƒ¼ä½œå“", f"{len(copyright_free):,}")
            
            authors = set()
            for w in works:
                if w.get('author_last_name'):
                    authors.add(w['author_last_name'] + w.get('author_first_name', ''))
            table.add_row("ãƒ¦ãƒ‹ãƒ¼ã‚¯ä½œå®¶æ•°", f"{len(authors):,}")
            
            console.print(table)
        else:
            console.print("âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ", style="red")
        
    except Exception as e:
        console.print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}", style="red")
        sys.exit(1)


@aozora.command()
@click.option('--authors', '-a', help='å¯¾è±¡ä½œå®¶ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰')
@click.option('--limit', '-l', type=int, help='ä½œå“æ•°åˆ¶é™')
@click.option('--test', '-t', is_flag=True, help='ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆå®Ÿéš›ã«ã¯ç™»éŒ²ã—ãªã„ï¼‰')
def build_database(authors: Optional[str], limit: Optional[int], test: bool):
    """é’ç©ºæ–‡åº«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰"""
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä½œå®¶ãƒªã‚¹ãƒˆ
    default_authors = [
        "å¤ç›®æ¼±çŸ³", "èŠ¥å·ç«œä¹‹ä»‹", "å¤ªå®°æ²»", "å®®æ²¢è³¢æ²»", "æ£®é´å¤–",
        "ä¸­å³¶æ•¦", "æ¢¶äº•åŸºæ¬¡éƒ", "å‚å£å®‰å¾", "ä¸è¬é‡æ™¶å­", "ä¸­åŸä¸­ä¹Ÿ"
    ]
    
    target_authors = authors.split(',') if authors else default_authors
    
    console.print(f"ğŸ—ï¸  é’ç©ºæ–‡åº«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰é–‹å§‹", style="blue")
    console.print(f"å¯¾è±¡ä½œå®¶: {', '.join(target_authors)}")
    if limit:
        console.print(f"ä½œå“æ•°åˆ¶é™: {limit}")
    if test:
        console.print("âš ï¸ ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰: å®Ÿéš›ã®ç™»éŒ²ã¯è¡Œã„ã¾ã›ã‚“", style="yellow")
    
    try:
        downloader = AozoraCSVDownloader()
        
        # CSVãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        console.print("ğŸ“¥ é’ç©ºæ–‡åº«CSVãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...", style="yellow")
        csv_content = downloader.download_csv_data()
        if not csv_content:
            console.print("âŒ CSVãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ", style="red")
            return
        
        asyncio.run(_build_database_async(downloader, csv_content, target_authors, limit, test))
        
    except Exception as e:
        console.print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}", style="red")
        logger.exception("Database build failed")
        sys.exit(1)


async def _build_database_async(downloader: AozoraCSVDownloader, 
                               csv_content: str,
                               target_authors: List[str], 
                               limit: Optional[int], 
                               test: bool):
    """éåŒæœŸã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰"""
    
    db = Database()
    total_added = 0
    total_processed = 0
    
    # CSVãƒ‡ãƒ¼ã‚¿ã‚’è§£æ
    all_works = downloader.parse_csv_data(csv_content)
    
    stats_table = Table(title="ä½œå®¶åˆ¥å‡¦ç†çµæœ")
    stats_table.add_column("ä½œå®¶", style="cyan")
    stats_table.add_column("é’ç©ºæ–‡åº«ä½œå“æ•°", style="blue")
    stats_table.add_column("ãƒ•ã‚£ãƒ«ã‚¿å¾Œ", style="green")
    stats_table.add_column("è¿½åŠ ä½œå“æ•°", style="magenta")
    
    for author_name in target_authors:
        console.print(f"\nğŸ“– {author_name} ã®ä½œå“ã‚’å‡¦ç†ä¸­...", style="blue")
        
        try:
            # ä½œå“æ¤œç´¢ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            works = _search_author_works(all_works, author_name)
            console.print(f"é’ç©ºæ–‡åº«ä½œå“æ•°: {len(works)}")
            
            filtered_works = _filter_literary_works(works)
            console.print(f"ãƒ•ã‚£ãƒ«ã‚¿å¾Œä½œå“æ•°: {len(filtered_works)}")
            
            if limit:
                filtered_works = filtered_works[:limit]
                console.print(f"åˆ¶é™é©ç”¨å¾Œ: {len(filtered_works)}")
            
            added_count = 0
            
            # å„ä½œå“ã‚’å‡¦ç†
            with Progress() as progress:
                task = progress.add_task(f"{author_name}ã®ä½œå“å‡¦ç†", total=len(filtered_works))
                
                async with aiohttp.ClientSession() as session:
                    for work in filtered_works:
                        if not test:
                            added = await _process_single_work(db, downloader, work, session)
                            if added:
                                added_count += 1
                        else:
                            added_count += 1  # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§ã¯å…¨ã¦è¿½åŠ ã—ãŸã‚‚ã®ã¨ã™ã‚‹
                        
                        total_processed += 1
                        progress.update(task, advance=1)
            
            total_added += added_count
            stats_table.add_row(
                author_name,
                str(len(works)),
                str(len(filtered_works)),
                str(added_count)
            )
            
        except Exception as e:
            console.print(f"âŒ {author_name}ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", style="red")
            logger.exception(f"Error processing {author_name}")
    
    # çµæœè¡¨ç¤º
    console.print(stats_table)
    
    summary_table = Table(title="å‡¦ç†ã‚µãƒãƒªãƒ¼")
    summary_table.add_column("é …ç›®", style="cyan")
    summary_table.add_column("å€¤", style="magenta")
    
    summary_table.add_row("å‡¦ç†ä½œå“æ•°", f"{total_processed:,}")
    summary_table.add_row("è¿½åŠ ä½œå“æ•°", f"{total_added:,}")
    
    if not test:
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆ
        current_stats = db.get_stats()
        summary_table.add_row("ç·ä½œå“æ•°", f"{current_stats['works']:,}")
        summary_table.add_row("URLè¨­å®šæ¸ˆã¿", f"{current_stats['works_with_url']:,}")
        summary_table.add_row("ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è¨­å®šæ¸ˆã¿", f"{current_stats['works_with_content']:,}")
    
    console.print(summary_table)
    
    if test:
        console.print("âœ… ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰å®Œäº†ï¼ˆå®Ÿéš›ã®ç™»éŒ²ã¯è¡Œã‚ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼‰", style="green")
    else:
        console.print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰å®Œäº†", style="green")


def _search_author_works(all_works: List[Dict], author_name: str) -> List[Dict]:
    """ä½œå®¶åã‹ã‚‰ä½œå“ã‚’æ¤œç´¢"""
    author_works = []
    for work in all_works:
        full_name = f"{work['author_last_name']}{work['author_first_name']}"
        if full_name == author_name:
            author_works.append(work)
    return author_works


def _filter_literary_works(works: List[Dict]) -> List[Dict]:
    """æ–‡å­¦ä½œå“ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
    exclude_keywords = [
        'è©©é›†', 'æ­Œé›†', 'å…¨é›†', 'æ›¸ç°¡', 'æ—¥è¨˜', 'éšç­†é›†', 'è©•è«–', 
        'è¬›æ¼”', 'åº§è«‡', 'å¯¾è«‡', 'ç¿»è¨³', 'ç«¥è¬¡', 'çŸ­æ­Œ', 'ä¿³å¥', 'è©©'
    ]
    
    filtered = []
    for work in works:
        title = work.get('title', '')
        if work.get('copyright_flag') == 'ãªã—':  # è‘—ä½œæ¨©ãƒ•ãƒªãƒ¼ã®ã¿
            exclude = False
            for keyword in exclude_keywords:
                if keyword in title:
                    exclude = True
                    break
            if not exclude:
                filtered.append(work)
    
    return filtered


async def _process_single_work(db: Database, downloader: AozoraCSVDownloader, 
                              work: dict, session: aiohttp.ClientSession) -> bool:
    """å˜ä¸€ä½œå“ã®å‡¦ç†"""
    try:
        # ä½œå®¶æƒ…å ±ã®è¿½åŠ /å–å¾—
        author_id = db.add_author(
            name=work['author_last_name'] + work['author_first_name'],
            birth_year=None,  # å¾Œã§æ›´æ–°å¯èƒ½
            death_year=None
        )
        
        # ä½œå“ã®è¿½åŠ 
        work_id = db.add_work(
            title=work['title'],
            author_id=author_id,
            publication_year=None,  # é’ç©ºæ–‡åº«CSVã«ã¯ç™ºè¡Œå¹´ãŒãªã„
            aozora_url=work.get('html_url'),
            text_url=work.get('text_url')
        )
        
        if work_id and work.get('text_url'):
            # ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å–å¾—ã¨è¨­å®š
            try:
                content = downloader.extract_content_from_url(work['text_url'])
                if content:
                    db.set_work_content(work_id, content)
                    return True
            except Exception as e:
                logger.warning(f"Failed to get content for {work['title']}: {e}")
                return True  # URLã¯è¨­å®šã§ãã¦ã„ã‚‹ã®ã§éƒ¨åˆ†çš„æˆåŠŸ
        
        return bool(work_id)
        
    except Exception as e:
        logger.error(f"Failed to process work {work['title']}: {e}")
        return False


@aozora.command()
def stats():
    """ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆã‚’è¡¨ç¤º"""
    console.print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆ", style="blue")
    
    try:
        db = Database()
        stats = db.get_stats()
        
        table = Table(title="ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆ")
        table.add_column("é …ç›®", style="cyan")
        table.add_column("ä»¶æ•°", style="magenta")
        table.add_column("å‰²åˆ", style="green")
        
        table.add_row("ä½œå®¶æ•°", f"{stats['authors']:,}", "-")
        table.add_row("ä½œå“æ•°", f"{stats['works']:,}", "-")
        table.add_row("åœ°åæ•°", f"{stats['places']:,}", "-")
        
        if stats['works'] > 0:
            url_rate = stats['works_with_url'] / stats['works'] * 100
            content_rate = stats['works_with_content'] / stats['works'] * 100
            
            table.add_row("URLè¨­å®šæ¸ˆã¿", f"{stats['works_with_url']:,}", f"{url_rate:.1f}%")
            table.add_row("ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è¨­å®šæ¸ˆã¿", f"{stats['works_with_content']:,}", f"{content_rate:.1f}%")
        
        console.print(table)
        
    except Exception as e:
        console.print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}", style="red")
        sys.exit(1)


if __name__ == '__main__':
    aozora() 
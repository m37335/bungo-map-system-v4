#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ æ–‡è±ªåœ°å›³ å®Œå…¨çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
æ–°ãƒ‡ãƒ¼ã‚¿è¿½åŠ æ™‚ã®è‡ªå‹•å“è³ªç®¡ç†å¯¾å¿œ

Features:
- è¤‡æ•°æŠ½å‡ºå™¨ã®çµ±åˆ
- AIæ–‡è„ˆåˆ¤æ–­å‹Geocoding
- è‡ªå‹•å“è³ªç®¡ç†
- æ–°ãƒ‡ãƒ¼ã‚¿æ¤œçŸ¥ã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
- çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ
"""

import sqlite3
import time
import logging
import click
from typing import List, Dict, Optional

from bungo_map.extractors.simple_place_extractor import SimplePlaceExtractor
from bungo_map.extractors.enhanced_place_extractor import EnhancedPlaceExtractor  
from bungo_map.ai.extractors.precise_compound_extractor import PreciseCompoundExtractor
from bungo_map.ai.context_aware_geocoding import ContextAwareGeocodingService

# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿½åŠ 
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

logger = logging.getLogger(__name__)

class FullPipeline:
    """å®Œå…¨çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    
    def __init__(self, db_path: str = 'data/bungo_production.db'):
        """åˆæœŸåŒ–"""
        self.db_path = db_path
        # self.db = Database(db_path)
        self.simple_extractor = SimplePlaceExtractor()
        self.enhanced_extractor = EnhancedPlaceExtractor()
        self.ai_extractor = PreciseCompoundExtractor()
        self.geocoding_service = ContextAwareGeocodingService()  # AIæ–‡è„ˆåˆ¤æ–­å‹ã«å¤‰æ›´
        self.batch_size = 10
        self.use_ai = True
        self.use_geocoding = True
        self.geocoding_confidence_threshold = 0.3
        
        # ğŸ†• å“è³ªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        try:
            from comprehensive_cleanup import ComprehensiveCleanup
            self.quality_manager = ComprehensiveCleanup(db_path)
        except ImportError:
            logger.warning("âš ï¸ å“è³ªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            self.quality_manager = None
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            'total_works': 0,
            'processed_works': 0,
            'total_places': 0,
            'extraction_methods': {},
            'geocoding_success': 0,
            'geocoding_failed': 0,
            'geocoding_skipped': 0,
            'processing_time': 0,
            'quality_before': 0,
            'quality_after': 0,
            'quality_improvement': 0,
            'cleanup_actions': []
        }
    
    def reset_places_data(self) -> None:
        """placesãƒ†ãƒ¼ãƒ–ãƒ«ã‚’åˆæœŸåŒ–"""
        click.echo("ğŸ§¹ placesãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–ä¸­...")
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("DELETE FROM places")
            conn.execute("UPDATE sqlite_sequence SET seq = 0 WHERE name = 'places'")
            conn.commit()
        
        # VACUUMã¯åˆ¥æ¥ç¶šã§å®Ÿè¡Œ
        conn = sqlite3.connect(self.db_path)
        conn.execute("VACUUM")
        conn.close()
        
        click.echo("âœ… placesãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–å®Œäº†")
    
    def get_works_for_processing(self, limit: Optional[int] = None, offset: int = 0) -> List[Dict]:
        """å‡¦ç†å¯¾è±¡ä½œå“ã®å–å¾—"""
        with sqlite3.connect(self.db_path) as conn:
            if limit:
                cursor = conn.execute("""
                    SELECT w.work_id, w.title, a.name as author_name, w.content, w.aozora_url 
                    FROM works w 
                    JOIN authors a ON w.author_id = a.author_id
                    WHERE w.content IS NOT NULL AND w.content != ''
                    ORDER BY w.work_id LIMIT ? OFFSET ?
                """, (limit, offset))
            else:
                cursor = conn.execute("""
                    SELECT w.work_id, w.title, a.name as author_name, w.content, w.aozora_url 
                    FROM works w 
                    JOIN authors a ON w.author_id = a.author_id
                    WHERE w.content IS NOT NULL AND w.content != ''
                    ORDER BY w.work_id
                """)
            
            works = [
                {
                    'work_id': row[0], 'title': row[1], 'author_name': row[2], 
                    'content': row[3], 'aozora_url': row[4]
                }
                for row in cursor.fetchall()
            ]
        
        self.stats['total_works'] = len(works)
        return works
    
    def extract_places_from_work(self, work_data: Dict, use_ai: bool = True) -> List:
        """ä½œå“ã‹ã‚‰åœ°åæŠ½å‡º"""
        work_id = work_data['work_id']
        title = work_data['title']
        content = work_data['content']
        all_places = []
        
        try:
            # 1. å¼·åŒ–ç‰ˆåœ°åæŠ½å‡ºï¼ˆé’ç©ºæ–‡åº«å‡¦ç† + é©åˆ‡ãªæ–‡è„ˆå–å¾—ï¼‰
            enhanced_places = self.enhanced_extractor.extract_places_from_work(
                work_id, content
            )
            
            # 2. SimplePlaceã¨äº’æ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›
            simple_places = self.enhanced_extractor.convert_to_simple_places(enhanced_places)
            all_places.extend(simple_places)
            
            # 3. AIè¤‡åˆåœ°åæŠ½å‡ºï¼ˆé’ç©ºæ–‡åº«ã‚¯ãƒªãƒ¼ãƒŠãƒ¼çµ±åˆæ¸ˆã¿ï¼‰
            if use_ai:
                try:
                    ai_places = self.ai_extractor.extract_precise_places(work_id, content)
                    all_places.extend(ai_places)
                except Exception as e:
                    logger.warning(f"AIæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {title} - {e}")
            
            # çµ±è¨ˆæ›´æ–°
            for place in all_places:
                method = place.extraction_method
                self.stats['extraction_methods'][method] = self.stats['extraction_methods'].get(method, 0) + 1
            
            logger.info(f"âœ… '{title}': {len(all_places)}ä»¶ã®åœ°åæŠ½å‡º")
            
        except Exception as e:
            logger.error(f"âŒ '{title}' æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        
        return all_places
    
    def save_places_to_db(self, places: List) -> None:
        """åœ°åãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        if not places:
            return
        
        with sqlite3.connect(self.db_path) as conn:
            for place in places:
                conn.execute("""
                    INSERT INTO places (work_id, place_name, before_text, sentence, after_text, 
                                      aozora_url, confidence, extraction_method)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    place.work_id, place.place_name, place.before_text, place.sentence,
                    place.after_text, place.aozora_url, place.confidence, place.extraction_method
                ))
            conn.commit()
    
    def geocode_places(self, batch_size: int = 50, min_confidence: float = 0.5) -> None:
        """åœ°åã®Geocodingå‡¦ç†"""
        click.echo("ğŸ—ºï¸ Geocodingå‡¦ç†é–‹å§‹...")
        
        # å¯¾è±¡åœ°åå–å¾—
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("""
                SELECT place_id, place_name, confidence 
                FROM places 
                WHERE lat IS NULL AND lng IS NULL
                AND confidence >= ?
                ORDER BY confidence DESC, LENGTH(place_name) DESC
            """, (min_confidence,))
            places_to_geocode = cursor.fetchall()
        
        if not places_to_geocode:
            click.echo("â­ï¸ Geocodingå¯¾è±¡åœ°åãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        total_places = len(places_to_geocode)
        total_batches = (total_places + batch_size - 1) // batch_size
        
        click.echo(f"ğŸ“ Geocodingå¯¾è±¡: {total_places}ä»¶ ({total_batches}ãƒãƒƒãƒ)")
        
        for i in range(0, total_places, batch_size):
            batch = places_to_geocode[i:i + batch_size]
            batch_num = i//batch_size + 1
            
            click.echo(f"ğŸ“¦ Geocodingãƒãƒƒãƒ {batch_num}/{total_batches} ({len(batch)}ä»¶)")
            
            batch_updates = []
            
            for place_id, place_name, confidence in batch:
                # ä½ä¿¡é ¼åº¦ã‚„æ˜ã‚‰ã‹ã«åœ°åã§ãªã„ã‚‚ã®ã¯ã‚¹ã‚­ãƒƒãƒ—
                if len(place_name) <= 1 or confidence < 0.3:
                    self.stats['geocoding_skipped'] += 1
                    continue
                
                # æ–‡è„ˆæƒ…å ±ã‚’å–å¾—ã—ã¦AIæ–‡è„ˆåˆ¤æ–­å‹Geocodingå®Ÿè¡Œ
                with sqlite3.connect(self.db_path) as conn:
                    cursor = conn.execute("""
                        SELECT sentence, before_text, after_text 
                        FROM places WHERE place_id = ?
                    """, (place_id,))
                    context_data = cursor.fetchone()
                
                if context_data:
                    sentence, before_text, after_text = context_data
                    geocoding_result = self.geocoding_service.geocode_place_sync(
                        place_name=place_name,
                        sentence=sentence or "",
                        before_text=before_text or "",
                        after_text=after_text or ""
                    )
                else:
                    geocoding_result = self.geocoding_service.geocode_place_sync(place_name)
                
                if geocoding_result:
                    batch_updates.append((
                        geocoding_result.latitude,
                        geocoding_result.longitude,
                        geocoding_result.confidence,
                        geocoding_result.source,
                        geocoding_result.prefecture,
                        geocoding_result.city,
                        place_id
                    ))
                    self.stats['geocoding_success'] += 1
                else:
                    self.stats['geocoding_failed'] += 1
            
            # ãƒãƒƒãƒæ›´æ–°
            if batch_updates:
                with sqlite3.connect(self.db_path) as conn:
                    conn.executemany("""
                        UPDATE places SET 
                            lat = ?, lng = ?, geocoding_confidence = ?, geocoding_source = ?,
                            prefecture = ?, city = ?
                        WHERE place_id = ?
                    """, batch_updates)
                    conn.commit()
                
                click.echo(f"  âœ… {len(batch_updates)}ä»¶ã®Geocodingå®Œäº†")
            
            # é€²æ—è¡¨ç¤º
            processed = min(i + batch_size, total_places)
            progress = (processed / total_places) * 100
            click.echo(f"  ğŸ“Š é€²æ—: {processed}/{total_places} ({progress:.1f}%)")
    
    def run_quality_management(self, auto_cleanup: bool = True) -> Dict:
        """ğŸ†• å“è³ªç®¡ç†ã®å®Ÿè¡Œ"""
        
        if not self.quality_manager:
            click.echo("âš ï¸ å“è³ªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ç„¡åŠ¹")
            return {'quality_improvement': 0, 'actions_taken': []}
        
        click.echo("ğŸ§  å“è³ªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œä¸­...")
        
        # æ–°ãƒ‡ãƒ¼ã‚¿æ¤œçŸ¥
        data_status = self.quality_manager.detect_new_data()
        before_score = self.quality_manager.get_quality_score()
        
        self.stats['quality_before'] = before_score
        
        click.echo(f"  ğŸ“Š å“è³ªã‚¹ã‚³ã‚¢: {before_score:.1f}/100")
        click.echo(f"  ğŸ“Š æ–°ãƒ‡ãƒ¼ã‚¿æ¤œçŸ¥: {data_status['new_data_detected']}")
        click.echo(f"  ğŸ“Š å¤‰æ›´ä»¶æ•°: {data_status['change_count']}")
        
        # é©å¿œå‹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ
        if auto_cleanup:
            result = self.quality_manager.run_adaptive_cleanup()
            
            after_score = result['after_score']
            improvement = result['improvement']
            
            self.stats['quality_after'] = after_score
            self.stats['quality_improvement'] = improvement
            self.stats['cleanup_actions'] = result['actions_taken']
            
            if improvement > 0:
                click.echo(f"  âœ… å“è³ªæ”¹å–„: +{improvement:.1f}ç‚¹")
                click.echo(f"  âš¡ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {len(result['actions_taken'])}ä»¶")
                for action in result['actions_taken']:
                    click.echo(f"    - {action}")
            else:
                click.echo("  âœ… å“è³ªè‰¯å¥½: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸è¦")
        
        return {
            'quality_improvement': self.stats['quality_improvement'],
            'actions_taken': self.stats['cleanup_actions']
        }
    
    def run_full_pipeline(self, 
                         reset_data: bool = True,
                         use_ai: bool = True, 
                         enable_geocoding: bool = True,
                         enable_quality_management: bool = True,
                         limit: Optional[int] = None,
                         batch_size: int = 5,
                         geocoding_min_confidence: float = 0.5) -> Dict:
        """å®Œå…¨çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        
        pipeline_start = time.time()
        
        if reset_data:
            self.reset_places_data()
        
        works = self.get_works_for_processing(limit)
        total_works = len(works)
        
        if total_works == 0:
            click.echo("âš ï¸ å‡¦ç†å¯¾è±¡ã®ä½œå“ãŒã‚ã‚Šã¾ã›ã‚“")
            return {'stats': self.stats}
        
        click.echo(f"ğŸš€ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹: {total_works}ä½œå“")
        
        # ãƒãƒƒãƒå‡¦ç†
        for i in range(0, total_works, batch_size):
            batch = works[i:i + batch_size]
            batch_num = i//batch_size + 1
            total_batches = (total_works + batch_size - 1)//batch_size
            
            click.echo(f"ğŸ“¦ ãƒãƒƒãƒ {batch_num}/{total_batches} ({len(batch)}ä½œå“)")
            
            batch_places = []
            for work in batch:
                places = self.extract_places_from_work(work, use_ai)
                batch_places.extend(places)
                self.stats['processed_works'] += 1
            
            # ãƒãƒƒãƒä¿å­˜
            self.save_places_to_db(batch_places)
            self.stats['total_places'] += len(batch_places)
            
            click.echo(f"  âœ… {len(batch_places)}ä»¶ã®åœ°åä¿å­˜å®Œäº†")
        
        # Geocodingå‡¦ç†
        if enable_geocoding:
            self.geocode_places(min_confidence=geocoding_min_confidence)
        
        # ğŸ†• å“è³ªç®¡ç†å®Ÿè¡Œ
        if enable_quality_management:
            quality_result = self.run_quality_management(auto_cleanup=True)
        
        # çµ±è¨ˆè¨ˆç®—
        processing_time = time.time() - pipeline_start
        self.stats['processing_time'] = processing_time
        
        return {'stats': self.stats}
    
    def display_final_stats(self) -> None:
        """æœ€çµ‚çµ±è¨ˆè¡¨ç¤ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        click.echo("\n" + "=" * 60)
        click.echo("ğŸ‰ å®Œå…¨çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†ï¼")
        click.echo("=" * 60)
        
        click.echo(f"ğŸ“Š å‡¦ç†çµ±è¨ˆ:")
        click.echo(f"  âœ… å‡¦ç†ä½œå“: {self.stats['processed_works']}/{self.stats['total_works']}")
        click.echo(f"  ğŸ“ æŠ½å‡ºåœ°å: {self.stats['total_places']}ä»¶")
        click.echo(f"  â±ï¸  å‡¦ç†æ™‚é–“: {self.stats['processing_time']:.1f}ç§’")
        
        if self.stats['total_places'] > 0:
            speed = self.stats['total_places'] / self.stats['processing_time']
            click.echo(f"  ğŸš€ å‡¦ç†é€Ÿåº¦: {speed:.1f}ä»¶/ç§’")
        
        if self.stats['extraction_methods']:
            click.echo(f"\nğŸ“‹ æŠ½å‡ºæ‰‹æ³•åˆ¥çµ±è¨ˆ:")
            for method, count in sorted(self.stats['extraction_methods'].items(), key=lambda x: x[1], reverse=True):
                percentage = (count / self.stats['total_places']) * 100
                click.echo(f"  {method}: {count}ä»¶ ({percentage:.1f}%)")
        
        # Geocodingçµ±è¨ˆ
        geocoding_total = self.stats['geocoding_success'] + self.stats['geocoding_failed']
        if geocoding_total > 0:
            success_rate = (self.stats['geocoding_success'] / geocoding_total) * 100
            click.echo(f"\nğŸ—ºï¸ Geocodingçµ±è¨ˆ:")
            click.echo(f"  âœ… æˆåŠŸ: {self.stats['geocoding_success']}ä»¶")
            click.echo(f"  âŒ å¤±æ•—: {self.stats['geocoding_failed']}ä»¶")
            click.echo(f"  â­ï¸  ã‚¹ã‚­ãƒƒãƒ—: {self.stats['geocoding_skipped']}ä»¶")
            click.echo(f"  ğŸ“Š æˆåŠŸç‡: {success_rate:.1f}%")
        
        # ğŸ†• å“è³ªç®¡ç†çµ±è¨ˆ
        if self.stats['quality_improvement'] != 0:
            click.echo(f"\nğŸ§  å“è³ªç®¡ç†çµ±è¨ˆ:")
            click.echo(f"  ğŸ“Š æ”¹å–„å‰å“è³ª: {self.stats['quality_before']:.1f}/100")
            click.echo(f"  ğŸ“Š æ”¹å–„å¾Œå“è³ª: {self.stats['quality_after']:.1f}/100")
            click.echo(f"  ğŸ“ˆ å“è³ªæ”¹å–„: +{self.stats['quality_improvement']:.1f}ç‚¹")
            if self.stats['cleanup_actions']:
                click.echo(f"  âš¡ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—:")
                for action in self.stats['cleanup_actions']:
                    click.echo(f"    - {action}")

@click.command()
@click.option('--reset-data/--no-reset', default=True, help='placesãƒ†ãƒ¼ãƒ–ãƒ«ã‚’åˆæœŸåŒ–')
@click.option('--use-ai/--no-ai', default=True, help='AIè¤‡åˆåœ°åæŠ½å‡ºã‚’ä½¿ç”¨')
@click.option('--geocoding/--no-geocoding', default=True, help='Geocodingå‡¦ç†ã‚’å®Ÿè¡Œ')
@click.option('--quality-management/--no-quality', default=True, help='å“è³ªç®¡ç†ã‚’å®Ÿè¡Œ')
@click.option('--limit', type=int, help='å‡¦ç†ä½œå“æ•°ã®åˆ¶é™')
@click.option('--batch-size', type=int, default=5, help='æŠ½å‡ºãƒãƒƒãƒã‚µã‚¤ã‚º')
@click.option('--geocoding-confidence', type=float, default=0.5, help='Geocodingæœ€å°ä¿¡é ¼åº¦')
def main(reset_data: bool, use_ai: bool, geocoding: bool, quality_management: bool,
         limit: Optional[int], batch_size: int, geocoding_confidence: float):
    """æ–‡è±ªåœ°å›³å®Œå…¨çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    pipeline = FullPipeline()
    result = pipeline.run_full_pipeline(
        reset_data=reset_data,
        use_ai=use_ai,
        enable_geocoding=geocoding,
        enable_quality_management=quality_management,
        limit=limit,
        batch_size=batch_size,
        geocoding_min_confidence=geocoding_confidence
    )
    
    # ğŸ†• æœ€çµ‚çµ±è¨ˆè¡¨ç¤º
    pipeline.display_final_stats()

if __name__ == '__main__':
    main() 
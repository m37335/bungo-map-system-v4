#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ” Sentenceé‡è¤‡æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ 
ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã®sentenceéƒ¨åˆ†ã®é‡è¤‡æ¤œçŸ¥æ©Ÿèƒ½ã‚’èª¿æŸ»ãƒ»åˆ†æ
"""

import sqlite3
import logging
from typing import Dict, List
from collections import defaultdict, Counter
from dataclasses import dataclass

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class DuplicatePattern:
    pattern_type: str
    sentence: str
    duplicated_places: List[str]
    extraction_methods: List[str]
    severity: str
    recommendation: str

class DatabaseVerificationSystem:
    def __init__(self, db_path: str = "data/bungo_production.db"):
        self.db_path = db_path
    
    def analyze_sentence_duplicates(self) -> List[DuplicatePattern]:
        """Sentence ãƒ¬ãƒ™ãƒ«ã®é‡è¤‡åˆ†æ"""
        logger.info("ğŸ” Sentenceé‡è¤‡åˆ†æé–‹å§‹")
        patterns = []
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("""
                SELECT sentence, 
                       GROUP_CONCAT(place_name, '|') as places,
                       GROUP_CONCAT(extraction_method, '|') as methods,
                       COUNT(*) as count
                FROM places 
                WHERE sentence IS NOT NULL AND sentence != ''
                GROUP BY sentence 
                HAVING COUNT(*) > 1 
                ORDER BY COUNT(*) DESC
            """)
            
            for sentence, places_str, methods_str, count in cursor.fetchall():
                places = places_str.split('|')
                methods = methods_str.split('|')
                
                unique_places = list(set(places))
                unique_methods = list(set(methods))
                
                # é‡è¤‡ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†é¡
                if len(unique_places) == 1:
                    pattern_type = "extractor_conflict"
                    severity = "medium" if count <= 3 else "high"
                    recommendation = f"æŠ½å‡ºå™¨é–“ã§é‡è¤‡: {unique_methods}"
                elif count > 10:
                    pattern_type = "name_list"
                    severity = "low"
                    recommendation = "åœ°ååˆ—æŒ™æ–‡: é‡è¦åº¦ã®é«˜ã„åœ°åã®ã¿ä¿æŒ"
                else:
                    pattern_type = "general_duplicate"
                    severity = "medium"
                    recommendation = "æ–‡è„ˆã¨ä¿¡é ¼åº¦ã§å„ªå…ˆåº¦æ±ºå®š"
                
                patterns.append(DuplicatePattern(
                    pattern_type=pattern_type,
                    sentence=sentence[:100] + "..." if len(sentence) > 100 else sentence,
                    duplicated_places=unique_places,
                    extraction_methods=unique_methods,
                    severity=severity,
                    recommendation=recommendation
                ))
        
        logger.info(f"âœ… {len(patterns)}ä»¶ã®é‡è¤‡ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º")
        return patterns
    
    def analyze_extractor_conflicts(self) -> Dict:
        """æŠ½å‡ºå™¨é–“ã®ç«¶åˆåˆ†æ"""
        logger.info("âš”ï¸ æŠ½å‡ºå™¨ç«¶åˆåˆ†æé–‹å§‹")
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("""
                SELECT place_name, extraction_method, COUNT(*) as count
                FROM places 
                GROUP BY place_name, extraction_method
                ORDER BY place_name, count DESC
            """)
            
            place_methods = defaultdict(list)
            for place_name, method, count in cursor.fetchall():
                place_methods[place_name].append((method, count))
        
        conflicts = {}
        for place_name, methods in place_methods.items():
            if len(methods) > 1:
                total_count = sum(count for _, count in methods)
                method_distribution = {
                    method: count / total_count for method, count in methods
                }
                
                max_ratio = max(method_distribution.values())
                if max_ratio < 0.7:  # ã©ã®æ‰‹æ³•ã‚‚70%æœªæº€ã®å ´åˆ
                    conflicts[place_name] = {
                        'methods': dict(methods),
                        'distribution': method_distribution,
                        'conflict_level': 'high' if max_ratio < 0.5 else 'medium',
                        'total_count': total_count
                    }
        
        logger.info(f"âš”ï¸ {len(conflicts)}ä»¶ã®æŠ½å‡ºå™¨ç«¶åˆã‚’æ¤œå‡º")
        return conflicts
    
    def run_verification(self) -> Dict:
        """åŒ…æ‹¬çš„æ¤œè¨¼ã®å®Ÿè¡Œ"""
        duplicate_patterns = self.analyze_sentence_duplicates()
        extractor_conflicts = self.analyze_extractor_conflicts()
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("SELECT COUNT(*) FROM places")
            total_places = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(DISTINCT sentence) FROM places WHERE sentence IS NOT NULL")
            unique_sentences = cursor.fetchone()[0]
            
            cursor = conn.execute("""
                SELECT COUNT(*) FROM (
                    SELECT sentence FROM places 
                    WHERE sentence IS NOT NULL 
                    GROUP BY sentence 
                    HAVING COUNT(*) > 1
                )
            """)
            sentence_duplicates = cursor.fetchone()[0]
        
        return {
            "total_places": total_places,
            "unique_sentences": unique_sentences,
            "sentence_duplicates": sentence_duplicates,
            "duplicate_patterns": len(duplicate_patterns),
            "extractor_conflicts": len(extractor_conflicts),
            "patterns": duplicate_patterns[:5],
            "conflicts": dict(list(extractor_conflicts.items())[:5])
        }

def main():
    import argparse
    parser = argparse.ArgumentParser(description='Sentenceé‡è¤‡æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ')
    parser.add_argument('command', choices=['verify', 'duplicates', 'conflicts'],
                       help='å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰')
    args = parser.parse_args()
    
    verifier = DatabaseVerificationSystem()
    
    if args.command == 'verify':
        result = verifier.run_verification()
        print("ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å“è³ªæ¤œè¨¼çµæœ")
        print("=" * 50)
        print(f"ğŸ“ ç·åœ°åæ•°: {result['total_places']:,}")
        print(f"ğŸ“ ãƒ¦ãƒ‹ãƒ¼ã‚¯æ–‡æ•°: {result['unique_sentences']:,}")
        print(f"ğŸ”„ Sentenceé‡è¤‡: {result['sentence_duplicates']}ä»¶")
        print(f"ğŸ“Š é‡è¤‡ãƒ‘ã‚¿ãƒ¼ãƒ³: {result['duplicate_patterns']}ä»¶")
        print(f"âš”ï¸ æŠ½å‡ºå™¨ç«¶åˆ: {result['extractor_conflicts']}ä»¶")
        
    elif args.command == 'duplicates':
        patterns = verifier.analyze_sentence_duplicates()
        print(f"ğŸ”„ Sentenceé‡è¤‡åˆ†æ: {len(patterns)}ä»¶æ¤œå‡º")
        print("=" * 50)
        
        for i, pattern in enumerate(patterns[:5]):
            print(f"ã€{i+1}ã€‘{pattern.severity}: {pattern.pattern_type}")
            print(f"åœ°å: {', '.join(pattern.duplicated_places)}")
            print(f"æ–‡: {pattern.sentence}")
            print(f"æ¨å¥¨: {pattern.recommendation}")
            print("-" * 40)
            
    elif args.command == 'conflicts':
        conflicts = verifier.analyze_extractor_conflicts()
        print(f"âš”ï¸ æŠ½å‡ºå™¨ç«¶åˆåˆ†æ: {len(conflicts)}ä»¶æ¤œå‡º")
        print("=" * 50)
        
        for place_name, info in list(conflicts.items())[:5]:
            print(f"åœ°å: {place_name}")
            print(f"ç«¶åˆãƒ¬ãƒ™ãƒ«: {info['conflict_level']}")
            print(f"åˆ†å¸ƒ: {info['distribution']}")
            print("-" * 40)

if __name__ == "__main__":
    main() 